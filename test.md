# æ™ºèƒ½é—®ç­”ç³»ç»ŸæŠ€æœ¯æ¶æ„è®¾è®¡æ–‡æ¡£

## 1. é¡¹ç›®æ¦‚è¿°ä¸æŠ€æœ¯èƒŒæ™¯

### 1.1 é¡¹ç›®ç›®æ ‡

æ„å»ºä¸€ä¸ªåŸºäº Agentic RAG çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œèƒ½å¤Ÿè‡ªåŠ¨ä»æœ¬åœ°æ–‡æ¡£åº“æ£€ç´¢ä¿¡æ¯ï¼Œå½“æœ¬åœ°çŸ¥è¯†ä¸è¶³æ—¶æ™ºèƒ½è°ƒç”¨ç½‘ç»œæœç´¢ï¼Œä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€å…¨é¢çš„ç­”æ¡ˆã€‚

### 1.2 æŠ€æœ¯èƒŒæ™¯è§£é‡Š

#### 1.2.1 ä»€ä¹ˆæ˜¯RAGï¼Ÿ

**RAGï¼ˆRetrieval Augmented Generationï¼‰**æ˜¯ä¸€ç§ç»“åˆä¿¡æ¯æ£€ç´¢å’Œç”Ÿæˆå¼AIçš„æŠ€æœ¯æ¶æ„ï¼š

- **ä¼ ç»Ÿæ–¹å¼çš„é—®é¢˜**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è™½ç„¶å¼ºå¤§ï¼Œä½†å­˜åœ¨çŸ¥è¯†æˆªæ­¢æ—¶é—´é™åˆ¶ï¼Œæ— æ³•è·å–æœ€æ–°ä¿¡æ¯ï¼Œä¸”å¯èƒ½äº§ç”Ÿå¹»è§‰ï¼ˆç¼–é€ ä¸å­˜åœ¨çš„ä¿¡æ¯ï¼‰
- **RAGçš„è§£å†³æ–¹æ¡ˆ**ï¼šåœ¨ç”Ÿæˆç­”æ¡ˆå‰ï¼Œå…ˆä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œç„¶ååŸºäºæ£€ç´¢åˆ°çš„çœŸå®ä¿¡æ¯æ¥ç”Ÿæˆç­”æ¡ˆ
- **ä¼˜åŠ¿**ï¼šç¡®ä¿ç­”æ¡ˆåŸºäºçœŸå®æ•°æ®ï¼Œå¯ä»¥æ•´åˆæœ€æ–°ä¿¡æ¯ï¼Œå‡å°‘å¹»è§‰ç°è±¡

#### 1.2.2 ä»€ä¹ˆæ˜¯Agentic RAGï¼Ÿ

**Agentic RAG**æ˜¯RAGæŠ€æœ¯çš„è¿›åŒ–ç‰ˆæœ¬ï¼Œå¼•å…¥äº†æ™ºèƒ½ä»£ç†ï¼ˆAgentï¼‰çš„æ¦‚å¿µï¼š

- **ä¼ ç»ŸRAG**ï¼šæ£€ç´¢â†’ç”Ÿæˆï¼Œæµç¨‹å›ºå®š
- **Agentic RAG**ï¼šæ™ºèƒ½ä»£ç†å¯ä»¥æ ¹æ®æŸ¥è¯¢ç±»å‹å’Œç»“æœè´¨é‡ï¼ŒåŠ¨æ€å†³å®šæ£€ç´¢ç­–ç•¥ã€æ˜¯å¦éœ€è¦å¤šè½®æ£€ç´¢ã€æ˜¯å¦è°ƒç”¨å¤–éƒ¨å·¥å…·ç­‰
- **ä¸ºä»€ä¹ˆéœ€è¦**ï¼šä¸åŒç±»å‹çš„é—®é¢˜éœ€è¦ä¸åŒçš„æ£€ç´¢ç­–ç•¥ï¼ŒAgentic RAGå¯ä»¥æ™ºèƒ½é€‰æ‹©æœ€ä½³è·¯å¾„

#### 1.2.3 æŠ€æœ¯ç»„ä»¶çš„ä½œç”¨è§£é‡Š

**LightRAG**ï¼š

- **ä½œç”¨**ï¼šè½»é‡çº§çš„RAGæ¡†æ¶ï¼Œå¤„ç†æ–‡æ¡£å‘é‡åŒ–å’Œæ£€ç´¢
- **ä¸ºä»€ä¹ˆé€‰æ‹©**ï¼šç›¸æ¯”ä¼ ç»ŸRAGï¼ŒLightRAGç»“åˆäº†å‘é‡æ£€ç´¢å’Œå›¾æ£€ç´¢ï¼Œèƒ½æ›´å¥½åœ°ç†è§£æ–‡æ¡£é—´çš„å…³ç³»

**Graphiti**ï¼š

- **ä½œç”¨**ï¼šå®æ—¶æ„å»ºå’Œæ›´æ–°çŸ¥è¯†å›¾è°±
- **ä¸ºä»€ä¹ˆéœ€è¦**ï¼šçº¯å‘é‡æ£€ç´¢åªèƒ½æ‰¾åˆ°ç›¸ä¼¼å†…å®¹ï¼Œæ— æ³•ç†è§£å®ä½“é—´çš„å…³ç³»ã€‚çŸ¥è¯†å›¾è°±èƒ½å¤Ÿæ•è·"è°ä¸è°ç›¸å…³"ã€"ä»€ä¹ˆå½±å“ä»€ä¹ˆ"ç­‰å…³ç³»ä¿¡æ¯

**LangGraph**ï¼š

- **ä½œç”¨**ï¼šæ™ºèƒ½å·¥ä½œæµç¼–æ’å¼•æ“
- **ä¸ºä»€ä¹ˆéœ€è¦**ï¼šä¼ ç»ŸRAGæ˜¯çº¿æ€§æµç¨‹ï¼ŒLangGraphå¯ä»¥æ„å»ºå¤æ‚çš„å†³ç­–æ ‘ï¼Œè®©ç³»ç»Ÿèƒ½å¤Ÿæ™ºèƒ½é€‰æ‹©ä¸åŒçš„å¤„ç†è·¯å¾„

**Neo4j + PostgreSQL**ï¼š

- **ä½œç”¨**ï¼šNeo4jå­˜å‚¨å®ä½“å…³ç³»å›¾ï¼ŒPostgreSQLå­˜å‚¨å‘é‡åµŒå…¥
- **ä¸ºä»€ä¹ˆéœ€è¦ä¸¤ä¸ªæ•°æ®åº“**ï¼šå›¾æ•°æ®åº“æ“…é•¿å…³ç³»æŸ¥è¯¢ï¼Œå‘é‡æ•°æ®åº“æ“…é•¿ç›¸ä¼¼æ€§æœç´¢ï¼Œå„æœ‰æ‰€é•¿

### 1.3 æ ¸å¿ƒåŠŸèƒ½

- **æ™ºèƒ½é—®ç­”**ï¼šè‡ªç„¶è¯­è¨€äº¤äº’ï¼Œç†è§£ç”¨æˆ·æ„å›¾å¹¶é€‰æ‹©åˆé€‚çš„æ£€ç´¢ç­–ç•¥
- **æœ¬åœ°çŸ¥è¯†æ£€ç´¢**ï¼šä¼˜å…ˆä»æœ¬åœ°æ–‡æ¡£åº“å¯»æ‰¾ç­”æ¡ˆï¼Œæ”¯æŒå‘é‡æ£€ç´¢å’Œå›¾è°±æ£€ç´¢
- **ç½‘ç»œæœç´¢è¡¥å……**ï¼šå½“æœ¬åœ°çŸ¥è¯†ç½®ä¿¡åº¦ä¸è¶³æ—¶ï¼Œè‡ªåŠ¨è°ƒç”¨ç½‘ç»œæœç´¢è¡¥å……ä¿¡æ¯
- **çŸ¥è¯†å›¾è°±ç®¡ç†**ï¼šåŠ¨æ€æ„å»ºå’Œæ›´æ–°çŸ¥è¯†å…³ç³»ï¼Œå­¦ä¹ æ–°çš„å®ä½“å’Œå…³ç³»
- **å®æ—¶æµå¼æ˜¾ç¤º**ï¼šç”¨æˆ·å¯ä»¥çœ‹åˆ°ç³»ç»Ÿçš„æ€è€ƒè¿‡ç¨‹å’Œä¿¡æ¯æ¥æº

### 1.4 ç¡®å®šæŠ€æœ¯æ ˆ

#### æ ¸å¿ƒæ¡†æ¶

- **LightRAG**: è½»é‡çº§RAGå¼•æ“ï¼Œè´Ÿè´£æ–‡æ¡£å¤„ç†å’Œå‘é‡æ£€ç´¢
- **Graphiti**: å®æ—¶çŸ¥è¯†å›¾è°±æ„å»ºå’Œç®¡ç†
- **LangGraph**: æ™ºèƒ½ä»£ç†å·¥ä½œæµç¼–æ’
- **Neo4j**: å›¾æ•°æ®åº“å­˜å‚¨
- **Streamlit**: å‰ç«¯ç•Œé¢å’Œç”¨æˆ·äº¤äº’

#### æ”¯æŒç»„ä»¶

- **PostgreSQL + pgvector**: å‘é‡å­˜å‚¨
- **OpenAI API**: LLMæœåŠ¡
- **Tavily API**: ç½‘ç»œæœç´¢æœåŠ¡

## 2. ç³»ç»Ÿæ¶æ„è®¾è®¡

### 2.1 æ•´ä½“å·¥ä½œæµç¨‹å›¾

```mermaid
graph TB
    Start([å¼€å§‹]) --> QueryAnalysis[æŸ¥è¯¢åˆ†æèŠ‚ç‚¹<br/>åˆ†æç”¨æˆ·æ„å›¾å’ŒæŸ¥è¯¢ç±»å‹]
  
    QueryAnalysis --> LightRAGRetrieval[LightRAGæ£€ç´¢èŠ‚ç‚¹<br/>æœ¬åœ°å‘é‡+çŸ¥è¯†å›¾è°±æ£€ç´¢]
    QueryAnalysis --> GraphitiQuery[GraphitiæŸ¥è¯¢èŠ‚ç‚¹<br/>å®æ—¶çŸ¥è¯†å›¾è°±æŸ¥è¯¢]
  
    LightRAGRetrieval --> QualityCheck{ç»“æœè´¨é‡è¯„ä¼°èŠ‚ç‚¹<br/>è¯„ä¼°ç½®ä¿¡åº¦}
    GraphitiQuery --> QualityCheck
  
    QualityCheck -->|ç½®ä¿¡åº¦ >= é˜ˆå€¼| AnswerGen[ç­”æ¡ˆç”ŸæˆèŠ‚ç‚¹<br/>æ•´åˆæœ¬åœ°çŸ¥è¯†ç”Ÿæˆç­”æ¡ˆ]
    QualityCheck -->|ç½®ä¿¡åº¦ < é˜ˆå€¼| WebSearch[ç½‘ç»œæœç´¢èŠ‚ç‚¹<br/>è¡¥å……å¤–éƒ¨ä¿¡æ¯]
  
    WebSearch --> AnswerGen
    AnswerGen --> GraphitiUpdate[Graphitiæ›´æ–°èŠ‚ç‚¹<br/>å¼‚æ­¥æ›´æ–°çŸ¥è¯†å›¾è°±]
    GraphitiUpdate --> StreamResult[æµå¼è¾“å‡ºç»“æœ]
    StreamResult --> End([ç»“æŸ])
  
    subgraph "æ•°æ®å­˜å‚¨å±‚"
        Neo4j[(Neo4jå›¾æ•°æ®åº“<br/>çŸ¥è¯†å›¾è°±å­˜å‚¨)]
        PostgreSQL[(PostgreSQL<br/>å‘é‡å­˜å‚¨)]
    end
  
    subgraph "å¤–éƒ¨æœåŠ¡"
        OpenAI[OpenAI API<br/>LLMæœåŠ¡]
        TavilyAPI[Tavily API<br/>ç½‘ç»œæœç´¢]
    end
  
    LightRAGRetrieval -.-> Neo4j
    LightRAGRetrieval -.-> PostgreSQL
    GraphitiQuery -.-> Neo4j
    WebSearch -.-> TavilyAPI
    AnswerGen -.-> OpenAI
    GraphitiUpdate -.-> Neo4j
  
    classDef nodeStyle fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
    classDef decisionStyle fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef dataStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef serviceStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
  
    class QueryAnalysis,LightRAGRetrieval,GraphitiQuery,AnswerGen,GraphitiUpdate,StreamResult nodeStyle
    class QualityCheck decisionStyle
    class Neo4j,PostgreSQL dataStyle
    class OpenAI,TavilyAPI serviceStyle
```

### 2.2 ç³»ç»Ÿæ¶æ„åˆ†å±‚

```mermaid
graph TB
    subgraph "ç”¨æˆ·ç•Œé¢å±‚"
        Streamlit[Streamlit Webç•Œé¢]
    end
  
    subgraph "æ™ºèƒ½ä»£ç†å±‚"
        LangGraph[LangGraphå·¥ä½œæµå¼•æ“]
        Agents[æ™ºèƒ½ä»£ç†èŠ‚ç‚¹é›†åˆ]
    end
  
    subgraph "RAGå¼•æ“å±‚" 
        LightRAG[LightRAGæ£€ç´¢å¼•æ“]
        Graphiti[GraphitiçŸ¥è¯†å›¾è°±]
    end
  
    subgraph "æ•°æ®å­˜å‚¨å±‚"
        Neo4j[Neo4jå›¾æ•°æ®åº“]
        PostgreSQL[PostgreSQLå‘é‡åº“] 
        Documents[æ–‡æ¡£å­˜å‚¨]
    end
  
    subgraph "å¤–éƒ¨æœåŠ¡å±‚"
        OpenAI[OpenAI LLM]
        TavilyAPI[Tavilyæœç´¢]
    end
  
    Streamlit <--> LangGraph
    LangGraph <--> Agents
    Agents <--> LightRAG
    Agents <--> Graphiti
    LightRAG <--> Neo4j
    LightRAG <--> PostgreSQL
    Graphiti <--> Neo4j
    Agents <--> OpenAI
    Agents <--> TavilyAPI
    LightRAG <--> Documents
```

### 2.3 è¯¦ç»†çš„å®ç°æ€è·¯è§£é‡Š

#### 2.3.1 ä¸ºä»€ä¹ˆéœ€è¦è¿™æ ·çš„æ¶æ„ï¼Ÿ

**åˆ†å±‚è®¾è®¡çš„ä¼˜åŠ¿**ï¼š

- **èŒè´£åˆ†ç¦»**ï¼šæ¯å±‚ä¸“æ³¨è‡ªå·±çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œä¾¿äºç»´æŠ¤å’Œæ‰©å±•
- **å¯æ›¿æ¢æ€§**ï¼šæ¯”å¦‚å¯ä»¥è½»æ¾å°†Streamlitæ›¿æ¢ä¸ºReactï¼Œæˆ–å°†OpenAIæ›¿æ¢ä¸ºå…¶ä»–LLM
- **å¹¶è¡Œå¤„ç†**ï¼šLightRAGå’ŒGraphitiå¯ä»¥å¹¶è¡Œæ£€ç´¢ï¼Œæé«˜å“åº”é€Ÿåº¦

**æ™ºèƒ½ä»£ç†çš„å¿…è¦æ€§**ï¼š

- **åŠ¨æ€å†³ç­–**ï¼šæ ¹æ®æŸ¥è¯¢ç±»å‹ï¼ˆäº‹å®æŸ¥è¯¢ã€å…³ç³»æŸ¥è¯¢ã€æ¨ç†æŸ¥è¯¢ï¼‰é€‰æ‹©ä¸åŒç­–ç•¥
- **è´¨é‡æ§åˆ¶**ï¼šè¯„ä¼°æ£€ç´¢ç»“æœè´¨é‡ï¼Œå†³å®šæ˜¯å¦éœ€è¦è¡¥å……æœç´¢
- **é”™è¯¯æ¢å¤**ï¼šå½“æŸä¸ªç»„ä»¶å¤±è´¥æ—¶ï¼Œèƒ½å¤Ÿé€‰æ‹©å¤‡ç”¨æ–¹æ¡ˆ

#### 2.3.2 æ•°æ®æµè½¬è¿‡ç¨‹è¯¦è§£

**ç¬¬ä¸€æ­¥ï¼šæŸ¥è¯¢ç†è§£**

```
ç”¨æˆ·è¾“å…¥ â†’ æŸ¥è¯¢åˆ†æèŠ‚ç‚¹ â†’ ç¡®å®šæŸ¥è¯¢ç±»å‹å’Œç­–ç•¥
```

- **ç›®çš„**ï¼šç†è§£ç”¨æˆ·çœŸæ­£æƒ³é—®ä»€ä¹ˆï¼Œæ˜¯å¯»æ‰¾å…·ä½“äº‹å®ã€æ¢ç´¢å…³ç³»ï¼Œè¿˜æ˜¯éœ€è¦æ¨ç†
- **å®ç°**ï¼šä½¿ç”¨LLMåˆ†ææŸ¥è¯¢æ„å›¾ï¼Œæå–å…³é”®å®ä½“å’Œå…³ç³»

**ç¬¬äºŒæ­¥ï¼šå¹¶è¡Œæ£€ç´¢**

```
æŸ¥è¯¢æ„å›¾ â†’ LightRAGæ£€ç´¢ + GraphitiæŸ¥è¯¢ â†’ è·å–å€™é€‰ç­”æ¡ˆ
```

- **LightRAGæ£€ç´¢**ï¼šåŸºäºå‘é‡ç›¸ä¼¼æ€§æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ç‰‡æ®µ
- **GraphitiæŸ¥è¯¢**ï¼šåŸºäºå®ä½“å…³ç³»æ‰¾åˆ°ç›¸å…³è¿æ¥
- **ä¸ºä»€ä¹ˆå¹¶è¡Œ**ï¼šä¸¤ç§æ–¹æ³•å„æœ‰ä¼˜åŠ¿ï¼Œå¹¶è¡Œå¯ä»¥è·å¾—æ›´å…¨é¢çš„ä¿¡æ¯

**ç¬¬ä¸‰æ­¥ï¼šè´¨é‡è¯„ä¼°**

```
æ£€ç´¢ç»“æœ â†’ ç½®ä¿¡åº¦è¯„ä¼° â†’ å†³å®šæ˜¯å¦éœ€è¦ç½‘ç»œæœç´¢
```

- **è¯„ä¼°æ ‡å‡†**ï¼šä¿¡æ¯å®Œæ•´æ€§ã€ç›¸å…³æ€§ã€æƒå¨æ€§
- **é˜ˆå€¼è®¾è®¡**ï¼šå¯é…ç½®çš„ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå¹³è¡¡å‡†ç¡®æ€§å’Œå“åº”é€Ÿåº¦

**ç¬¬å››æ­¥ï¼šç­”æ¡ˆç”Ÿæˆ**

```
ç»¼åˆä¿¡æ¯ â†’ LLMç”Ÿæˆç­”æ¡ˆ â†’ å¼•ç”¨ä¿¡æ¯æ¥æº
```

- **ä¿¡æ¯èåˆ**ï¼šå°†æœ¬åœ°çŸ¥è¯†å’Œç½‘ç»œæœç´¢ç»“æœæœ‰æœºç»“åˆ
- **æ¥æºæ ‡æ³¨**ï¼šæ¸…æ¥šæ ‡æ˜æ¯ä¸ªä¿¡æ¯ç‚¹çš„æ¥æºï¼Œå¢å¼ºå¯ä¿¡åº¦

**ç¬¬äº”æ­¥ï¼šçŸ¥è¯†æ›´æ–°**

```
æ–°ä¿¡æ¯ â†’ Graphitiå¼‚æ­¥æ›´æ–° â†’ ä¸°å¯ŒçŸ¥è¯†å›¾è°±
```

- **å­¦ä¹ æœºåˆ¶**ï¼šç³»ç»Ÿä¸æ–­ä»æ–°æŸ¥è¯¢ä¸­å­¦ä¹ ï¼Œæ›´æ–°çŸ¥è¯†å›¾è°±
- **å¼‚æ­¥å¤„ç†**ï¼šæ›´æ–°è¿‡ç¨‹ä¸å½±å“ç”¨æˆ·ä½“éªŒ## 3. LangGraphèŠ‚ç‚¹è¯¦ç»†å®ç°

### 3.1 æ¯ä¸ªèŠ‚ç‚¹çš„åŠŸèƒ½è§£é‡Šä¸ä»£ç å®ç°

#### 3.1.1 æŸ¥è¯¢åˆ†æèŠ‚ç‚¹ (QueryAnalysisNode)

**èŠ‚ç‚¹ä½œç”¨**ï¼šç†è§£ç”¨æˆ·çš„æŸ¥è¯¢æ„å›¾ï¼Œè¿™æ˜¯ç³»ç»Ÿçš„"æ™ºèƒ½å¤§è„‘"
**ä¸ºä»€ä¹ˆéœ€è¦**ï¼šä¸åŒç±»å‹çš„é—®é¢˜éœ€è¦ä¸åŒçš„å¤„ç†ç­–ç•¥

- äº‹å®æ€§é—®é¢˜ï¼š"ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ" â†’ éœ€è¦å®šä¹‰å’Œæ¦‚å¿µ
- å…³ç³»æ€§é—®é¢˜ï¼š"è°å‘æ˜äº†æœºå™¨å­¦ä¹ ï¼Ÿ" â†’ éœ€è¦äººç‰©å…³ç³»æŸ¥è¯¢
- æ¨ç†æ€§é—®é¢˜ï¼š"æœºå™¨å­¦ä¹ å¯¹æœªæ¥çš„å½±å“ï¼Ÿ" â†’ éœ€è¦ç»¼åˆåˆ†æ

```python
from typing import TypedDict
from langgraph import StateGraph
from langchain_openai import ChatOpenAI

class AgentState(TypedDict):
    user_query: str
    query_type: str
    processed_query: str
    local_results: list
    graph_context: dict
    web_results: list
    confidence_score: float
    need_web_search: bool
    final_answer: str
    sources: list

def query_analysis_node(state: AgentState):
    """åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œåˆ¤æ–­æŸ¥è¯¢ç±»å‹å’Œæ„å›¾"""
    llm = ChatOpenAI(model="gpt-4", temperature=0)
  
    # æŸ¥è¯¢æ„å›¾åˆ†ææç¤ºè¯
    analysis_prompt = f"""
    åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢çš„ç±»å‹å’Œæ„å›¾ï¼š
  
    æŸ¥è¯¢ï¼š{state["user_query"]}
  
    è¯·åˆ¤æ–­æŸ¥è¯¢ç±»å‹ï¼š
    1. FACTUAL: å¯»æ‰¾å…·ä½“äº‹å®æˆ–å®šä¹‰
    2. RELATIONAL: æ¢ç´¢å®ä½“é—´å…³ç³»
    3. ANALYTICAL: éœ€è¦åˆ†ææ¨ç†
    4. PROCEDURAL: å¯»æ‰¾æ“ä½œæ­¥éª¤
  
    åŒæ—¶æå–å…³é”®å®ä½“å’Œå…³é”®è¯ã€‚
  
    è¿”å›JSONæ ¼å¼ï¼š
    {{
        "query_type": "ç±»å‹",
        "key_entities": ["å®ä½“1", "å®ä½“2"],
        "key_concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2"],
        "processed_query": "ä¼˜åŒ–åçš„æŸ¥è¯¢"
    }}
    """
  
    result = llm.invoke(analysis_prompt)
    analysis = json.loads(result.content)
  
    return {
        "query_type": analysis["query_type"],
        "processed_query": analysis["processed_query"],
        "key_entities": analysis["key_entities"],
        "key_concepts": analysis["key_concepts"]
    }
```

#### 3.1.2 LightRAGæ£€ç´¢èŠ‚ç‚¹

**èŠ‚ç‚¹ä½œç”¨**ï¼šä»æœ¬åœ°æ–‡æ¡£åº“è¿›è¡Œå‘é‡æ£€ç´¢å’ŒçŸ¥è¯†å›¾è°±æ£€ç´¢
**ä¸ºä»€ä¹ˆé‡è¦**ï¼šæœ¬åœ°çŸ¥è¯†æ˜¯ç³»ç»Ÿçš„åŸºç¡€ï¼Œä¼˜å…ˆä½¿ç”¨å¯ä¿¡çš„æœ¬åœ°ä¿¡æ¯

```python
from lightrag import LightRAG

def lightrag_retrieval_node(state: AgentState):
    """ä»æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯"""
  
    # åˆå§‹åŒ–LightRAGå®¢æˆ·ç«¯
    lightrag_client = LightRAG(
        working_dir="./rag_storage",
        kv_storage="JsonKVStorage",
        vector_storage="NanoVectorDBStorage", 
        graph_storage="Neo4jStorage",
        neo4j_config={
            "uri": "bolt://localhost:7687",
            "username": "neo4j", 
            "password": "password"
        }
    )
  
    # æ··åˆæ£€ç´¢ï¼šå‘é‡æ£€ç´¢ + å›¾æ£€ç´¢
    vector_results = lightrag_client.query(
        state["processed_query"],
        param=QueryParam(mode="local")  # çº¯å‘é‡æ£€ç´¢
    )
  
    graph_results = lightrag_client.query(
        state["processed_query"], 
        param=QueryParam(mode="global")  # å›¾æ£€ç´¢
    )
  
    # è®¡ç®—æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§åˆ†æ•°
    relevance_score = calculate_relevance_score(
        vector_results, graph_results, state["processed_query"]
    )
  
    return {
        "local_results": {
            "vector_results": vector_results,
            "graph_results": graph_results,
            "combined_results": combine_results(vector_results, graph_results)
        },
        "retrieval_score": relevance_score
    }

def calculate_relevance_score(vector_results, graph_results, query):
    """è®¡ç®—æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§åˆ†æ•°"""
    # åŸºäºç»“æœæ•°é‡ã€ç›¸ä¼¼åº¦åˆ†æ•°ã€å†…å®¹è´¨é‡ç­‰è®¡ç®—ç»¼åˆåˆ†æ•°
    vector_score = len(vector_results.split('\n')) * 0.6
    graph_score = len(graph_results.split('\n')) * 0.4
  
    # ç®€åŒ–çš„ç½®ä¿¡åº¦è®¡ç®—ï¼Œå®é™…åº”è¯¥æ›´å¤æ‚
    total_score = min((vector_score + graph_score) / 10, 1.0)
    return total_score
```

#### 3.1.3 GraphitiçŸ¥è¯†å›¾è°±æŸ¥è¯¢èŠ‚ç‚¹

**èŠ‚ç‚¹ä½œç”¨**ï¼šä»åŠ¨æ€çŸ¥è¯†å›¾è°±ä¸­æŸ¥è¯¢å®ä½“å…³ç³»å’Œäº‹å®
**ä¸ºä»€ä¹ˆéœ€è¦**ï¼šè¡¥å……LightRAGçš„å…³ç³»æ¨ç†èƒ½åŠ›ï¼Œè·å–æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡

```python
from graphiti import Graphiti

def graphiti_query_node(state: AgentState):
    """æŸ¥è¯¢GraphitiçŸ¥è¯†å›¾è°±è·å–å…³ç³»ä¿¡æ¯"""
  
    # åˆå§‹åŒ–Graphitiå®¢æˆ·ç«¯
    graphiti_client = Graphiti(
        neo4j_config={
            "uri": "bolt://localhost:7687",
            "username": "neo4j",
            "password": "password"
        }
    )
  
    # æœç´¢ç›¸å…³å®ä½“
    entities = graphiti_client.search_nodes(
        query=state["processed_query"],
        limit=10
    )
  
    # æœç´¢ç›¸å…³äº‹å®å’Œå…³ç³»
    facts = graphiti_client.search_facts(
        query=state["processed_query"],
        limit=20
    )
  
    # æ„å»ºå…³ç³»ä¸Šä¸‹æ–‡
    relationship_context = build_relationship_context(entities, facts)
  
    return {
        "graph_entities": entities,
        "graph_facts": facts, 
        "relationship_context": relationship_context
    }

def build_relationship_context(entities, facts):
    """ä»å®ä½“å’Œäº‹å®æ„å»ºå…³ç³»ä¸Šä¸‹æ–‡"""
    context = {
        "entity_summary": f"å‘ç° {len(entities)} ä¸ªç›¸å…³å®ä½“",
        "fact_summary": f"å‘ç° {len(facts)} ä¸ªç›¸å…³äº‹å®",
        "key_relationships": [],
        "temporal_info": []
    }
  
    for fact in facts:
        if hasattr(fact, 'relationship_type'):
            context["key_relationships"].append({
                "source": fact.source_entity,
                "relation": fact.relationship_type,
                "target": fact.target_entity
            })
  
    return context
```

#### 3.1.4 ç»“æœè´¨é‡è¯„ä¼°èŠ‚ç‚¹

**èŠ‚ç‚¹ä½œç”¨**ï¼šè¯„ä¼°æœ¬åœ°æ£€ç´¢ç»“æœçš„è´¨é‡ï¼Œå†³å®šæ˜¯å¦éœ€è¦ç½‘ç»œæœç´¢
**ä¸ºä»€ä¹ˆé‡è¦**ï¼šé¿å…ä¸å¿…è¦çš„ç½‘ç»œæœç´¢ï¼Œæé«˜å“åº”é€Ÿåº¦ï¼›ç¡®ä¿ä¿¡æ¯å……åˆ†æ€§

```python
def quality_assessment_node(state: AgentState):
    """è¯„ä¼°æ£€ç´¢ç»“æœè´¨é‡ï¼Œå†³å®šæ˜¯å¦éœ€è¦ç½‘ç»œæœç´¢"""
  
    # ç½®ä¿¡åº¦è¯„ä¼°æ ‡å‡†
    confidence_factors = {
        "retrieval_score": state.get("retrieval_score", 0) * 0.3,
        "entity_coverage": evaluate_entity_coverage(state) * 0.2,
        "content_completeness": evaluate_content_completeness(state) * 0.3,
        "source_authority": evaluate_source_authority(state) * 0.2
    }
  
    total_confidence = sum(confidence_factors.values())
  
    # åŠ¨æ€é˜ˆå€¼è®¾ç½®
    if state["query_type"] == "FACTUAL":
        threshold = 0.7  # äº‹å®æŸ¥è¯¢è¦æ±‚è¾ƒé«˜ç½®ä¿¡åº¦
    elif state["query_type"] == "RELATIONAL": 
        threshold = 0.6  # å…³ç³»æŸ¥è¯¢ä¸­ç­‰ç½®ä¿¡åº¦
    else:
        threshold = 0.5  # åˆ†ææŸ¥è¯¢è¾ƒä½ç½®ä¿¡åº¦
  
    need_web_search = total_confidence < threshold
  
    return {
        "confidence_score": total_confidence,
        "confidence_breakdown": confidence_factors,
        "need_web_search": need_web_search,
        "assessment_reason": f"ç½®ä¿¡åº¦ {total_confidence:.2f} {'<' if need_web_search else '>='} é˜ˆå€¼ {threshold}"
    }

def evaluate_entity_coverage(state):
    """è¯„ä¼°å®ä½“è¦†ç›–åº¦"""
    expected_entities = state.get("key_entities", [])
    found_entities = state.get("graph_entities", [])
  
    if not expected_entities:
        return 1.0
  
    coverage = len(set(expected_entities) & set(found_entities)) / len(expected_entities)
    return coverage

def evaluate_content_completeness(state):
    """è¯„ä¼°å†…å®¹å®Œæ•´æ€§"""
    local_results = state.get("local_results", {})
    vector_content = local_results.get("vector_results", "")
    graph_content = local_results.get("graph_results", "")
  
    # ç®€åŒ–çš„å®Œæ•´æ€§è¯„ä¼°
    total_length = len(vector_content) + len(graph_content)
    completeness = min(total_length / 1000, 1.0)  # å‡è®¾1000å­—ç¬¦ä¸ºå®Œæ•´
    return completeness
```

#### 3.1.5 ç½‘ç»œæœç´¢èŠ‚ç‚¹

**èŠ‚ç‚¹ä½œç”¨**ï¼šå½“æœ¬åœ°ä¿¡æ¯ä¸è¶³æ—¶ï¼Œä»ç½‘ç»œè·å–è¡¥å……ä¿¡æ¯
**ä»€ä¹ˆæ—¶å€™è§¦å‘**ï¼šè´¨é‡è¯„ä¼°èŠ‚ç‚¹åˆ¤å®šéœ€è¦è¡¥å……ä¿¡æ¯æ—¶

```python
from tavily import TavilySearchAPIWrapper

def web_search_node(state: AgentState):
    """ç½‘ç»œæœç´¢è¡¥å……ä¿¡æ¯"""
  
    # åªæœ‰å½“éœ€è¦ç½‘ç»œæœç´¢æ—¶æ‰æ‰§è¡Œ
    if not state.get("need_web_search", False):
        return {"web_results": []}
  
    # åˆå§‹åŒ–Tavilyæœç´¢
    tavily_search = TavilySearchAPIWrapper(
        tavily_api_key=os.getenv("TAVILY_API_KEY")
    )
  
    # åŸºäºæŸ¥è¯¢ç±»å‹ä¼˜åŒ–æœç´¢ç­–ç•¥
    if state["query_type"] == "FACTUAL":
        search_mode = "factual"
        max_results = 3
    elif state["query_type"] == "ANALYTICAL":
        search_mode = "comprehensive" 
        max_results = 5
    else:
        search_mode = "balanced"
        max_results = 4
  
    search_results = tavily_search.search(
        query=state["processed_query"],
        search_depth=search_mode,
        max_results=max_results,
        include_answer=True,
        include_raw_content=False
    )
  
    # å¤„ç†æœç´¢ç»“æœ
    processed_results = []
    for result in search_results:
        processed_results.append({
            "title": result.get("title", ""),
            "content": result.get("content", ""),
            "url": result.get("url", ""),
            "score": result.get("score", 0),
            "source_type": "web_search"
        })
  
    return {
        "web_results": processed_results,
        "web_search_summary": f"ä»ç½‘ç»œè·å– {len(processed_results)} ä¸ªè¡¥å……ä¿¡æ¯"
    }
  
    answer = llm.invoke(
        f"åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”é—®é¢˜ï¼š{state['user_query']}\n\n{context}"
    )
  
    # å¼‚æ­¥æ›´æ–°çŸ¥è¯†å›¾è°±
    asyncio.create_task(
        graphiti_client.add_episode(
            name="QA Session",
            episode_body=f"Q: {state['user_query']}\nA: {answer}",
            source=EpisodeType.message
        )
    )
  
    return {"final_answer": answer}
```

#### 2.2.2 æ¡ä»¶è¾¹é€»è¾‘

```python
def should_web_search(state: AgentState) -> str:
    """å†³å®šæ˜¯å¦éœ€è¦ç½‘ç»œæœç´¢"""
    if state["need_web_search"]:
        return "web_search"
    else:
        return "answer_generation"

def route_after_web_search(state: AgentState) -> str:
    """ç½‘ç»œæœç´¢åçš„è·¯ç”±"""
    return "answer_generation"
```

## 3. æŠ€æœ¯å®ç°è¯¦æƒ…

### 3.1 LightRAG é…ç½®ä¸é›†æˆ

#### 3.1.1 åŸºç¡€é…ç½®

```python
from lightrag import LightRAG, QueryParam
from lightrag.llm.openai import gpt_4o_mini_complete, openai_embed
from lightrag.utils import EmbeddingFunc

# åˆå§‹åŒ– LightRAG
lightrag_client = LightRAG(
    working_dir="./rag_storage",
    llm_model_func=gpt_4o_mini_complete,
    embedding_func=EmbeddingFunc(
        embedding_dim=3072,
        max_token_size=8192,
        func=lambda texts: openai_embed(
            texts,
            model="text-embedding-3-large",
            api_key=os.getenv("OPENAI_API_KEY")
        )
    ),
    graph_storage="Neo4JStorage",  # ä½¿ç”¨Neo4jä½œä¸ºå›¾å­˜å‚¨
    vector_storage="PGVectorStorage",  # ä½¿ç”¨PostgreSQLå‘é‡å­˜å‚¨
    chunk_token_size=1200,
    chunk_overlap_token_size=100,
    max_parallel_insert=3,
    llm_model_max_async=12
)
```

#### 3.1.2 æ–‡æ¡£å¤„ç†å’Œç´¢å¼•

```python
async def ingest_documents(documents_path: str):
    """æ‰¹é‡å¤„ç†æ–‡æ¡£å¹¶å»ºç«‹ç´¢å¼•"""
    await lightrag_client.initialize_storages()
  
    # è¯»å–æ–‡æ¡£
    documents = load_documents_from_path(documents_path)
  
    # æ‰¹é‡æ’å…¥
    for doc_batch in batch_documents(documents, batch_size=10):
        await lightrag_client.insert_batch(doc_batch)
  
    print(f"å·²å¤„ç† {len(documents)} ä¸ªæ–‡æ¡£")
```

### 3.2 Graphiti çŸ¥è¯†å›¾è°±ç®¡ç†

#### 3.2.1 è¿æ¥é…ç½®

```python
from graphiti_core import Graphiti
from graphiti_core.nodes import EpisodeType

# åˆå§‹åŒ– Graphiti å®¢æˆ·ç«¯
graphiti_client = Graphiti(
    neo4j_uri=os.getenv('NEO4J_URI', 'bolt://localhost:7687'),
    neo4j_user=os.getenv('NEO4J_USER', 'neo4j'),
    neo4j_password=os.getenv('NEO4J_PASSWORD', 'password')
)

await graphiti_client.build_indices_and_constraints()
```

#### 3.2.2 åŠ¨æ€çŸ¥è¯†æ›´æ–°

```python
async def update_knowledge_graph(query: str, answer: str, context: dict):
    """æ ¹æ®é—®ç­”ç»“æœåŠ¨æ€æ›´æ–°çŸ¥è¯†å›¾è°±"""
  
    # æ·»åŠ é—®ç­”è®°å½•ä½œä¸ºæ–°çš„ episode
    await graphiti_client.add_episode(
        name=f"QA_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        episode_body=f"ç”¨æˆ·é—®é¢˜: {query}\nç³»ç»Ÿå›ç­”: {answer}",
        source=EpisodeType.text,
        reference_time=datetime.now(timezone.utc),
        source_description="æ™ºèƒ½é—®ç­”ç³»ç»Ÿ"
    )
  
    # æå–æ–°çš„å®ä½“å’Œå…³ç³»
    if context.get("new_entities"):
        for entity_data in context["new_entities"]:
            await graphiti_client.create_entity(
                entity_data["name"],
                entity_data["properties"]
            )
```

### 3.3 LangGraph å·¥ä½œæµç¼–æ’

#### 3.3.1 çŠ¶æ€å®šä¹‰

```python
from typing_extensions import TypedDict
from typing import List, Optional

class AgentState(TypedDict):
    user_query: str
    processed_query: str
    query_type: str
    local_results: List[dict]
    graph_entities: List[dict]
    graph_facts: List[dict]
    relationship_context: str
    confidence_score: float
    need_web_search: bool
    web_results: Optional[List[dict]]
    final_answer: str
    session_id: str
```

#### 3.3.2 å›¾æ„å»º

```python
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver

# æ„å»ºå·¥ä½œæµ
workflow = StateGraph(AgentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("query_analysis", query_analysis_node)
workflow.add_node("lightrag_retrieval", lightrag_retrieval_node)  
workflow.add_node("graphiti_query", graphiti_query_node)
workflow.add_node("quality_assessment", quality_assessment_node)
workflow.add_node("web_search", web_search_node)
workflow.add_node("answer_generation", answer_generation_node)

# æ·»åŠ è¾¹
workflow.add_edge(START, "query_analysis")
workflow.add_edge("query_analysis", "lightrag_retrieval")
workflow.add_edge("query_analysis", "graphiti_query")
workflow.add_edge(["lightrag_retrieval", "graphiti_query"], "quality_assessment")
workflow.add_conditional_edges(
    "quality_assessment",
    should_web_search,
    {"web_search": "web_search", "answer_generation": "answer_generation"}
)
workflow.add_edge("web_search", "answer_generation")
workflow.add_edge("answer_generation", END)

# ç¼–è¯‘å›¾
memory = MemorySaver()
app = workflow.compile(checkpointer=memory)
```

### 3.4 Streamlit å‰ç«¯å®ç°

#### 3.4.1 ä¸»ç•Œé¢è®¾è®¡

```python
import streamlit as st
import asyncio
from datetime import datetime

st.set_page_config(
    page_title="æ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ¤– æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
st.markdown("åŸºäº Agentic RAG + LightRAG + Graphiti çš„æ™ºèƒ½é—®ç­”")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("ç³»ç»Ÿé…ç½®")
  
    # æ£€ç´¢é…ç½®
    retrieval_mode = st.selectbox(
        "æ£€ç´¢æ¨¡å¼",
        ["hybrid", "local", "global"],
        index=0
    )
  
    confidence_threshold = st.slider(
        "ç½®ä¿¡åº¦é˜ˆå€¼",
        min_value=0.0,
        max_value=1.0,
        value=0.7
    )
  
    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    st.header("ç³»ç»ŸçŠ¶æ€")
    if st.button("æ£€æŸ¥è¿æ¥çŠ¶æ€"):
        check_system_status()
```

#### 3.4.2 å®æ—¶æµå¼æ˜¾ç¤º

```python
@st.fragment(run_every=0.1)
def stream_response():
    """æµå¼æ˜¾ç¤ºå“åº”è¿‡ç¨‹"""
    if "current_stream" in st.session_state:
        stream = st.session_state.current_stream
      
        progress_container = st.container()
        response_container = st.container()
      
        with progress_container:
            col1, col2, col3 = st.columns(3)
          
            with col1:
                st.info("ğŸ“Š æŸ¥è¯¢åˆ†æ")
                if stream.get("query_analysis_done"):
                    st.success("âœ… å®Œæˆ")
                else:
                    st.warning("â³ å¤„ç†ä¸­...")
          
            with col2:
                st.info("ğŸ” çŸ¥è¯†æ£€ç´¢")
                if stream.get("retrieval_done"):
                    st.success(f"âœ… æ‰¾åˆ°{stream.get('result_count', 0)}æ¡ç»“æœ")
                else:
                    st.warning("â³ æœç´¢ä¸­...")
          
            with col3:
                st.info("ğŸ§  ç­”æ¡ˆç”Ÿæˆ")
                if stream.get("generation_done"):
                    st.success("âœ… å®Œæˆ")
                else:
                    st.warning("â³ ç”Ÿæˆä¸­...")
      
        with response_container:
            if stream.get("partial_answer"):
                st.write_stream(stream["partial_answer"])

async def process_query(query: str):
    """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
    session_id = st.session_state.get("session_id", str(uuid.uuid4()))
  
    # åˆå§‹åŒ–æµå¼çŠ¶æ€
    st.session_state.current_stream = {
        "query_analysis_done": False,
        "retrieval_done": False,
        "generation_done": False,
        "partial_answer": "",
        "result_count": 0
    }
  
    config = {"configurable": {"thread_id": session_id}}
  
    # æµå¼æ‰§è¡Œå·¥ä½œæµ
    async for event in app.astream(
        {"user_query": query, "session_id": session_id},
        config=config
    ):
        node_name = list(event.keys())[0]
        node_output = event[node_name]
      
        # æ›´æ–°è¿›åº¦çŠ¶æ€
        if node_name == "query_analysis":
            st.session_state.current_stream["query_analysis_done"] = True
        elif node_name in ["lightrag_retrieval", "graphiti_query"]:
            st.session_state.current_stream["retrieval_done"] = True
            st.session_state.current_stream["result_count"] = len(
                node_output.get("local_results", [])
            )
        elif node_name == "answer_generation":
            st.session_state.current_stream["generation_done"] = True
            st.session_state.current_stream["partial_answer"] = node_output.get("final_answer", "")
```

#### 3.4.3 äº¤äº’å¼ç»„ä»¶

```python
def main():
    """ä¸»ç•Œé¢é€»è¾‘"""
  
    # æŸ¥è¯¢è¾“å…¥
    query = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")
  
    if query:
        with st.chat_message("user"):
            st.write(query)
      
        with st.chat_message("assistant"):
            # ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œ
            response = asyncio.run(process_query(query))
          
            # æ˜¾ç¤ºç­”æ¡ˆ
            st.write(response.get("final_answer", ""))
          
            # æ˜¾ç¤ºæ¥æºä¿¡æ¯
            with st.expander("ğŸ“š ä¿¡æ¯æ¥æº"):
                if response.get("local_results"):
                    st.subheader("æœ¬åœ°çŸ¥è¯†åº“")
                    for result in response["local_results"]:
                        st.write(f"- {result.get('content', '')[:200]}...")
              
                if response.get("web_results"):
                    st.subheader("ç½‘ç»œæœç´¢")
                    for result in response["web_results"]:
                        st.write(f"- [{result.get('title', '')}]({result.get('url', '')})")
          
            # æ˜¾ç¤ºçŸ¥è¯†å›¾è°±
            with st.expander("ğŸ•¸ï¸ ç›¸å…³å®ä½“å…³ç³»"):
                display_knowledge_graph(response.get("graph_entities", []))

def display_knowledge_graph(entities):
    """æ˜¾ç¤ºçŸ¥è¯†å›¾è°±å¯è§†åŒ–"""
    if entities:
        # æ„å»ºå›¾æ•°æ®
        nodes = []
        edges = []
      
        for entity in entities:
            nodes.append({
                "id": entity["uuid"],
                "label": entity["name"],
                "title": entity.get("summary", "")
            })
      
        # ä½¿ç”¨streamlit-agraphæ˜¾ç¤º
        try:
            from streamlit_agraph import agraph, Node, Edge, Config
          
            config = Config(width=600, height=400, directed=True)
            agraph(nodes=nodes, edges=edges, config=config)
        except ImportError:
            st.info("å®‰è£… streamlit-agraph ä»¥æŸ¥çœ‹å›¾è°±å¯è§†åŒ–")
            for entity in entities:
                st.write(f"- **{entity['name']}**: {entity.get('summary', '')}")

if __name__ == "__main__":
    main()
```

## 4. æ•°æ®åº“è®¾è®¡

### 4.1 Neo4j å›¾æ•°æ®åº“

#### 4.1.1 èŠ‚ç‚¹ç±»å‹

```cypher
// æ–‡æ¡£èŠ‚ç‚¹
CREATE CONSTRAINT document_id IF NOT EXISTS FOR (d:Document) REQUIRE d.id IS UNIQUE;

// å®ä½“èŠ‚ç‚¹  
CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:Entity) REQUIRE e.id IS UNIQUE;

// é—®ç­”è®°å½•èŠ‚ç‚¹
CREATE CONSTRAINT qa_session_id IF NOT EXISTS FOR (q:QASession) REQUIRE q.id IS UNIQUE;
```

#### 4.1.2 å…³ç³»ç±»å‹

```cypher
// æ–‡æ¡£åŒ…å«å®ä½“
(:Document)-[:CONTAINS]->(:Entity)

// å®ä½“é—´å…³ç³»
(:Entity)-[:RELATES_TO]->(:Entity)

// é—®ç­”å¼•ç”¨å®ä½“
(:QASession)-[:REFERENCES]->(:Entity)

// æ–‡æ¡£å¼•ç”¨å…³ç³»
(:Document)-[:REFERENCES]->(:Document)
```

### 4.2 PostgreSQL å‘é‡å­˜å‚¨

#### 4.2.1 è¡¨ç»“æ„è®¾è®¡

```sql
-- æ–‡æ¡£å—è¡¨
CREATE TABLE IF NOT EXISTS document_chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id VARCHAR(255) NOT NULL,
    chunk_index INTEGER NOT NULL,
    content TEXT NOT NULL,
    content_vector vector(3072),  -- OpenAI text-embedding-3-large
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å®ä½“å‘é‡è¡¨
CREATE TABLE IF NOT EXISTS entity_embeddings (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    entity_id VARCHAR(255) NOT NULL,
    entity_name VARCHAR(500) NOT NULL,
    description TEXT,
    embedding vector(3072),
    metadata JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- åˆ›å»ºå‘é‡ç´¢å¼•
CREATE INDEX IF NOT EXISTS document_chunks_vector_idx 
ON document_chunks USING ivfflat (content_vector vector_cosine_ops) 
WITH (lists = 100);

CREATE INDEX IF NOT EXISTS entity_embeddings_vector_idx 
ON entity_embeddings USING ivfflat (embedding vector_cosine_ops) 
WITH (lists = 100);
```

## 5. éƒ¨ç½²é…ç½®

### 5.1 Docker Compose é…ç½®

```yaml
version: '3.8'

services:
  # ä¸»åº”ç”¨
  qa-system:
    build: .
    ports:
      - "8501:8501"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=qa_system
    depends_on:
      - neo4j
      - postgres
    volumes:
      - ./data:/app/data
      - ./rag_storage:/app/rag_storage

  # Neo4j å›¾æ•°æ®åº“
  neo4j:
    image: neo4j:5.22.0
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD}
      - NEO4J_PLUGINS=["apoc"]
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs

  # PostgreSQL + pgvector
  postgres:
    image: pgvector/pgvector:pg16
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=qa_system
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql

volumes:
  neo4j_data:
  neo4j_logs:
  postgres_data:
```

### 5.2 ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env æ–‡ä»¶
OPENAI_API_KEY=sk-your-openai-api-key
NEO4J_PASSWORD=your-neo4j-password
POSTGRES_PASSWORD=your-postgres-password
TAVILY_API_KEY=your-tavily-api-key

# LightRAG é…ç½®
LIGHTRAG_WORKING_DIR=./rag_storage
LIGHTRAG_CHUNK_SIZE=1200
LIGHTRAG_CHUNK_OVERLAP=100

# Graphiti é…ç½®  
GRAPHITI_MODEL_NAME=gpt-4o-mini
GRAPHITI_EMBEDDING_MODEL=text-embedding-3-large

# ç³»ç»Ÿé…ç½®
CONFIDENCE_THRESHOLD=0.7
MAX_RETRIEVAL_RESULTS=10
WEB_SEARCH_RESULTS=5
```

## 6. å¼€å‘æŒ‡å—

### 6.1 é¡¹ç›®ç»“æ„

```
qa_system/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents/                 # LangGraphèŠ‚ç‚¹å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ query_analysis.py
â”‚   â”‚   â”œâ”€â”€ retrieval.py
â”‚   â”‚   â”œâ”€â”€ quality_assessment.py
â”‚   â”‚   â””â”€â”€ answer_generation.py
â”‚   â”œâ”€â”€ core/                   # æ ¸å¿ƒç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ lightrag_client.py
â”‚   â”‚   â”œâ”€â”€ graphiti_client.py
â”‚   â”‚   â””â”€â”€ workflow.py
â”‚   â”œâ”€â”€ ui/                     # Streamlitç•Œé¢
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â””â”€â”€ config/                 # é…ç½®æ–‡ä»¶
â”‚       â”œâ”€â”€ settings.py
â”‚       â””â”€â”€ prompts.py
â”œâ”€â”€ data/                       # æ•°æ®æ–‡ä»¶
â”‚   â””â”€â”€ documents/
â”œâ”€â”€ scripts/                    # è„šæœ¬å·¥å…·
â”‚   â”œâ”€â”€ ingest_documents.py
â”‚   â””â”€â”€ setup_database.py
â”œâ”€â”€ tests/                      # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### 6.2 å¯åŠ¨æµç¨‹

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd qa_system

# 2. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶

# 3. å¯åŠ¨æœåŠ¡
docker-compose up -d

# 4. åˆå§‹åŒ–æ•°æ®åº“
python scripts/setup_database.py

# 5. å¯¼å…¥æ–‡æ¡£
python scripts/ingest_documents.py --path ./data/documents

# 6. å¯åŠ¨åº”ç”¨
streamlit run app/ui/main.py
```

### 6.3 æ‰©å±•å¼€å‘

#### 6.3.1 æ·»åŠ æ–°çš„æ£€ç´¢èŠ‚ç‚¹

```python
def custom_retrieval_node(state: AgentState):
    """è‡ªå®šä¹‰æ£€ç´¢èŠ‚ç‚¹"""
    # å®ç°è‡ªå®šä¹‰æ£€ç´¢é€»è¾‘
    pass

# åœ¨å·¥ä½œæµä¸­æ·»åŠ èŠ‚ç‚¹
workflow.add_node("custom_retrieval", custom_retrieval_node)
```

#### 6.3.2 è‡ªå®šä¹‰æ¡ä»¶è¾¹

```python
def custom_routing_logic(state: AgentState) -> str:
    """è‡ªå®šä¹‰è·¯ç”±é€»è¾‘"""
    if state["custom_condition"]:
        return "custom_node"
    else:
        return "default_node"
```

## 7. ç›‘æ§å’Œç»´æŠ¤

### 7.1 æ€§èƒ½ç›‘æ§

- **å“åº”æ—¶é—´ç›‘æ§**: è®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œæ—¶é—´
- **å‡†ç¡®ç‡è¯„ä¼°**: å®šæœŸè¯„ä¼°ç­”æ¡ˆè´¨é‡
- **èµ„æºä½¿ç”¨ç›‘æ§**: ç›‘æ§å†…å­˜ã€CPUä½¿ç”¨æƒ…å†µ

### 7.2 æ—¥å¿—é…ç½®

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('qa_system.log'),
        logging.StreamHandler()
    ]
)
```

### 7.3 æ•°æ®å¤‡ä»½

```bash
# Neo4j å¤‡ä»½
docker exec neo4j neo4j-admin database dump neo4j --to-path=/backups

# PostgreSQL å¤‡ä»½  
docker exec postgres pg_dump -U postgres qa_system > backup.sql
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v2.0
**æœ€åæ›´æ–°**: 2024-01-XX
**æŠ€æœ¯æ ˆ**: LightRAG + Graphiti + LangGraph + Neo4j + Streamlit
