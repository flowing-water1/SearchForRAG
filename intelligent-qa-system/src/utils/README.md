# å·¥å…·æ¨¡å—æŠ€æœ¯æ–‡æ¡£

> è¿”å› [é¡¹ç›®æ¦‚è§ˆæ–‡æ¡£](../../TECHNICAL_REFERENCE.md)

## ğŸ“ ç›¸å…³æ–‡æ¡£å¯¼èˆª
- **[æ ¸å¿ƒæ¨¡å—æ–‡æ¡£](../core/README.md)** - æŸ¥çœ‹å·¥å…·æ¨¡å—æ”¯æŒçš„æ ¸å¿ƒé…ç½®å’ŒçŠ¶æ€ç®¡ç†
- **[å·¥ä½œæµèŠ‚ç‚¹æ–‡æ¡£](../agents/README.md)** - æŸ¥çœ‹å·¥å…·æ¨¡å—åœ¨å„èŠ‚ç‚¹ä¸­çš„ä½¿ç”¨
- **[é¡¹ç›®æ ¹ç›®å½•](../../TECHNICAL_REFERENCE.md)** - è¿”å›é¡¹ç›®å®Œæ•´æ¦‚è§ˆ

## ğŸ”— å·¥å…·ä¸ç³»ç»Ÿé›†æˆ
- [é…ç½®ç³»ç»Ÿ](../core/README.md#1-é…ç½®ç®¡ç†ç³»ç»Ÿ-configpy) - å·¥å…·æ¨¡å—çš„é…ç½®æ¥æº
- [AgentStateæ¥å£](../core/README.md#2-çŠ¶æ€å®šä¹‰-statepy) - å·¥å…·æ¨¡å—å¤„ç†çš„æ•°æ®ç»“æ„
- [æŸ¥è¯¢åˆ†æèŠ‚ç‚¹](../agents/README.md#1-æŸ¥è¯¢åˆ†æèŠ‚ç‚¹-query_analysispy) - ä½¿ç”¨simple_loggerå’Œerror_handling
- [æ£€ç´¢èŠ‚ç‚¹](../agents/README.md#2-lightragæ£€ç´¢èŠ‚ç‚¹-lightrag_retrievalpy) - æ ¸å¿ƒä¾èµ–lightrag_client
- [è´¨é‡è¯„ä¼°èŠ‚ç‚¹](../agents/README.md#3-è´¨é‡è¯„ä¼°èŠ‚ç‚¹-quality_assessmentpy) - ä½¿ç”¨helpersæ¨¡å—è¿›è¡Œè¯„ä¼°
- [ç­”æ¡ˆç”ŸæˆèŠ‚ç‚¹](../agents/README.md#5-ç­”æ¡ˆç”ŸæˆèŠ‚ç‚¹-answer_generationpy) - ä½¿ç”¨advanced_loggingå’Œhelpers

---

## æ¨¡å—æ¦‚è¿°

å·¥å…·æ¨¡å— (src/utils/) æä¾›äº†æ™ºèƒ½é—®ç­”ç³»ç»Ÿçš„æ ¸å¿ƒæ”¯æ’‘åŠŸèƒ½ï¼ŒåŒ…æ‹¬å®¢æˆ·ç«¯å°è£…ã€æ—¥å¿—ç³»ç»Ÿã€é”™è¯¯å¤„ç†ã€ç³»ç»Ÿç›‘æ§ç­‰é‡è¦ç»„ä»¶ã€‚è¿™äº›å·¥å…·ç¡®ä¿ç³»ç»Ÿçš„å¯é æ€§ã€å¯è§‚æµ‹æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

### æ¨¡å—ç»“æ„
```
src/utils/
â”œâ”€â”€ __init__.py                 # æ¨¡å—åˆå§‹åŒ–
â”œâ”€â”€ lightrag_client.py          # LightRAGå®¢æˆ·ç«¯å°è£…
â”œâ”€â”€ kg_llm_client.py           # çŸ¥è¯†å›¾è°±LLMå®¢æˆ·ç«¯
â”œâ”€â”€ document_processor.py      # æ–‡æ¡£å¤„ç†å™¨
â”œâ”€â”€ simple_logger.py           # ç®€å•æ—¥å¿—ç³»ç»Ÿ
â”œâ”€â”€ advanced_logging.py        # é«˜çº§æ—¥å¿—ç³»ç»Ÿ
â”œâ”€â”€ error_handling.py          # é”™è¯¯å¤„ç†æ¡†æ¶
â”œâ”€â”€ system_monitoring.py       # ç³»ç»Ÿç›‘æ§
â””â”€â”€ helpers.py                 # é€šç”¨è¾…åŠ©å‡½æ•°
```

### ä¾èµ–å…³ç³»å±‚æ¬¡
```
simple_logger.py (åŸºç¡€å±‚)
    â†“
advanced_logging.py + error_handling.py (ä¸­é—´å±‚)
    â†“  
system_monitoring.py + helpers.py (åº”ç”¨å±‚)
    â†“
lightrag_client.py + document_processor.py (ä¸šåŠ¡å±‚)
```

---

## æ–‡ä»¶è¯¦è§£

### 1. ç®€å•æ—¥å¿—ç³»ç»Ÿ (simple_logger.py)

**ä¸»è¦åŠŸèƒ½**: æä¾›è½»é‡çº§ã€é›¶ä¾èµ–çš„æ—¥å¿—è®°å½•åŠŸèƒ½ï¼Œé¿å…å¾ªç¯å¯¼å…¥é—®é¢˜ã€‚

#### æ ¸å¿ƒå‡½æ•°: get_simple_logger

```python
def get_simple_logger(name: str, level: str = "INFO") -> logging.Logger:
    """
    åˆ›å»ºç®€å•çš„æ—¥å¿—è®°å½•å™¨ï¼Œé¿å…å¾ªç¯å¯¼å…¥
    
    ç‰¹ç‚¹:
    - é›¶å¤–éƒ¨ä¾èµ–
    - é˜²é‡å¤æ·»åŠ å¤„ç†å™¨
    - æ ‡å‡†æ ¼å¼åŒ–è¾“å‡º
    - é˜²æ­¢æ—¥å¿—ä¼ æ’­
    """
```

#### å®ç°ç‰¹ç‚¹

**é¿å…é‡å¤å¤„ç†å™¨**
```python
# æ£€æŸ¥æ˜¯å¦å·²æœ‰å¤„ç†å™¨
if logger.handlers:
    return logger  # ç›´æ¥è¿”å›å·²é…ç½®çš„æ—¥å¿—å™¨
```

**æ ‡å‡†åŒ–æ ¼å¼**
```python
formatter = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
```

**é˜²æ­¢æ—¥å¿—ä¼ æ’­**
```python
logger.propagate = False  # é¿å…é‡å¤è¾“å‡ºåˆ°æ ¹æ—¥å¿—å™¨
```

#### ä½¿ç”¨åœºæ™¯
- LightRAGå®¢æˆ·ç«¯åˆå§‹åŒ–
- å„ä¸ªagentsèŠ‚ç‚¹çš„åŸºç¡€æ—¥å¿—
- é¿å…å¾ªç¯å¯¼å…¥çš„æ¨¡å—é—´é€šä¿¡
- ç³»ç»Ÿå¯åŠ¨é˜¶æ®µçš„æ—¥å¿—è®°å½•

#### ä½¿ç”¨ç¤ºä¾‹

```python
from src.utils.simple_logger import get_simple_logger

# åˆ›å»ºæ—¥å¿—å™¨
logger = get_simple_logger(__name__)

# åŸºç¡€æ—¥å¿—è®°å½•
logger.info("LightRAGå®¢æˆ·ç«¯åˆå§‹åŒ–")
logger.warning("é…ç½®é¡¹ç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼")
logger.error("è¿æ¥æ•°æ®åº“å¤±è´¥")
```

---

### 2. é«˜çº§æ—¥å¿—ç³»ç»Ÿ (advanced_logging.py)

**ä¸»è¦åŠŸèƒ½**: æä¾›ç»“æ„åŒ–JSONæ—¥å¿—ã€æ€§èƒ½ç›‘æ§ã€é”™è¯¯è¿½è¸ªå’Œå®¡è®¡æ—¥å¿—åŠŸèƒ½ã€‚

#### æ ¸å¿ƒç±»: StructuredFormatter

```python
class StructuredFormatter(logging.Formatter):
    """ç»“æ„åŒ–æ—¥å¿—æ ¼å¼åŒ–å™¨
    
    è¾“å‡ºJSONæ ¼å¼æ—¥å¿—ï¼ŒåŒ…å«:
    - åŸºç¡€æ—¥å¿—ä¿¡æ¯ (æ—¶é—´æˆ³ã€çº§åˆ«ã€æ¶ˆæ¯ç­‰)
    - ä¸šåŠ¡å­—æ®µ (ç”¨æˆ·IDã€ä¼šè¯IDã€æŸ¥è¯¢ID)
    - æ€§èƒ½æŒ‡æ ‡ (å¤„ç†æ—¶é—´ã€æ“ä½œæŒ‡æ ‡)
    - å¼‚å¸¸ä¿¡æ¯ (å¼‚å¸¸ç±»å‹ã€æ¶ˆæ¯ã€å †æ ˆè·Ÿè¸ª)
    """
```

**JSONæ—¥å¿—ç»“æ„**
```json
{
  "timestamp": "2024-01-20T10:30:45.123456",
  "level": "INFO",
  "logger": "src.agents.query_analysis",
  "message": "æŸ¥è¯¢åˆ†æå®Œæˆ",
  "module": "query_analysis",
  "function": "query_analysis_node",
  "line": 67,
  "user_id": "user123",
  "session_id": "session456",
  "query_id": "query789",
  "processing_time": 0.156,
  "metrics": {
    "operation": "query_analysis",
    "tokens_used": 150,
    "confidence": 0.85
  }
}
```

#### æ ¸å¿ƒç±»: PerformanceLogger

```python
class PerformanceLogger:
    """æ€§èƒ½ç›‘æ§æ—¥å¿—å™¨
    
    åŠŸèƒ½:
    - æ“ä½œè®¡æ—¶å’Œæ€§èƒ½æŒ‡æ ‡æ”¶é›†
    - è‡ªåŠ¨è®°å½•å¼€å§‹/ç»“æŸæ—¶é—´
    - æˆåŠŸ/å¤±è´¥çŠ¶æ€è¿½è¸ª
    - è¯¦ç»†æ€§èƒ½æ•°æ®è®°å½•
    """
```

**æ€§èƒ½ç›‘æ§ä½¿ç”¨**
```python
perf_logger = get_performance_logger(__name__)

# å¼€å§‹æ“ä½œè®¡æ—¶
perf_logger.start_operation("lightrag_retrieval", mode="hybrid", query_length=45)

# æ‰§è¡Œä¸šåŠ¡é€»è¾‘
result = perform_retrieval()

# ç»“æŸæ“ä½œè®¡æ—¶
perf_logger.end_operation(
    success=True, 
    results_count=5, 
    confidence_score=0.85
)
```

#### æ ¸å¿ƒç±»: ErrorTracker

```python
class ErrorTracker:
    """é”™è¯¯è¿½è¸ªå™¨
    
    åŠŸèƒ½:
    - é”™è¯¯è®°å½•å’Œåˆ†ç±»ç»Ÿè®¡
    - å¼‚å¸¸å †æ ˆè·Ÿè¸ª
    - é”™è¯¯è¶‹åŠ¿åˆ†æ
    - è‡ªåŠ¨å‘Šè­¦æœºåˆ¶
    """
```

#### è£…é¥°å™¨å‡½æ•°

**æ€§èƒ½æ—¥å¿—è£…é¥°å™¨**
```python
@log_performance("node_execution")
def query_analysis_node(state: AgentState) -> Dict[str, Any]:
    """è‡ªåŠ¨è®°å½•èŠ‚ç‚¹æ‰§è¡Œæ€§èƒ½"""
    # èŠ‚ç‚¹ä¸šåŠ¡é€»è¾‘
    return result  # è‡ªåŠ¨è®°å½•æ‰§è¡Œæ—¶é—´å’ŒæˆåŠŸçŠ¶æ€
```

**é”™è¯¯æ—¥å¿—è£…é¥°å™¨**
```python
@log_errors("lightrag_query")
def query_lightrag_sync(query: str, mode: str) -> dict:
    """è‡ªåŠ¨æ•è·å’Œè®°å½•æŸ¥è¯¢é”™è¯¯"""
    # æŸ¥è¯¢é€»è¾‘ï¼Œå¼‚å¸¸ä¼šè¢«è‡ªåŠ¨æ•è·å’Œè®°å½•
    return result
```

#### ç›‘æ§å’Œå®¡è®¡å‡½æ•°

**æŒ‡æ ‡è®°å½•**
```python
def record_metric(name: str, value: float, **tags) -> None:
    """è®°å½•ä¸šåŠ¡æŒ‡æ ‡
    
    ç¤ºä¾‹:
    - record_metric("query_latency", 0.156, query_type="FACTUAL")
    - record_metric("retrieval_score", 0.85, mode="hybrid")
    - record_metric("confidence_score", 0.72, has_web_search=True)
    """
```

**å®¡è®¡æ—¥å¿—**
```python
def audit_log(action: str, user: str = "system", details: dict = None) -> None:
    """è®°å½•å®¡è®¡äº‹ä»¶
    
    ç¤ºä¾‹:
    - audit_log("user_query", user="user123", details={"query": "AI trends"})
    - audit_log("workflow_execution", details={"duration": 2.5, "nodes": 5})
    - audit_log("config_change", user="admin", details={"field": "threshold"})
    """
```

#### ä¸Šä¸‹æ–‡ç®¡ç†å™¨

```python
@contextmanager
def performance_context(operation_name: str, logger_name: str):
    """æ€§èƒ½ç›‘æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    perf_logger = get_performance_logger(logger_name)
    perf_logger.start_operation(operation_name)
    
    try:
        yield perf_logger
        perf_logger.end_operation(success=True)
    except Exception as e:
        perf_logger.end_operation(success=False, error=str(e))
        raise

# ä½¿ç”¨ç¤ºä¾‹
with performance_context("database_query", __name__) as perf:
    result = execute_database_query()
    perf.add_metric("rows_returned", len(result))
```

---

### 3. é”™è¯¯å¤„ç†æ¡†æ¶ (error_handling.py)

**ä¸»è¦åŠŸèƒ½**: æä¾›ç»¼åˆé”™è¯¯å¤„ç†æœºåˆ¶ï¼ŒåŒ…æ‹¬è‡ªå®šä¹‰å¼‚å¸¸ã€é‡è¯•æœºåˆ¶å’Œç†”æ–­å™¨ã€‚

#### é”™è¯¯åˆ†ç±»ä½“ç³»

**é”™è¯¯ä¸¥é‡ç¨‹åº¦**
```python
class ErrorSeverity(Enum):
    LOW = "low"         # è½»å¾®é”™è¯¯ï¼Œä¸å½±å“ä¸»è¦åŠŸèƒ½
    MEDIUM = "medium"   # ä¸­ç­‰é”™è¯¯ï¼Œéƒ¨åˆ†åŠŸèƒ½å—å½±å“
    HIGH = "high"       # ä¸¥é‡é”™è¯¯ï¼Œä¸»è¦åŠŸèƒ½ä¸å¯ç”¨
    CRITICAL = "critical"  # è‡´å‘½é”™è¯¯ï¼Œç³»ç»Ÿæ— æ³•æ­£å¸¸è¿è¡Œ
```

**é”™è¯¯ç±»åˆ«**
```python
class ErrorCategory(Enum):
    SYSTEM = "system"              # ç³»ç»Ÿå†…éƒ¨é”™è¯¯
    NETWORK = "network"            # ç½‘ç»œè¿æ¥é”™è¯¯
    DATABASE = "database"          # æ•°æ®åº“ç›¸å…³é”™è¯¯
    API = "api"                   # å¤–éƒ¨APIè°ƒç”¨é”™è¯¯
    VALIDATION = "validation"      # æ•°æ®éªŒè¯é”™è¯¯
    AUTHENTICATION = "authentication"  # èº«ä»½éªŒè¯é”™è¯¯
    PERMISSION = "permission"      # æƒé™ç›¸å…³é”™è¯¯
    CONFIGURATION = "configuration"  # é…ç½®é”™è¯¯
    EXTERNAL_SERVICE = "external_service"  # å¤–éƒ¨æœåŠ¡é”™è¯¯
    USER_INPUT = "user_input"      # ç”¨æˆ·è¾“å…¥é”™è¯¯
```

#### æ ¸å¿ƒå¼‚å¸¸ç±»: SystemError

```python
class SystemError(Exception):
    """ç³»ç»ŸåŸºç¡€å¼‚å¸¸ç±»
    
    æä¾›ç»Ÿä¸€çš„é”™è¯¯æ¥å£:
    - é”™è¯¯æ¶ˆæ¯å’Œç”¨æˆ·å‹å¥½æç¤º
    - é”™è¯¯åˆ†ç±»å’Œä¸¥é‡ç¨‹åº¦
    - æ¢å¤å»ºè®®å’Œè¯¦ç»†ä¿¡æ¯
    - æ—¶é—´æˆ³å’Œé”™è¯¯ç¼–ç 
    """
    
    def __init__(self, 
                 message: str,
                 error_code: str = None,
                 category: ErrorCategory = ErrorCategory.SYSTEM,
                 severity: ErrorSeverity = ErrorSeverity.MEDIUM,
                 details: Dict[str, Any] = None,
                 recovery_suggestions: List[str] = None,
                 user_message: str = None):
```

**å…·ä½“å¼‚å¸¸ç±»å‹**
```python
class ConfigurationError(SystemError):
    """é…ç½®é”™è¯¯ - ç³»ç»Ÿé…ç½®ä¸æ­£ç¡®æˆ–ç¼ºå¤±"""

class DatabaseError(SystemError):
    """æ•°æ®åº“é”™è¯¯ - æ•°æ®åº“è¿æ¥æˆ–æŸ¥è¯¢å¤±è´¥"""
    
class NetworkError(SystemError):
    """ç½‘ç»œé”™è¯¯ - ç½‘ç»œè¿æ¥æˆ–é€šä¿¡å¤±è´¥"""
    
class APIError(SystemError):
    """APIé”™è¯¯ - å¤–éƒ¨APIè°ƒç”¨å¤±è´¥"""
    
class ValidationError(SystemError):
    """éªŒè¯é”™è¯¯ - è¾“å…¥æ•°æ®éªŒè¯å¤±è´¥"""
```

#### é”™è¯¯å¤„ç†å™¨: ErrorHandler

```python
class ErrorHandler:
    """ç»Ÿä¸€é”™è¯¯å¤„ç†å™¨
    
    åŠŸèƒ½:
    - é”™è¯¯åˆ†ç±»å’Œæ ‡å‡†åŒ–å¤„ç†
    - ç”Ÿæˆç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
    - è®°å½•è¯¦ç»†çš„é”™è¯¯æ—¥å¿—
    - æ‰§è¡Œé”™è¯¯æ¢å¤ç­–ç•¥
    """
    
    def handle_error(self, error: Exception, context: dict = None) -> dict:
        """å¤„ç†é”™è¯¯å¹¶è¿”å›æ ‡å‡†åŒ–ç»“æœ"""
```

#### é‡è¯•æœºåˆ¶: RetryHandler

```python
class RetryHandler:
    """æ™ºèƒ½é‡è¯•å¤„ç†å™¨
    
    åŠŸèƒ½:
    - æŒ‡æ•°é€€é¿ç®—æ³•
    - æœ€å¤§é‡è¯•æ¬¡æ•°æ§åˆ¶
    - ç‰¹å®šå¼‚å¸¸ç±»å‹çš„é‡è¯•ç­–ç•¥
    - é‡è¯•çŠ¶æ€è®°å½•
    """
    
    def retry_with_backoff(self, 
                          func: callable, 
                          max_retries: int = 3,
                          backoff_factor: float = 1.0,
                          *args, **kwargs):
        """æ‰§è¡Œå¸¦é€€é¿çš„é‡è¯•é€»è¾‘"""
```

#### ç†”æ–­å™¨: CircuitBreaker

```python
class CircuitBreaker:
    """ç†”æ–­å™¨æ¨¡å¼å®ç°
    
    çŠ¶æ€:
    - CLOSED: æ­£å¸¸çŠ¶æ€ï¼Œå…è®¸è¯·æ±‚é€šè¿‡
    - OPEN: ç†”æ–­çŠ¶æ€ï¼Œç›´æ¥æ‹’ç»è¯·æ±‚
    - HALF_OPEN: åŠå¼€çŠ¶æ€ï¼Œå…è®¸å°‘é‡è¯·æ±‚æµ‹è¯•
    
    åŠŸèƒ½:
    - æ•…éšœæ£€æµ‹å’Œè‡ªåŠ¨ç†”æ–­
    - è‡ªåŠ¨æ¢å¤å’ŒçŠ¶æ€è½¬æ¢
    - å¤±è´¥ç‡å’Œè¶…æ—¶æ§åˆ¶
    """
```

#### è£…é¥°å™¨ä½¿ç”¨

**åŸºç¡€é”™è¯¯å¤„ç†**
```python
@handle_errors(reraise=False, return_on_error={"error": "æ“ä½œå¤±è´¥"})
def risky_operation():
    """å¯èƒ½å¤±è´¥çš„æ“ä½œï¼Œè‡ªåŠ¨å¤„ç†é”™è¯¯"""
    # ä¸šåŠ¡é€»è¾‘
    pass
```

**é‡è¯•è£…é¥°å™¨**
```python
@retry_on_failure(max_retries=3, backoff_factor=2.0)
def unreliable_api_call():
    """ä¸ç¨³å®šçš„APIè°ƒç”¨ï¼Œè‡ªåŠ¨é‡è¯•"""
    # APIè°ƒç”¨é€»è¾‘
    pass
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from src.utils.error_handling import (
    SystemError, ConfigurationError, ErrorHandler, 
    RetryHandler, CircuitBreaker
)

# æŠ›å‡ºè‡ªå®šä¹‰å¼‚å¸¸
if not config.LLM_API_KEY:
    raise ConfigurationError(
        "LLM APIå¯†é’¥æœªé…ç½®",
        error_code="CONFIG_MISSING_API_KEY",
        recovery_suggestions=[
            "æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„LLM_API_KEYè®¾ç½®",
            "ç¡®è®¤APIå¯†é’¥æ ¼å¼æ­£ç¡®",
            "éªŒè¯APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ"
        ]
    )

# ä½¿ç”¨é”™è¯¯å¤„ç†å™¨
error_handler = ErrorHandler()
try:
    result = risky_operation()
except Exception as e:
    error_info = error_handler.handle_error(e, context={"operation": "test"})
    print(f"é”™è¯¯å¤„ç†ç»“æœ: {error_info}")

# ä½¿ç”¨é‡è¯•å¤„ç†å™¨
retry_handler = RetryHandler()
result = retry_handler.retry_with_backoff(
    unreliable_function,
    max_retries=3,
    backoff_factor=2.0
)

# ä½¿ç”¨ç†”æ–­å™¨
circuit_breaker = CircuitBreaker(failure_threshold=5, timeout=60)
try:
    result = circuit_breaker.call(external_service_call)
except Exception as e:
    print(f"ç†”æ–­å™¨ä¿æŠ¤: {e}")
```

---

### 4. ç³»ç»Ÿç›‘æ§ (system_monitoring.py)

**ä¸»è¦åŠŸèƒ½**: æä¾›ç³»ç»Ÿå¥åº·æ£€æŸ¥ã€æ€§èƒ½ç›‘æ§å’ŒçŠ¶æ€æŠ¥å‘ŠåŠŸèƒ½ã€‚

#### å¥åº·çŠ¶æ€æšä¸¾

```python
class HealthStatus(Enum):
    HEALTHY = "healthy"     # ç³»ç»Ÿæ­£å¸¸è¿è¡Œ
    WARNING = "warning"     # å­˜åœ¨æ½œåœ¨é—®é¢˜
    ERROR = "error"        # å­˜åœ¨æ˜ç¡®é”™è¯¯
    CRITICAL = "critical"  # ä¸¥é‡æ•…éšœçŠ¶æ€
```

#### æ ¸å¿ƒæ•°æ®ç±»: HealthCheck

```python
@dataclass
class HealthCheck:
    """å¥åº·æ£€æŸ¥ç»“æœçš„æ ‡å‡†åŒ–è¡¨ç¤º
    
    å­—æ®µ:
    - name: æ£€æŸ¥é¡¹ç›®åç§°
    - status: å¥åº·çŠ¶æ€
    - message: çŠ¶æ€æè¿°ä¿¡æ¯
    - details: è¯¦ç»†æ£€æŸ¥æ•°æ®
    - timestamp: æ£€æŸ¥æ‰§è¡Œæ—¶é—´
    - execution_time: æ£€æŸ¥è€—æ—¶
    """
```

#### æ ¸å¿ƒç±»: SystemMonitor

```python
class SystemMonitor:
    """ç³»ç»Ÿç›‘æ§å™¨
    
    åŠŸèƒ½:
    - æ³¨å†Œå’Œç®¡ç†å¥åº·æ£€æŸ¥é¡¹
    - å®šæœŸæ‰§è¡Œç³»ç»Ÿç›‘æ§
    - æ”¶é›†å’Œå­˜å‚¨æ€§èƒ½æŒ‡æ ‡
    - å‘Šè­¦é˜ˆå€¼ç®¡ç†
    - ç›‘æ§æ•°æ®å†å²è®°å½•
    """
```

**å‘Šè­¦é˜ˆå€¼é…ç½®**
```python
alert_thresholds = {
    "cpu_usage": 80.0,        # CPUä½¿ç”¨ç‡å‘Šè­¦é˜ˆå€¼
    "memory_usage": 85.0,     # å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦é˜ˆå€¼
    "disk_usage": 90.0,       # ç£ç›˜ä½¿ç”¨ç‡å‘Šè­¦é˜ˆå€¼
    "response_time": 5.0,     # å“åº”æ—¶é—´å‘Šè­¦é˜ˆå€¼(ç§’)
    "error_rate": 0.1         # é”™è¯¯ç‡å‘Šè­¦é˜ˆå€¼(10%)
}
```

#### å¥åº·æ£€æŸ¥æ³¨å†Œ

```python
def register_health_check(self, name: str, check_func: Callable) -> None:
    """æ³¨å†Œè‡ªå®šä¹‰å¥åº·æ£€æŸ¥
    
    ç¤ºä¾‹:
    monitor.register_health_check("database", check_database_health)
    monitor.register_health_check("api_endpoints", check_api_health)
    monitor.register_health_check("cache_status", check_cache_health)
    """
```

#### ç³»ç»ŸæŒ‡æ ‡æ”¶é›†

```python
def _collect_system_metrics(self):
    """æ”¶é›†ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
    
    # CPUä½¿ç”¨ç‡
    cpu_usage = psutil.cpu_percent(interval=1)
    
    # å†…å­˜ä½¿ç”¨æƒ…å†µ
    memory = psutil.virtual_memory()
    memory_usage = memory.percent
    
    # ç£ç›˜ä½¿ç”¨æƒ…å†µ
    disk = psutil.disk_usage('/')
    disk_usage = (disk.used / disk.total) * 100
    
    # è®°å½•æŒ‡æ ‡
    self.add_metric("cpu_usage", cpu_usage)
    self.add_metric("memory_usage", memory_usage)
    self.add_metric("disk_usage", disk_usage)
```

#### æ ¸å¿ƒç±»: ApplicationHealthChecker

```python
class ApplicationHealthChecker:
    """åº”ç”¨çº§å¥åº·æ£€æŸ¥å™¨
    
    æ£€æŸ¥é¡¹ç›®:
    - æ•°æ®åº“è¿æ¥çŠ¶æ€
    - å¤–éƒ¨APIå¯ç”¨æ€§
    - ç¼“å­˜ç³»ç»ŸçŠ¶æ€
    - é…ç½®æœ‰æ•ˆæ€§
    - ä¾èµ–æœåŠ¡çŠ¶æ€
    """
```

**æ•°æ®åº“å¥åº·æ£€æŸ¥**
```python
def check_database_connection(self) -> HealthCheck:
    """æ£€æŸ¥æ•°æ®åº“è¿æ¥å¥åº·çŠ¶æ€"""
    
    start_time = time.time()
    
    try:
        # PostgreSQLè¿æ¥æ£€æŸ¥
        postgres_status = self._check_postgres()
        
        # Neo4jè¿æ¥æ£€æŸ¥
        neo4j_status = self._check_neo4j()
        
        # ç»¼åˆè¯„ä¼°
        if postgres_status and neo4j_status:
            status = HealthStatus.HEALTHY
            message = "æ‰€æœ‰æ•°æ®åº“è¿æ¥æ­£å¸¸"
        elif postgres_status or neo4j_status:
            status = HealthStatus.WARNING
            message = "éƒ¨åˆ†æ•°æ®åº“è¿æ¥å¼‚å¸¸"
        else:
            status = HealthStatus.ERROR
            message = "æ•°æ®åº“è¿æ¥å…¨éƒ¨å¤±è´¥"
            
        return HealthCheck(
            name="database_connection",
            status=status,
            message=message,
            details={
                "postgres": postgres_status,
                "neo4j": neo4j_status
            },
            timestamp=datetime.now(),
            execution_time=time.time() - start_time
        )
        
    except Exception as e:
        return HealthCheck(
            name="database_connection",
            status=HealthStatus.CRITICAL,
            message=f"æ•°æ®åº“å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}",
            details={"error": str(e)},
            timestamp=datetime.now(),
            execution_time=time.time() - start_time
        )
```

**APIç«¯ç‚¹å¥åº·æ£€æŸ¥**
```python
def check_api_endpoints(self) -> HealthCheck:
    """æ£€æŸ¥å¤–éƒ¨APIç«¯ç‚¹å¯ç”¨æ€§"""
    
    api_results = {}
    
    # OpenAI APIæ£€æŸ¥
    api_results["openai"] = self._test_openai_api()
    
    # Tavily APIæ£€æŸ¥
    api_results["tavily"] = self._test_tavily_api()
    
    # è¯„ä¼°æ•´ä½“çŠ¶æ€
    healthy_apis = sum(1 for result in api_results.values() if result["status"] == "healthy")
    total_apis = len(api_results)
    
    if healthy_apis == total_apis:
        status = HealthStatus.HEALTHY
        message = "æ‰€æœ‰APIç«¯ç‚¹æ­£å¸¸"
    elif healthy_apis >= total_apis * 0.5:
        status = HealthStatus.WARNING
        message = f"{healthy_apis}/{total_apis} APIç«¯ç‚¹å¯ç”¨"
    else:
        status = HealthStatus.ERROR
        message = f"å¤šæ•°APIç«¯ç‚¹ä¸å¯ç”¨ ({healthy_apis}/{total_apis})"
    
    return HealthCheck(
        name="api_endpoints",
        status=status,
        message=message,
        details=api_results,
        timestamp=datetime.now(),
        execution_time=0.0  # å®é™…è®¡ç®—æ‰§è¡Œæ—¶é—´
    )
```

#### ç›‘æ§å¯åŠ¨å’Œæ§åˆ¶

```python
# å¯åŠ¨ç³»ç»Ÿç›‘æ§
monitor = SystemMonitor()

# æ³¨å†Œå¥åº·æ£€æŸ¥
monitor.register_health_check("database", app_health_checker.check_database_connection)
monitor.register_health_check("api_endpoints", app_health_checker.check_api_endpoints)

# å¯åŠ¨å®šæœŸç›‘æ§ (æ¯60ç§’æ‰§è¡Œä¸€æ¬¡)
monitor.start_monitoring(interval=60)

# è·å–å½“å‰ç³»ç»Ÿå¥åº·çŠ¶æ€
health_report = monitor.get_system_health()
print(f"ç³»ç»Ÿæ•´ä½“çŠ¶æ€: {health_report['overall_status']}")
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from src.utils.system_monitoring import (
    SystemMonitor, ApplicationHealthChecker, 
    HealthStatus, get_system_health
)

# åˆ›å»ºç›‘æ§å®ä¾‹
monitor = SystemMonitor()
health_checker = ApplicationHealthChecker()

# æ³¨å†Œè‡ªå®šä¹‰å¥åº·æ£€æŸ¥
def check_custom_service():
    """è‡ªå®šä¹‰æœåŠ¡å¥åº·æ£€æŸ¥"""
    try:
        # æ‰§è¡ŒæœåŠ¡æ£€æŸ¥é€»è¾‘
        result = ping_custom_service()
        
        return HealthCheck(
            name="custom_service",
            status=HealthStatus.HEALTHY if result else HealthStatus.ERROR,
            message="è‡ªå®šä¹‰æœåŠ¡çŠ¶æ€æ£€æŸ¥",
            details={"response_time": result.get("latency", 0)},
            timestamp=datetime.now(),
            execution_time=0.1
        )
    except Exception as e:
        return HealthCheck(
            name="custom_service",
            status=HealthStatus.CRITICAL,
            message=f"æœåŠ¡æ£€æŸ¥å¤±è´¥: {str(e)}",
            details={"error": str(e)},
            timestamp=datetime.now(),
            execution_time=0.0
        )

monitor.register_health_check("custom_service", check_custom_service)

# è·å–å®Œæ•´çš„å¥åº·æŠ¥å‘Š
health_report = get_system_health()
print(json.dumps(health_report, indent=2, ensure_ascii=False))
```

---

### 5. LightRAGå®¢æˆ·ç«¯ (lightrag_client.py)

**ä¸»è¦åŠŸèƒ½**: å°è£…LightRAGæ“ä½œï¼Œç®¡ç†PostgreSQLå’ŒNeo4jè¿æ¥ï¼Œæä¾›ç»Ÿä¸€çš„æ£€ç´¢æ¥å£ã€‚

#### è‡ªå®šä¹‰LLMå‡½æ•°

**ä¸»LLMå‡½æ•°**
```python
def custom_llm_func(prompt: str, **kwargs) -> str:
    """è‡ªå®šä¹‰LLMå‡½æ•°ï¼Œæ”¯æŒä¸åŒçš„base_urlå’ŒAPI key
    
    ç‰¹ç‚¹:
    - ä½¿ç”¨ä¸»LLMé…ç½® (å¯¹è¯å’Œæ¨ç†)
    - æ”¯æŒè‡ªå®šä¹‰base_url
    - å®Œæ•´çš„é”™è¯¯å¤„ç†
    - è°ƒç”¨æ—¥å¿—è®°å½•
    """
```

**å‘é‡ä¸“ç”¨LLMå‡½æ•°**
```python
def custom_vector_llm_func(prompt: str, **kwargs) -> str:
    """å‘é‡æå–ä¸“ç”¨LLMå‡½æ•°
    
    ç‰¹ç‚¹:
    - ä½¿ç”¨å‘é‡LLMé…ç½® (æ–‡æ¡£åˆ†å—å’Œè¯­ä¹‰ç†è§£)
    - ä½æ¸©åº¦è®¾ç½®ä¿è¯ä¸€è‡´æ€§
    - ä¼˜åŒ–çš„tokené™åˆ¶
    - é«˜æ•ˆå¤„ç†å¤§é‡æ–‡æ¡£
    """
```

**åµŒå…¥å‡½æ•°**
```python
def custom_embedding_func(texts: list[str]) -> list[list[float]]:
    """è‡ªå®šä¹‰åµŒå…¥å‡½æ•°
    
    ç‰¹ç‚¹:
    - æ”¯æŒè‡ªå®šä¹‰embeddingæœåŠ¡
    - æ‰¹é‡æ–‡æœ¬å‘é‡åŒ–
    - ç»´åº¦å‚æ•°é…ç½®
    - é”™è¯¯é‡è¯•æœºåˆ¶
    """
```

#### æ ¸å¿ƒç±»: LightRAGClient

```python
class LightRAGClient:
    """LightRAGå®¢æˆ·ç«¯å°è£…ç±»
    
    åŠŸèƒ½:
    - ç®¡ç†LightRAGå®ä¾‹ç”Ÿå‘½å‘¨æœŸ
    - å¤„ç†æ•°æ®åº“è¿æ¥å’Œå›é€€æœºåˆ¶
    - æä¾›ç»Ÿä¸€çš„æ£€ç´¢æ¥å£
    - å¥åº·æ£€æŸ¥å’ŒçŠ¶æ€ç›‘æ§
    - æ”¯æŒå¤šç§LLMé…ç½®
    """
```

#### æ•°æ®åº“åç«¯ç®¡ç†

**PostgreSQLæ”¯æŒ**
```python
async def _check_pgvector(self) -> bool:
    """æ£€æŸ¥PostgreSQL pgvectoræ‰©å±•å¯ç”¨æ€§"""
    
    try:
        # æµ‹è¯•è¿æ¥
        conn = psycopg2.connect(config.postgres_url)
        cursor = conn.cursor()
        
        # æ£€æŸ¥pgvectoræ‰©å±•
        cursor.execute("SELECT EXISTS(SELECT 1 FROM pg_extension WHERE extname = 'vector')")
        has_pgvector = cursor.fetchone()[0]
        
        cursor.close()
        conn.close()
        
        return has_pgvector
        
    except Exception as e:
        logger.error(f"PostgreSQLæ£€æŸ¥å¤±è´¥: {e}")
        return False
```

**Neo4jæ”¯æŒ**
```python
async def _check_neo4j(self) -> bool:
    """æ£€æŸ¥Neo4jè¿æ¥å¯ç”¨æ€§"""
    
    try:
        from neo4j import GraphDatabase
        
        driver = GraphDatabase.driver(
            config.NEO4J_URI,
            auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD)
        )
        
        # æµ‹è¯•è¿æ¥
        with driver.session() as session:
            result = session.run("RETURN 1 as test")
            test_value = result.single()["test"]
            
        driver.close()
        return test_value == 1
        
    except Exception as e:
        logger.error(f"Neo4jæ£€æŸ¥å¤±è´¥: {e}")
        return False
```

**è‡ªåŠ¨å›é€€æœºåˆ¶**
```python
async def initialize(self) -> bool:
    """åˆå§‹åŒ–LightRAGå®ä¾‹ï¼Œæ”¯æŒè‡ªåŠ¨å›é€€"""
    
    # ä¼˜å…ˆå°è¯•å®Œæ•´é…ç½® (PostgreSQL + Neo4j)
    if await self._check_pgvector() and await self._check_neo4j():
        storage_config = {
            "vector_storage": "postgresql",
            "graph_storage": "neo4j"
        }
        logger.info("ä½¿ç”¨PostgreSQL+Neo4jå®Œæ•´é…ç½®")
        
    # å›é€€åˆ°éƒ¨åˆ†é…ç½®
    elif await self._check_pgvector():
        storage_config = {
            "vector_storage": "postgresql", 
            "graph_storage": "networkx"  # å†…å­˜å›¾å­˜å‚¨
        }
        logger.warning("Neo4jä¸å¯ç”¨ï¼Œå›é€€åˆ°PostgreSQL+NetworkX")
        
    elif await self._check_neo4j():
        storage_config = {
            "vector_storage": "nano_vectordb",  # æ–‡ä»¶å‘é‡å­˜å‚¨
            "graph_storage": "neo4j"
        }
        logger.warning("PostgreSQLä¸å¯ç”¨ï¼Œå›é€€åˆ°NanoVectorDB+Neo4j")
        
    # æœ€å°åŒ–é…ç½®
    else:
        storage_config = {
            "vector_storage": "nano_vectordb",
            "graph_storage": "networkx"
        }
        logger.warning("æ•°æ®åº“ä¸å¯ç”¨ï¼Œä½¿ç”¨æœ€å°åŒ–é…ç½®")
    
    # åˆå§‹åŒ–LightRAGå®ä¾‹
    self.rag_instance = LightRAG(
        working_dir=config.RAG_STORAGE_DIR,
        llm_model_func=custom_llm_func,
        vector_llm_model_func=custom_vector_llm_func,
        embedding_func=custom_embedding_func,
        **storage_config
    )
    
    self._initialized = True
    return True
```

#### æŸ¥è¯¢æ¥å£

**ç»Ÿä¸€æŸ¥è¯¢æ–¹æ³•**
```python
async def query(self, query: str, mode: str = "hybrid") -> dict:
    """æ‰§è¡ŒLightRAGæŸ¥è¯¢
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        mode: æ£€ç´¢æ¨¡å¼ ("local", "global", "hybrid")
        
    Returns:
        dict: æ ‡å‡†åŒ–æŸ¥è¯¢ç»“æœ
        {
            "success": bool,
            "content": str,
            "mode": str,
            "error": str  # ä»…åœ¨å¤±è´¥æ—¶å­˜åœ¨
        }
    """
```

**åŒæ­¥æŸ¥è¯¢åŒ…è£…**
```python
def query_lightrag_sync(query: str, mode: str) -> dict:
    """åŒæ­¥LightRAGæŸ¥è¯¢åŒ…è£…å‡½æ•°
    
    ç”¨äºåœ¨åŒæ­¥ç¯å¢ƒä¸­è°ƒç”¨å¼‚æ­¥LightRAGæŸ¥è¯¢
    é€‚ç”¨äºagentsèŠ‚ç‚¹ä¸­çš„ç›´æ¥è°ƒç”¨
    """
    
    try:
        # è·å–æˆ–åˆ›å»ºäº‹ä»¶å¾ªç¯
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        # æ‰§è¡Œå¼‚æ­¥æŸ¥è¯¢
        if not lightrag_client._initialized:
            loop.run_until_complete(lightrag_client.initialize())
        
        result = loop.run_until_complete(
            lightrag_client.query(query, mode)
        )
        
        return result
        
    except Exception as e:
        logger.error(f"åŒæ­¥æŸ¥è¯¢å¤±è´¥: {e}")
        return {
            "success": False,
            "content": "",
            "mode": mode,
            "error": str(e)
        }
```

#### æ–‡æ¡£ç®¡ç†

**æ–‡æ¡£æ’å…¥**
```python
async def insert_document(self, document: str, metadata: dict = None) -> bool:
    """æ’å…¥æ–‡æ¡£åˆ°çŸ¥è¯†åº“
    
    æµç¨‹:
    1. æ–‡æ¡£é¢„å¤„ç†å’Œæ¸…æ´—
    2. æ™ºèƒ½åˆ†å—å¤„ç†
    3. å‘é‡åŒ–å’Œç´¢å¼•
    4. çŸ¥è¯†å›¾è°±æ„å»º
    5. å­˜å‚¨åˆ°æŒ‡å®šåç«¯
    """
```

**æ‰¹é‡æ–‡æ¡£å¤„ç†**
```python
async def insert_documents_batch(self, documents: List[str], batch_size: int = 10) -> dict:
    """æ‰¹é‡æ’å…¥æ–‡æ¡£
    
    ç‰¹ç‚¹:
    - åˆ†æ‰¹å¤„ç†é¿å…å†…å­˜æº¢å‡º
    - å¹¶è¡Œå¤„ç†æé«˜æ•ˆç‡
    - é”™è¯¯éš”ç¦»å’Œæ¢å¤
    - è¿›åº¦è·Ÿè¸ªå’ŒæŠ¥å‘Š
    """
```

#### å¥åº·æ£€æŸ¥

```python
async def get_health_status(self) -> dict:
    """è·å–LightRAGå®¢æˆ·ç«¯å¥åº·çŠ¶æ€"""
    
    health_info = {
        "initialized": self._initialized,
        "backend_status": {},
        "storage_usage": {},
        "last_query_time": self._last_query_time,
        "total_queries": self._query_count
    }
    
    if self._initialized:
        # æ£€æŸ¥å­˜å‚¨åç«¯çŠ¶æ€
        health_info["backend_status"]["postgresql"] = await self._check_pgvector()
        health_info["backend_status"]["neo4j"] = await self._check_neo4j()
        
        # è·å–å­˜å‚¨ä½¿ç”¨æƒ…å†µ
        health_info["storage_usage"] = await self._get_storage_usage()
    
    return health_info
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from src.utils.lightrag_client import lightrag_client, query_lightrag_sync
import asyncio

# å¼‚æ­¥ä½¿ç”¨ç¤ºä¾‹
async def async_example():
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    await lightrag_client.initialize()
    
    # æ‰§è¡ŒæŸ¥è¯¢
    result = await lightrag_client.query("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ", mode="local")
    
    if result["success"]:
        print(f"æŸ¥è¯¢ç»“æœ: {result['content']}")
    else:
        print(f"æŸ¥è¯¢å¤±è´¥: {result['error']}")
    
    # æ’å…¥æ–‡æ¡£
    success = await lightrag_client.insert_document(
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯...",
        metadata={"source": "æ•™ç§‘ä¹¦", "chapter": "ç¬¬ä¸€ç« "}
    )
    
    print(f"æ–‡æ¡£æ’å…¥: {'æˆåŠŸ' if success else 'å¤±è´¥'}")

# åŒæ­¥ä½¿ç”¨ç¤ºä¾‹ (åœ¨agentsèŠ‚ç‚¹ä¸­)
def sync_example():
    # ç›´æ¥åŒæ­¥è°ƒç”¨
    result = query_lightrag_sync("æ·±åº¦å­¦ä¹ çš„åº”ç”¨é¢†åŸŸ", mode="hybrid")
    
    if result["success"]:
        print(f"æ£€ç´¢å†…å®¹: {result['content'][:200]}...")
    else:
        print(f"æ£€ç´¢å¤±è´¥: {result['error']}")

# å¥åº·æ£€æŸ¥ç¤ºä¾‹
async def health_check_example():
    health = await lightrag_client.get_health_status()
    
    print(f"å®¢æˆ·ç«¯çŠ¶æ€: {'å·²åˆå§‹åŒ–' if health['initialized'] else 'æœªåˆå§‹åŒ–'}")
    print(f"PostgreSQLçŠ¶æ€: {health['backend_status']['postgresql']}")
    print(f"Neo4jçŠ¶æ€: {health['backend_status']['neo4j']}")
    print(f"æ€»æŸ¥è¯¢æ¬¡æ•°: {health['total_queries']}")
```

---

### 6. è¾…åŠ©å‡½æ•°æ¨¡å— (helpers.py)

**ä¸»è¦åŠŸèƒ½**: æä¾›é€šç”¨çš„è¾…åŠ©å‡½æ•°ï¼Œé›†æˆé«˜çº§æ—¥å¿—è®°å½•å’Œé”™è¯¯å¤„ç†ã€‚

#### ä¿¡æ¯æºæ ¼å¼åŒ–

```python
@handle_errors(reraise=False, return_on_error="")
def format_sources(sources: List[Dict[str, Any]]) -> str:
    """æ ¼å¼åŒ–ä¿¡æ¯æ¥æºä¸ºç”¨æˆ·å‹å¥½çš„æ–‡æœ¬
    
    æ”¯æŒçš„æ¥æºç±»å‹:
    - lightrag_knowledge: æœ¬åœ°çŸ¥è¯†åº“
    - web_search: ç½‘ç»œæœç´¢ç»“æœ
    - knowledge_graph: çŸ¥è¯†å›¾è°±ä¿¡æ¯
    """
```

**æ ¼å¼åŒ–ç¤ºä¾‹è¾“å‡º**
```
1. æœ¬åœ°çŸ¥è¯†åº“ (hybridæ¨¡å¼, ç½®ä¿¡åº¦: 0.85)
2. ç½‘ç»œæœç´¢: [æ·±åº¦å­¦ä¹ å‘å±•è¶‹åŠ¿](https://example.com/article) - example.com (è¯„åˆ†: 0.92)
3. çŸ¥è¯†å›¾è°± (å®ä½“æ•°: 15)
```

#### ç½®ä¿¡åº¦è®¡ç®—

```python
def calculate_confidence(
    retrieval_score: float,
    content_length: int, 
    entity_coverage: float,
    mode_effectiveness: float,
    additional_factors: Dict[str, float] = None
) -> float:
    """è®¡ç®—ç»¼åˆç½®ä¿¡åº¦åˆ†æ•°
    
    ç®—æ³•:
    - åŸºç¡€æƒé‡åˆ†é…
    - åŠ¨æ€å› å­è°ƒæ•´
    - å½’ä¸€åŒ–å¤„ç†
    - è¾¹ç•Œå€¼æ§åˆ¶
    """
```

**ç½®ä¿¡åº¦è®¡ç®—å…¬å¼**
```python
# åŸºç¡€æƒé‡
weights = {
    "retrieval_score": 0.35,      # æ£€ç´¢è´¨é‡æœ€é‡è¦
    "content_length": 0.25,       # å†…å®¹å……å®åº¦
    "entity_coverage": 0.20,      # å®ä½“è¦†ç›–ç‡
    "mode_effectiveness": 0.20    # æ¨¡å¼æœ‰æ•ˆæ€§
}

# é•¿åº¦å› å­è®¡ç®—
length_factor = min(content_length / 800, 1.0)  # 800å­—ç¬¦ä¸ºåŸºå‡†

# å®ä½“è¦†ç›–åº¦å½’ä¸€åŒ–
entity_factor = max(0, min(entity_coverage, 1.0))

# ç»¼åˆè¯„åˆ†
confidence = (
    retrieval_score * weights["retrieval_score"] +
    length_factor * weights["content_length"] +
    entity_factor * weights["entity_coverage"] +
    mode_effectiveness * weights["mode_effectiveness"]
)
```

#### æ•°æ®éªŒè¯å’Œå¤„ç†

**æŸ¥è¯¢éªŒè¯**
```python
def validate_query(query: str) -> tuple[bool, str]:
    """éªŒè¯ç”¨æˆ·æŸ¥è¯¢çš„æœ‰æ•ˆæ€§
    
    éªŒè¯è§„åˆ™:
    - é•¿åº¦é™åˆ¶ (5-1000å­—ç¬¦)
    - æ¶æ„å†…å®¹æ£€æµ‹
    - ç‰¹æ®Šå­—ç¬¦è¿‡æ»¤
    - è¯­è¨€æ£€æµ‹
    """
    
    if not query or not query.strip():
        return False, "æŸ¥è¯¢ä¸èƒ½ä¸ºç©º"
    
    query = query.strip()
    
    # é•¿åº¦æ£€æŸ¥
    if len(query) < 5:
        return False, "æŸ¥è¯¢å¤ªçŸ­ï¼Œè‡³å°‘éœ€è¦5ä¸ªå­—ç¬¦"
    
    if len(query) > 1000:
        return False, "æŸ¥è¯¢å¤ªé•¿ï¼Œæœ€å¤š1000ä¸ªå­—ç¬¦"
    
    # æ¶æ„å†…å®¹æ£€æµ‹ (ç®€å•å®ç°)
    malicious_patterns = [
        r'<script[^>]*>.*?</script>',  # JavaScriptæ³¨å…¥
        r'javascript:',               # JavaScriptåè®®
        r'on\w+\s*=',                # HTMLäº‹ä»¶å±æ€§
    ]
    
    for pattern in malicious_patterns:
        if re.search(pattern, query, re.IGNORECASE):
            return False, "æŸ¥è¯¢åŒ…å«ä¸å®‰å…¨å†…å®¹"
    
    return True, "æŸ¥è¯¢æœ‰æ•ˆ"
```

**JSONå®‰å…¨è§£æ**
```python
def safe_json_parse(json_str: str, default_value=None, logger_name: str = None):
    """å®‰å…¨çš„JSONè§£æï¼Œå¸¦é”™è¯¯å¤„ç†
    
    ç‰¹ç‚¹:
    - å¼‚å¸¸å®‰å…¨
    - é»˜è®¤å€¼å¤„ç†
    - æ—¥å¿—è®°å½•
    - ç±»å‹éªŒè¯
    """
    
    if not json_str:
        return default_value
    
    try:
        result = json.loads(json_str)
        return result
        
    except json.JSONDecodeError as e:
        if logger_name:
            logger = setup_logger(logger_name)
            logger.warning(f"JSONè§£æå¤±è´¥: {e}")
        
        return default_value
    
    except Exception as e:
        if logger_name:
            logger = setup_logger(logger_name)
            logger.error(f"JSONè§£æå¼‚å¸¸: {e}")
        
        return default_value
```

#### æ–‡æœ¬å¤„ç†å·¥å…·

**æ™ºèƒ½æ–‡æœ¬æˆªæ–­**
```python
def smart_truncate(text: str, max_length: int, preserve_words: bool = True) -> str:
    """æ™ºèƒ½æ–‡æœ¬æˆªæ–­ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§
    
    ç‰¹ç‚¹:
    - ä¿æŒè¯æ±‡å®Œæ•´æ€§
    - æ™ºèƒ½æ–­å¥
    - çœç•¥å·æ·»åŠ 
    - å¤šè¯­è¨€æ”¯æŒ
    """
    
    if len(text) <= max_length:
        return text
    
    # åŸºç¡€æˆªæ–­
    truncated = text[:max_length]
    
    if preserve_words:
        # æŸ¥æ‰¾æœ€åä¸€ä¸ªå®Œæ•´è¯æ±‡è¾¹ç•Œ
        last_space = truncated.rfind(' ')
        last_punct = max(
            truncated.rfind('ã€‚'),
            truncated.rfind('ï¼'), 
            truncated.rfind('ï¼Ÿ'),
            truncated.rfind('.')
        )
        
        # é€‰æ‹©æœ€ä½³æˆªæ–­ç‚¹
        if last_punct > last_space and last_punct > max_length * 0.8:
            truncated = truncated[:last_punct + 1]
        elif last_space > max_length * 0.7:
            truncated = truncated[:last_space]
    
    # æ·»åŠ çœç•¥å·
    if len(truncated) < len(text):
        truncated += "..."
    
    return truncated
```

#### IDç”Ÿæˆå’Œä¼šè¯ç®¡ç†

**ä¼šè¯IDç”Ÿæˆ**
```python
def generate_session_id(prefix: str = "sess") -> str:
    """ç”Ÿæˆå”¯ä¸€ä¼šè¯ID
    
    æ ¼å¼: {prefix}_{timestamp}_{random}
    ç¤ºä¾‹: sess_20240120_103045_a1b2c3
    """
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    random_suffix = str(uuid.uuid4())[:6]
    
    return f"{prefix}_{timestamp}_{random_suffix}"

def generate_query_id(session_id: str = None) -> str:
    """ç”ŸæˆæŸ¥è¯¢ID"""
    
    if session_id:
        # åŸºäºä¼šè¯IDç”Ÿæˆ
        query_suffix = str(uuid.uuid4())[:8]
        return f"{session_id}_q_{query_suffix}"
    else:
        # ç‹¬ç«‹æŸ¥è¯¢ID
        return f"query_{int(time.time())}_{str(uuid.uuid4())[:8]}"
```

#### æ€§èƒ½å·¥å…·

**æ—¶é—´æ ¼å¼åŒ–**
```python
def format_duration(seconds: float) -> str:
    """å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºäººç±»å¯è¯»çš„æ—¶é—´"""
    
    if seconds < 0.001:
        return f"{seconds*1000000:.0f}Î¼s"
    elif seconds < 1:
        return f"{seconds*1000:.1f}ms"
    elif seconds < 60:
        return f"{seconds:.2f}s"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        seconds = seconds % 60
        return f"{minutes}m {seconds:.1f}s"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds = seconds % 60
        return f"{hours}h {minutes}m {seconds:.0f}s"
```

**æ–‡ä»¶å¤§å°æ ¼å¼åŒ–**
```python
def format_file_size(bytes_size: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if bytes_size < 1024.0:
            return f"{bytes_size:.1f} {unit}"
        bytes_size /= 1024.0
    
    return f"{bytes_size:.1f} PB"
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from src.utils.helpers import (
    format_sources, calculate_confidence, validate_query,
    safe_json_parse, smart_truncate, generate_session_id,
    format_duration
)

# ä¿¡æ¯æºæ ¼å¼åŒ–
sources = [
    {"type": "lightrag_knowledge", "mode": "hybrid", "confidence": 0.85},
    {"type": "web_search", "title": "AIè¶‹åŠ¿", "url": "https://example.com", "score": 0.92}
]
formatted = format_sources(sources)
print(formatted)

# ç½®ä¿¡åº¦è®¡ç®—
confidence = calculate_confidence(
    retrieval_score=0.85,
    content_length=1200,
    entity_coverage=0.8,
    mode_effectiveness=0.9
)
print(f"ç»¼åˆç½®ä¿¡åº¦: {confidence:.2f}")

# æŸ¥è¯¢éªŒè¯
is_valid, message = validate_query("ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ")
print(f"æŸ¥è¯¢æœ‰æ•ˆæ€§: {is_valid}, æ¶ˆæ¯: {message}")

# ä¼šè¯ç®¡ç†
session_id = generate_session_id("demo")
query_id = generate_query_id(session_id)
print(f"ä¼šè¯ID: {session_id}")
print(f"æŸ¥è¯¢ID: {query_id}")

# æ—¶é—´æ ¼å¼åŒ–
duration = 1.234
print(f"å¤„ç†æ—¶é—´: {format_duration(duration)}")
```

---

## æ¨¡å—é›†æˆå’Œä¾èµ–å…³ç³»

### å†…éƒ¨ä¾èµ–å±‚æ¬¡

**åŸºç¡€å±‚**
- `simple_logger.py` - æä¾›åŸºç¡€æ—¥å¿—åŠŸèƒ½

**ä¸­é—´å±‚**  
- `advanced_logging.py` - ä¾èµ–simple_loggerï¼Œæä¾›é«˜çº§æ—¥å¿—
- `error_handling.py` - ä¾èµ–advanced_loggingï¼Œæä¾›é”™è¯¯å¤„ç†

**åº”ç”¨å±‚**
- `system_monitoring.py` - ä¾èµ–loggingå’Œerror_handling
- `helpers.py` - ä¾èµ–loggingå’Œerror_handling

**ä¸šåŠ¡å±‚**
- `lightrag_client.py` - ä¾èµ–æ‰€æœ‰åŸºç¡€å·¥å…·
- `document_processor.py` - ä¾èµ–loggingå’Œhelpers

### å¤–éƒ¨ä¾èµ–å…³ç³»

**è¢«ä¾èµ–æ¨¡å—**
- `src/core/` - é…ç½®å’ŒçŠ¶æ€å®šä¹‰
- `src/agents/` - æ‰€æœ‰å·¥ä½œæµèŠ‚ç‚¹
- `main_app.py` å’Œ `streamlit_app.py` - åº”ç”¨å±‚

**ä¾èµ–çš„å¤–éƒ¨åº“**
- `lightrag` - RAGæ¡†æ¶
- `psycopg2` - PostgreSQLè¿æ¥
- `neo4j` - Neo4jå›¾æ•°æ®åº“é©±åŠ¨
- `psutil` - ç³»ç»Ÿç›‘æ§
- `tavily-python` - ç½‘ç»œæœç´¢API

### æ¨¡å—åˆå§‹åŒ–é¡ºåº

1. **simple_logger** - åŸºç¡€æ—¥å¿—ç³»ç»Ÿ
2. **advanced_logging** - é«˜çº§æ—¥å¿—å’Œæ€§èƒ½ç›‘æ§
3. **error_handling** - é”™è¯¯å¤„ç†æ¡†æ¶
4. **system_monitoring** - ç³»ç»Ÿç›‘æ§ (å¯é€‰ï¼Œåå°è¿è¡Œ)
5. **lightrag_client** - ä¸šåŠ¡æ ¸å¿ƒå®¢æˆ·ç«¯
6. **helpers** - é€šç”¨è¾…åŠ©å·¥å…·

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### æ—¥å¿—ç³»ç»Ÿä¼˜åŒ–

**å¼‚æ­¥æ—¥å¿—å¤„ç†**
```python
# ä½¿ç”¨å¼‚æ­¥æ—¥å¿—å¤„ç†å™¨é¿å…é˜»å¡
handler = logging.handlers.QueueHandler(log_queue)
logger.addHandler(handler)

# åå°çº¿ç¨‹å¤„ç†æ—¥å¿—é˜Ÿåˆ—
log_processor = logging.handlers.QueueListener(
    log_queue, file_handler, console_handler
)
log_processor.start()
```

**æ—¥å¿—çº§åˆ«æ§åˆ¶**
```python
# ç”Ÿäº§ç¯å¢ƒé™ä½æ—¥å¿—çº§åˆ«
if config.DEBUG:
    log_level = logging.DEBUG
else:
    log_level = logging.INFO
```

### LightRAGå®¢æˆ·ç«¯ä¼˜åŒ–

**è¿æ¥æ± ç®¡ç†**
```python
# æ•°æ®åº“è¿æ¥æ± 
connection_pool = psycopg2.pool.ThreadedConnectionPool(
    minconn=1, maxconn=20,
    dsn=config.postgres_url
)
```

**æŸ¥è¯¢ç¼“å­˜**
```python
# æŸ¥è¯¢ç»“æœç¼“å­˜ (ç®€å•LRUç¼“å­˜)
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_query(query_hash: str, mode: str):
    return lightrag_query(query, mode)
```

### ç›‘æ§ç³»ç»Ÿä¼˜åŒ–

**æ‰¹é‡æŒ‡æ ‡å¤„ç†**
```python
# æ‰¹é‡æäº¤æŒ‡æ ‡å‡å°‘I/O
metrics_buffer = []
if len(metrics_buffer) >= batch_size:
    submit_metrics_batch(metrics_buffer)
    metrics_buffer.clear()
```

**é‡‡æ ·ç›‘æ§**
```python
# é«˜é¢‘æ“ä½œé‡‡æ ·ç›‘æ§
if random.random() < sampling_rate:
    record_metric("operation_latency", duration)
```

---

## æ•…éšœæ’é™¤æŒ‡å—

### å¸¸è§é—®é¢˜è¯Šæ–­

**LightRAGå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥**
```python
# è¯Šæ–­æ•°æ®åº“è¿æ¥é—®é¢˜
async def diagnose_lightrag_issues():
    print("ğŸ” è¯Šæ–­LightRAGå®¢æˆ·ç«¯é—®é¢˜...")
    
    # æ£€æŸ¥é…ç½®
    if not config.LLM_API_KEY:
        print("âŒ LLM_API_KEYæœªé…ç½®")
    
    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    postgres_ok = await lightrag_client._check_pgvector()
    neo4j_ok = await lightrag_client._check_neo4j()
    
    print(f"PostgreSQLçŠ¶æ€: {'âœ…' if postgres_ok else 'âŒ'}")
    print(f"Neo4jçŠ¶æ€: {'âœ…' if neo4j_ok else 'âŒ'}")
    
    if not postgres_ok and not neo4j_ok:
        print("âš ï¸  æ‰€æœ‰æ•°æ®åº“ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ–‡ä»¶å­˜å‚¨")
```

**ç³»ç»Ÿç›‘æ§å¼‚å¸¸**
```python
# æ£€æŸ¥ç›‘æ§ç³»ç»ŸçŠ¶æ€
def check_monitoring_health():
    try:
        monitor = SystemMonitor()
        health = monitor.get_system_health()
        print(f"ç›‘æ§ç³»ç»ŸçŠ¶æ€: {health['status']}")
        
        for check_name, result in health['checks'].items():
            status_icon = "âœ…" if result['status'] == 'healthy' else "âŒ"
            print(f"  {status_icon} {check_name}: {result['message']}")
            
    except Exception as e:
        print(f"âŒ ç›‘æ§ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {e}")
```

**æ—¥å¿—ç³»ç»Ÿé—®é¢˜**
```python
# éªŒè¯æ—¥å¿—ç³»ç»Ÿé…ç½®
def verify_logging_setup():
    # æµ‹è¯•ç®€å•æ—¥å¿—
    simple_logger = get_simple_logger("test_simple")
    simple_logger.info("ç®€å•æ—¥å¿—æµ‹è¯•")
    
    # æµ‹è¯•é«˜çº§æ—¥å¿—
    advanced_logger = setup_logger("test_advanced")
    advanced_logger.info("é«˜çº§æ—¥å¿—æµ‹è¯•", extra={"test_field": "test_value"})
    
    # æµ‹è¯•æ€§èƒ½æ—¥å¿—
    perf_logger = get_performance_logger("test_perf")
    perf_logger.start_operation("test_operation")
    time.sleep(0.1)
    perf_logger.end_operation(success=True)
    
    print("âœ… æ—¥å¿—ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
```

### è°ƒè¯•å’Œå¼€å‘å»ºè®®

**å¯ç”¨è¯¦ç»†æ—¥å¿—**
```python
# å¼€å‘ç¯å¢ƒé…ç½®
import logging
logging.basicConfig(level=logging.DEBUG)

# æˆ–è€…é€šè¿‡ç¯å¢ƒå˜é‡
os.environ["LOG_LEVEL"] = "DEBUG"
```

**æ€§èƒ½åˆ†æ**
```python
# ä½¿ç”¨æ€§èƒ½ä¸Šä¸‹æ–‡åˆ†æç“¶é¢ˆ
with performance_context("slow_operation", __name__) as perf:
    # æ‰§è¡Œå¯èƒ½å¾ˆæ…¢çš„æ“ä½œ
    result = slow_function()
    perf.add_metric("items_processed", len(result))
```

**é”™è¯¯è¿½è¸ª**
```python
# ä½¿ç”¨é”™è¯¯è¿½è¸ªè£…é¥°å™¨
@log_errors("critical_operation")
def critical_function():
    # å…³é”®ä¸šåŠ¡é€»è¾‘
    pass
```

---

**ğŸ“ è¯´æ˜**: æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†utilsæ¨¡å—çš„æ‰€æœ‰ç»„ä»¶ã€‚è¿™äº›å·¥å…·æ¨¡å—æ˜¯ç³»ç»Ÿç¨³å®šè¿è¡Œçš„é‡è¦ä¿éšœï¼Œæä¾›äº†å®Œæ•´çš„å¯è§‚æµ‹æ€§å’Œå¯ç»´æŠ¤æ€§æ”¯æŒã€‚