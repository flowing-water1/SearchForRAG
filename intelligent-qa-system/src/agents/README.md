# å·¥ä½œæµèŠ‚ç‚¹æŠ€æœ¯æ–‡æ¡£

> è¿”å› [é¡¹ç›®æ¦‚è§ˆæ–‡æ¡£](../../TECHNICAL_REFERENCE.md)

## ğŸ“ ç›¸å…³æ–‡æ¡£å¯¼èˆª
- **[æ ¸å¿ƒæ¨¡å—æ–‡æ¡£](../core/README.md)** - æŸ¥çœ‹å·¥ä½œæµèŠ‚ç‚¹ä½¿ç”¨çš„é…ç½®ã€çŠ¶æ€å’Œå·¥ä½œæµå®šä¹‰
- **[å·¥å…·æ¨¡å—æ–‡æ¡£](../utils/README.md)** - æŸ¥çœ‹èŠ‚ç‚¹ä½¿ç”¨çš„å®¢æˆ·ç«¯ã€æ—¥å¿—å’Œé”™è¯¯å¤„ç†å·¥å…·
- **[é¡¹ç›®æ ¹ç›®å½•](../../TECHNICAL_REFERENCE.md)** - è¿”å›é¡¹ç›®å®Œæ•´æ¦‚è§ˆ

## ğŸ”— ç›¸å…³æ ¸å¿ƒç»„ä»¶
- [AgentStateå®šä¹‰](../core/README.md#2-çŠ¶æ€å®šä¹‰-statepy) - æ‰€æœ‰èŠ‚ç‚¹å…±äº«çš„çŠ¶æ€æ¥å£
- [å·¥ä½œæµå¼•æ“](../core/README.md#3-åŸºç¡€å·¥ä½œæµ-workflowpy) - èŠ‚ç‚¹çš„æ‰§è¡Œç¯å¢ƒ
- [LightRAGå®¢æˆ·ç«¯](../utils/README.md#5-lightragå®¢æˆ·ç«¯-lightrag_clientpy) - æ£€ç´¢èŠ‚ç‚¹çš„æ ¸å¿ƒä¾èµ–
- [é”™è¯¯å¤„ç†ç³»ç»Ÿ](../utils/README.md#3-é”™è¯¯å¤„ç†æ¡†æ¶-error_handlingpy) - èŠ‚ç‚¹çš„å®¹é”™æœºåˆ¶

---

## æ¨¡å—æ¦‚è¿°

å·¥ä½œæµèŠ‚ç‚¹æ¨¡å— (src/agents/) å®ç°äº†æ™ºèƒ½é—®ç­”ç³»ç»Ÿçš„æ ¸å¿ƒAIä»£ç†ï¼Œæ¯ä¸ªèŠ‚ç‚¹è´Ÿè´£å·¥ä½œæµä¸­çš„ç‰¹å®šæ­¥éª¤ã€‚åŸºäºLangGraphæ¡†æ¶ï¼Œè¿™äº›èŠ‚ç‚¹é€šè¿‡çŠ¶æ€ä¼ é€’ååŒå·¥ä½œï¼Œå®ç°å®Œæ•´çš„Agentic RAGæµç¨‹ã€‚

### æ¨¡å—ç»“æ„
```
src/agents/
â”œâ”€â”€ __init__.py               # æ¨¡å—åˆå§‹åŒ–
â”œâ”€â”€ query_analysis.py        # æŸ¥è¯¢åˆ†æèŠ‚ç‚¹
â”œâ”€â”€ lightrag_retrieval.py    # LightRAGæ£€ç´¢èŠ‚ç‚¹
â”œâ”€â”€ quality_assessment.py    # è´¨é‡è¯„ä¼°èŠ‚ç‚¹
â”œâ”€â”€ web_search.py            # ç½‘ç»œæœç´¢èŠ‚ç‚¹
â””â”€â”€ answer_generation.py     # ç­”æ¡ˆç”ŸæˆèŠ‚ç‚¹
```

### å·¥ä½œæµæ‰§è¡Œé¡ºåº
```
ç”¨æˆ·æŸ¥è¯¢ â†’ æŸ¥è¯¢åˆ†æ â†’ LightRAGæ£€ç´¢ â†’ è´¨é‡è¯„ä¼° â†’ [æ¡ä»¶è·¯ç”±] â†’ ç­”æ¡ˆç”Ÿæˆ
                                        â†“
                                    ç½‘ç»œæœç´¢ â†’ ç­”æ¡ˆç”Ÿæˆ
```

---

## èŠ‚ç‚¹è¯¦è§£

### 1. æŸ¥è¯¢åˆ†æèŠ‚ç‚¹ (query_analysis.py)

**ä¸»è¦åŠŸèƒ½**: åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œç¡®å®šæŸ¥è¯¢ç±»å‹å¹¶é€‰æ‹©æœ€é€‚åˆçš„LightRAGæ£€ç´¢æ¨¡å¼ã€‚

#### æ ¸å¿ƒå‡½æ•°: query_analysis_node

```python
def query_analysis_node(state: AgentState) -> Dict[str, Any]:
    """
    æŸ¥è¯¢åˆ†æèŠ‚ç‚¹
    
    åŠŸèƒ½:
    1. åˆ†ææŸ¥è¯¢æ„å›¾å’Œç±»å‹
    2. é€‰æ‹©æœ€ä½³LightRAGæ£€ç´¢æ¨¡å¼
    3. æå–å…³é”®å®ä½“
    4. ä¼˜åŒ–æŸ¥è¯¢æ–‡æœ¬
    
    æŸ¥è¯¢ç±»å‹æ˜ å°„:
    - FACTUAL â†’ localæ¨¡å¼ (å‘é‡æ£€ç´¢)
    - RELATIONAL â†’ globalæ¨¡å¼ (å›¾æ£€ç´¢)  
    - ANALYTICAL â†’ hybridæ¨¡å¼ (æ··åˆæ£€ç´¢)
    """
```

#### æŸ¥è¯¢ç±»å‹åˆ†ç±»

**FACTUAL (äº‹å®æ€§æŸ¥è¯¢)**
- ç‰¹å¾ï¼šå¯»æ‰¾å…·ä½“äº‹å®ã€å®šä¹‰ã€æ¦‚å¿µ
- æ£€ç´¢æ¨¡å¼ï¼š`local` (å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢)
- ç¤ºä¾‹ï¼š
  - "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
  - "Pythonçš„è¯­æ³•ç‰¹ç‚¹"
  - "æ·±åº¦å­¦ä¹ çš„å®šä¹‰"

**RELATIONAL (å…³ç³»æ€§æŸ¥è¯¢)**
- ç‰¹å¾ï¼šæ¢ç´¢å®ä½“é—´å…³ç³»ã€å½±å“ã€è”ç³»
- æ£€ç´¢æ¨¡å¼ï¼š`global` (å›¾è°±å…³ç³»æ£€ç´¢)
- ç¤ºä¾‹ï¼š
  - "OpenAIå’Œå¾®è½¯çš„å…³ç³»"
  - "AIå¯¹å°±ä¸šå¸‚åœºçš„å½±å“"
  - "å„å¤§ç§‘æŠ€å…¬å¸åœ¨AIé¢†åŸŸçš„ç«äº‰"

**ANALYTICAL (åˆ†ææ€§æŸ¥è¯¢)**
- ç‰¹å¾ï¼šéœ€è¦ç»¼åˆåˆ†æã€æ¨ç†ã€å¤šç»´ä¿¡æ¯
- æ£€ç´¢æ¨¡å¼ï¼š`hybrid` (æ··åˆæ£€ç´¢)
- ç¤ºä¾‹ï¼š
  - "åˆ†æAIå‘å±•è¶‹åŠ¿"
  - "æ¯”è¾ƒä¸åŒæœºå™¨å­¦ä¹ ç®—æ³•"
  - "è¯„ä¼°æŸé¡¹æŠ€æœ¯çš„ä¼˜åŠ£"

#### å®ç°ç»†èŠ‚

**LLMåˆ†ææç¤ºè¯æ„å»º**
```python
def _build_analysis_prompt(user_query: str) -> str:
    """æ„å»ºæŸ¥è¯¢åˆ†ææç¤ºè¯"""
    return f"""
è¯·åˆ†æä»¥ä¸‹æŸ¥è¯¢å¹¶è¿”å›JSONæ ¼å¼ç»“æœï¼š

æŸ¥è¯¢: {user_query}

è¯·åˆ¤æ–­æŸ¥è¯¢ç±»å‹å¹¶é€‰æ‹©æ£€ç´¢æ¨¡å¼ï¼š

1. FACTUAL (äº‹å®æ€§) - å¯»æ‰¾å…·ä½“å®šä¹‰ã€æ¦‚å¿µ â†’ ä½¿ç”¨ local æ¨¡å¼
2. RELATIONAL (å…³ç³»æ€§) - æ¢ç´¢å®ä½“å…³ç³»ã€å½±å“ â†’ ä½¿ç”¨ global æ¨¡å¼  
3. ANALYTICAL (åˆ†ææ€§) - éœ€è¦ç»¼åˆåˆ†ææ¨ç† â†’ ä½¿ç”¨ hybrid æ¨¡å¼

è¿”å›æ ¼å¼ï¼š
{{
  "query_type": "FACTUAL|RELATIONAL|ANALYTICAL",
  "lightrag_mode": "local|global|hybrid", 
  "key_entities": ["å®ä½“1", "å®ä½“2"],
  "processed_query": "ä¼˜åŒ–åçš„æŸ¥è¯¢",
  "reasoning": "é€‰æ‹©åŸå› è¯´æ˜"
}}
"""
```

**ç»“æœéªŒè¯æœºåˆ¶**
```python
def _validate_analysis_result(analysis: dict) -> dict:
    """éªŒè¯åˆ†æç»“æœçš„æœ‰æ•ˆæ€§"""
    
    # é»˜è®¤å€¼è®¾å®š
    defaults = {
        "query_type": "ANALYTICAL",
        "lightrag_mode": "hybrid", 
        "key_entities": [],
        "processed_query": "",
        "reasoning": "åˆ†æç»“æœéªŒè¯å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®"
    }
    
    # éªŒè¯å¿…éœ€å­—æ®µ
    required_fields = ["query_type", "lightrag_mode", "key_entities", "processed_query"]
    
    for field in required_fields:
        if field not in analysis:
            analysis[field] = defaults[field]
    
    # éªŒè¯æŸ¥è¯¢ç±»å‹
    valid_types = ["FACTUAL", "RELATIONAL", "ANALYTICAL"]
    if analysis["query_type"] not in valid_types:
        analysis["query_type"] = "ANALYTICAL"
        analysis["lightrag_mode"] = "hybrid"
    
    # éªŒè¯æ£€ç´¢æ¨¡å¼
    valid_modes = ["local", "global", "hybrid"]
    if analysis["lightrag_mode"] not in valid_modes:
        analysis["lightrag_mode"] = "hybrid"
    
    return analysis
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from src.agents.query_analysis import query_analysis_node
from src.core.state import AgentState

# æ„å»ºè¾“å…¥çŠ¶æ€
initial_state: AgentState = {
    "user_query": "OpenAIå’Œå¾®è½¯çš„åˆä½œå…³ç³»å¦‚ä½•ï¼Ÿ",
    "session_id": "session_123"
}

# æ‰§è¡ŒæŸ¥è¯¢åˆ†æ
result = query_analysis_node(initial_state)

print(f"æŸ¥è¯¢ç±»å‹: {result['query_type']}")        # RELATIONAL
print(f"æ£€ç´¢æ¨¡å¼: {result['lightrag_mode']}")     # global  
print(f"å…³é”®å®ä½“: {result['key_entities']}")      # ["OpenAI", "å¾®è½¯"]
print(f"ä¼˜åŒ–æŸ¥è¯¢: {result['processed_query']}")   # ä¼˜åŒ–åçš„æŸ¥è¯¢æ–‡æœ¬
```

---

### 2. LightRAGæ£€ç´¢èŠ‚ç‚¹ (lightrag_retrieval.py)

**ä¸»è¦åŠŸèƒ½**: ä½¿ç”¨LightRAGæ‰§è¡Œæ™ºèƒ½æ£€ç´¢ï¼Œæ”¯æŒlocal/global/hybridä¸‰ç§æ¨¡å¼ã€‚

#### æ ¸å¿ƒå‡½æ•°: lightrag_retrieval_node

```python
def lightrag_retrieval_node(state: AgentState) -> Dict[str, Any]:
    """
    LightRAGæ£€ç´¢èŠ‚ç‚¹
    
    æ ¹æ®æŸ¥è¯¢åˆ†æç»“æœï¼Œä½¿ç”¨å¯¹åº”çš„LightRAGæ£€ç´¢æ¨¡å¼ï¼š
    - localæ¨¡å¼: åŸºäºå‘é‡ç›¸ä¼¼æ€§çš„è¯­ä¹‰æ£€ç´¢
    - globalæ¨¡å¼: åŸºäºå›¾è°±çš„å…³ç³»æ£€ç´¢
    - hybridæ¨¡å¼: ç»“åˆå‘é‡å’Œå›¾è°±çš„æ··åˆæ£€ç´¢
    """
```

#### æ£€ç´¢æ¨¡å¼è¯¦è§£

**Localæ¨¡å¼ (å‘é‡æ£€ç´¢)**
- åŸç†ï¼šåŸºäºå‘é‡ç›¸ä¼¼åº¦åŒ¹é…
- é€‚ç”¨ï¼šäº‹å®æ€§æŸ¥è¯¢ã€å®šä¹‰æŸ¥æ‰¾
- ä¼˜åŠ¿ï¼šå¿«é€Ÿã€ç²¾ç¡®åŒ¹é…
- ç‰¹ç‚¹ï¼šè¿”å›è¯­ä¹‰ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ

**Globalæ¨¡å¼ (å›¾è°±æ£€ç´¢)**
- åŸç†ï¼šåŸºäºçŸ¥è¯†å›¾è°±å…³ç³»éå†
- é€‚ç”¨ï¼šå…³ç³»æ€§æŸ¥è¯¢ã€å½±å“åˆ†æ
- ä¼˜åŠ¿ï¼šå‘ç°å¤æ‚å…³è”å…³ç³»
- ç‰¹ç‚¹ï¼šè¿”å›å®ä½“é—´çš„å…³ç³»ä¿¡æ¯

**Hybridæ¨¡å¼ (æ··åˆæ£€ç´¢)**
- åŸç†ï¼šç»“åˆå‘é‡æ£€ç´¢å’Œå›¾è°±æ£€ç´¢
- é€‚ç”¨ï¼šå¤æ‚åˆ†ææ€§æŸ¥è¯¢
- ä¼˜åŠ¿ï¼šç»¼åˆä¿¡æ¯è¦†ç›–æœ€å…¨é¢
- ç‰¹ç‚¹ï¼šå¹³è¡¡ç²¾ç¡®æ€§å’Œå…³è”æ€§

#### è´¨é‡è¯„åˆ†æœºåˆ¶

```python
def _calculate_retrieval_quality(content: str, mode: str) -> float:
    """
    è®¡ç®—æ£€ç´¢è´¨é‡åˆ†æ•°
    
    è¯„åˆ†å› å­:
    - å†…å®¹é•¿åº¦å’Œå®Œæ•´æ€§ (40%)
    - æ£€ç´¢æ¨¡å¼åŒ¹é…åº¦ (30%) 
    - ç»“æœç›¸å…³æ€§ (30%)
    
    Returns:
        float: è´¨é‡åˆ†æ•° (0.0-1.0)
    """
    if not content:
        return 0.0
    
    # åŸºç¡€å†…å®¹è´¨é‡ (é•¿åº¦å› å­)
    content_score = min(len(content) / 1000, 1.0)  # 1000å­—ç¬¦ä¸ºæ»¡åˆ†
    
    # æ¨¡å¼åŒ¹é…åº¦åŠ æƒ
    mode_weights = {
        "local": 0.8,   # å‘é‡æ£€ç´¢é€šå¸¸è´¨é‡è¾ƒç¨³å®š
        "global": 0.7,  # å›¾è°±æ£€ç´¢è´¨é‡ä¾èµ–å…³ç³»å®Œæ•´æ€§
        "hybrid": 0.9   # æ··åˆæ¨¡å¼ç»¼åˆæ€§æœ€å¥½
    }
    mode_score = mode_weights.get(mode, 0.5)
    
    # ç»¼åˆè¯„åˆ†
    final_score = (content_score * 0.6) + (mode_score * 0.4)
    return min(final_score, 1.0)
```

#### é”™è¯¯å¤„ç†æœºåˆ¶

```python
# æ£€ç´¢å¼‚å¸¸å¤„ç†
try:
    result = query_lightrag_sync(processed_query, retrieval_mode)
    retrieval_time = time.time() - start_time
    
    if result.get("success", False):
        # æˆåŠŸå¤„ç†é€»è¾‘
        return {
            "lightrag_results": {...},
            "retrieval_score": quality_score,
            "retrieval_success": True
        }
    else:
        # å¤±è´¥å¤„ç†é€»è¾‘  
        logger.error(f"âŒ LightRAG æ£€ç´¢å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        return {
            "lightrag_results": {...},
            "retrieval_score": 0.0,
            "retrieval_success": False
        }
        
except Exception as e:
    # å¼‚å¸¸å¤„ç†é€»è¾‘
    logger.error(f"âŒ LightRAG æ£€ç´¢å¼‚å¸¸: {e}")
    return {
        "lightrag_results": {...},
        "retrieval_score": 0.0, 
        "retrieval_success": False
    }
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from src.agents.lightrag_retrieval import lightrag_retrieval_node

# è¾“å…¥çŠ¶æ€ï¼ˆæ¥è‡ªæŸ¥è¯¢åˆ†æèŠ‚ç‚¹ï¼‰
state_with_analysis = {
    "user_query": "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ",
    "query_type": "FACTUAL",
    "lightrag_mode": "local",
    "processed_query": "æ·±åº¦å­¦ä¹ çš„å®šä¹‰å’ŒåŸºæœ¬æ¦‚å¿µ"
}

# æ‰§è¡Œæ£€ç´¢
retrieval_result = lightrag_retrieval_node(state_with_analysis)

print(f"æ£€ç´¢æˆåŠŸ: {retrieval_result['retrieval_success']}")
print(f"è´¨é‡åˆ†æ•°: {retrieval_result['retrieval_score']:.2f}")
print(f"å†…å®¹é•¿åº¦: {len(retrieval_result['lightrag_results']['content'])}")
```

---

### 3. è´¨é‡è¯„ä¼°èŠ‚ç‚¹ (quality_assessment.py)

**ä¸»è¦åŠŸèƒ½**: è¯„ä¼°LightRAGæ£€ç´¢ç»“æœçš„è´¨é‡ï¼Œå†³å®šæ˜¯å¦éœ€è¦ç½‘ç»œæœç´¢è¡¥å……ã€‚

#### æ ¸å¿ƒå‡½æ•°: quality_assessment_node

```python
def quality_assessment_node(state: AgentState) -> Dict[str, Any]:
    """
    è´¨é‡è¯„ä¼°èŠ‚ç‚¹
    
    è¯„ä¼°ç»´åº¦:
    - æ£€ç´¢æˆåŠŸç‡ (30%)
    - å†…å®¹å®Œæ•´æ€§ (25%) 
    - å®ä½“è¦†ç›–åº¦ (20%)
    - æ¨¡å¼æœ‰æ•ˆæ€§ (15%)
    - æŸ¥è¯¢ç‰¹å¼‚æ€§ (10%)
    """
```

#### å¤šç»´åº¦è¯„ä¼°ä½“ç³»

**è¯„ä¼°ç»´åº¦æƒé‡é…ç½®**
```python
weights = {
    "retrieval_score": 0.3,        # æ£€ç´¢è´¨é‡åˆ†æ•°
    "content_completeness": 0.25,   # å†…å®¹å®Œæ•´æ€§
    "entity_coverage": 0.2,         # å®ä½“è¦†ç›–åº¦
    "mode_effectiveness": 0.15,     # æ¨¡å¼æœ‰æ•ˆæ€§
    "query_specificity": 0.1        # æŸ¥è¯¢ç‰¹å¼‚æ€§
}
```

**ç»¼åˆè¯„ä¼°é€»è¾‘**
```python
def _comprehensive_quality_assessment(state: AgentState) -> QualityAssessment:
    """ç»¼åˆè´¨é‡è¯„ä¼°"""
    
    # è¯„ä¼°å„ä¸ªç»´åº¦
    factors = {
        "retrieval_score": _evaluate_retrieval_score(state),
        "content_completeness": _evaluate_content_completeness(state), 
        "entity_coverage": _evaluate_entity_coverage(state),
        "mode_effectiveness": _evaluate_mode_effectiveness(state),
        "query_specificity": _evaluate_query_specificity(state)
    }
    
    # åŠ æƒè®¡ç®—ç»¼åˆåˆ†æ•°
    weighted_score = sum(
        factors[factor] * weights[factor] 
        for factor in factors
    )
    
    # åŠ¨æ€é˜ˆå€¼è®¡ç®—
    dynamic_threshold = _calculate_dynamic_threshold(state.get("query_type", "ANALYTICAL"))
    
    # å†³ç­–æ˜¯å¦éœ€è¦ç½‘ç»œæœç´¢
    need_web_search = weighted_score < dynamic_threshold
    
    return QualityAssessment(
        confidence_score=weighted_score,
        confidence_breakdown=factors,
        need_web_search=need_web_search,
        threshold=dynamic_threshold,
        reason=_generate_assessment_reason(factors, weighted_score, dynamic_threshold)
    )
```

#### è¯„ä¼°ç»´åº¦è¯¦è§£

**1. æ£€ç´¢æˆåŠŸç‡è¯„ä¼°**
```python
def _evaluate_retrieval_score(state: AgentState) -> float:
    """è¯„ä¼°æ£€ç´¢æˆåŠŸç‡"""
    if not state.get("retrieval_success", False):
        return 0.0
    
    retrieval_score = state.get("retrieval_score", 0.0)
    return min(retrieval_score, 1.0)
```

**2. å†…å®¹å®Œæ•´æ€§è¯„ä¼°**
```python
def _evaluate_content_completeness(state: AgentState) -> float:
    """è¯„ä¼°å†…å®¹å®Œæ•´æ€§"""
    lightrag_results = state.get("lightrag_results", {})
    content = lightrag_results.get("content", "")
    
    if not content:
        return 0.0
    
    # å†…å®¹é•¿åº¦è¯„åˆ†
    length_score = min(len(content) / 800, 1.0)  # 800å­—ç¬¦ä¸ºåŸºå‡†
    
    # ç»“æ„å®Œæ•´æ€§è¯„åˆ† (ç®€å•å¯å‘å¼)
    structure_indicators = [
        "ã€‚" in content,  # åŒ…å«å®Œæ•´å¥å­
        len(content.split()) > 10,  # è¯æ±‡é‡å……è¶³
        not content.endswith("..."),  # å†…å®¹ä¸æˆªæ–­
    ]
    structure_score = sum(structure_indicators) / len(structure_indicators)
    
    return (length_score * 0.7) + (structure_score * 0.3)
```

**3. å®ä½“è¦†ç›–åº¦è¯„ä¼°**
```python
def _evaluate_entity_coverage(state: AgentState) -> float:
    """è¯„ä¼°å…³é”®å®ä½“è¦†ç›–åº¦"""
    key_entities = state.get("key_entities", [])
    if not key_entities:
        return 1.0  # æ²¡æœ‰å…³é”®å®ä½“è¦æ±‚æ—¶è®¤ä¸ºå®Œå…¨è¦†ç›–
    
    lightrag_results = state.get("lightrag_results", {})
    content = lightrag_results.get("content", "").lower()
    
    # æ£€æŸ¥å®ä½“åœ¨å†…å®¹ä¸­çš„å‡ºç°
    covered_entities = 0
    for entity in key_entities:
        if entity.lower() in content:
            covered_entities += 1
    
    coverage_ratio = covered_entities / len(key_entities)
    return coverage_ratio
```

**4. æ¨¡å¼æœ‰æ•ˆæ€§è¯„ä¼°**
```python
def _evaluate_mode_effectiveness(state: AgentState) -> float:
    """è¯„ä¼°æ£€ç´¢æ¨¡å¼æœ‰æ•ˆæ€§"""
    query_type = state.get("query_type", "ANALYTICAL")
    lightrag_mode = state.get("lightrag_mode", "hybrid")
    
    # æ¨¡å¼åŒ¹é…åº¦è¯„åˆ†
    optimal_modes = {
        "FACTUAL": "local",
        "RELATIONAL": "global", 
        "ANALYTICAL": "hybrid"
    }
    
    if optimal_modes.get(query_type) == lightrag_mode:
        return 1.0  # å®Œç¾åŒ¹é…
    elif lightrag_mode == "hybrid":
        return 0.8  # hybridæ¨¡å¼é€šç”¨æ€§å¥½
    else:
        return 0.6  # éƒ¨åˆ†åŒ¹é…
```

**5. æŸ¥è¯¢ç‰¹å¼‚æ€§è¯„ä¼°**
```python
def _evaluate_query_specificity(state: AgentState) -> float:
    """è¯„ä¼°æŸ¥è¯¢ç‰¹å¼‚æ€§"""
    user_query = state.get("user_query", "")
    
    # æŸ¥è¯¢å¤æ‚åº¦æŒ‡æ ‡
    complexity_indicators = [
        len(user_query) > 20,  # æŸ¥è¯¢é•¿åº¦
        "?" in user_query,     # æ˜ç¡®é—®é¢˜
        any(word in user_query.lower() for word in ["å¦‚ä½•", "ä¸ºä»€ä¹ˆ", "ä»€ä¹ˆ", "åˆ†æ"]),  # é—®è¯¢è¯
        len(user_query.split()) > 5,  # è¯æ±‡æ•°é‡
    ]
    
    complexity_score = sum(complexity_indicators) / len(complexity_indicators)
    return complexity_score
```

#### åŠ¨æ€é˜ˆå€¼æœºåˆ¶

```python
def _calculate_dynamic_threshold(query_type: str) -> float:
    """æ ¹æ®æŸ¥è¯¢ç±»å‹è®¡ç®—åŠ¨æ€é˜ˆå€¼"""
    
    base_thresholds = {
        "FACTUAL": 0.7,      # äº‹å®æ€§æŸ¥è¯¢è¦æ±‚é«˜ç²¾ç¡®åº¦
        "RELATIONAL": 0.6,   # å…³ç³»æ€§æŸ¥è¯¢è¦æ±‚ä¸­ç­‰ç²¾ç¡®åº¦
        "ANALYTICAL": 0.5    # åˆ†ææ€§æŸ¥è¯¢å®¹å¿åº¦æ›´é«˜
    }
    
    return base_thresholds.get(query_type, 0.6)
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from src.agents.quality_assessment import quality_assessment_node

# è¾“å…¥çŠ¶æ€ï¼ˆæ¥è‡ªæ£€ç´¢èŠ‚ç‚¹ï¼‰
state_with_retrieval = {
    "user_query": "æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„åŒºåˆ«",
    "query_type": "ANALYTICAL", 
    "lightrag_mode": "hybrid",
    "key_entities": ["æ·±åº¦å­¦ä¹ ", "æœºå™¨å­¦ä¹ "],
    "lightrag_results": {
        "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†...(800å­—å†…å®¹)",
        "mode": "hybrid"
    },
    "retrieval_success": True,
    "retrieval_score": 0.85
}

# æ‰§è¡Œè´¨é‡è¯„ä¼°
assessment_result = quality_assessment_node(state_with_retrieval)

print(f"ç»¼åˆç½®ä¿¡åº¦: {assessment_result['confidence_score']:.2f}")
print(f"éœ€è¦ç½‘ç»œæœç´¢: {assessment_result['need_web_search']}")
print(f"è¯„ä¼°åŸå› : {assessment_result['assessment_reason']}")

# æŸ¥çœ‹è¯¦ç»†åˆ†è§£
for factor, score in assessment_result['confidence_breakdown'].items():
    print(f"  {factor}: {score:.2f}")
```

---

### 4. ç½‘ç»œæœç´¢èŠ‚ç‚¹ (web_search.py)

**ä¸»è¦åŠŸèƒ½**: å½“æœ¬åœ°ä¿¡æ¯ä¸è¶³æ—¶ï¼Œä½¿ç”¨Tavily APIè¿›è¡Œç½‘ç»œæœç´¢è¡¥å……ã€‚

#### æ ¸å¿ƒå‡½æ•°: web_search_node

```python
def web_search_node(state: AgentState) -> Dict[str, Any]:
    """
    ç½‘ç»œæœç´¢èŠ‚ç‚¹
    
    æœç´¢ç­–ç•¥:
    - æ ¹æ®æŸ¥è¯¢ç±»å‹è°ƒæ•´æœç´¢æ·±åº¦
    - åŠ¨æ€è°ƒæ•´ç»“æœæ•°é‡
    - ä¼˜åŒ–æœç´¢æŸ¥è¯¢
    - ç»“æœè¿‡æ»¤å’Œæ’åº
    """
```

#### æ¡ä»¶æ‰§è¡Œæœºåˆ¶

```python
# æ£€æŸ¥æ˜¯å¦éœ€è¦ç½‘ç»œæœç´¢
need_web_search = state.get("need_web_search", False)
if not need_web_search:
    logger.info("æ— éœ€ç½‘ç»œæœç´¢ï¼Œè·³è¿‡æ­¤èŠ‚ç‚¹")
    return {"web_results": []}

# æ£€æŸ¥APIå¯†é’¥é…ç½®
if not config.TAVILY_API_KEY:
    logger.error("Tavily APIå¯†é’¥æœªé…ç½®ï¼Œæ— æ³•è¿›è¡Œç½‘ç»œæœç´¢")
    return {
        "web_results": [],
        "web_search_summary": "APIå¯†é’¥æœªé…ç½®ï¼Œç½‘ç»œæœç´¢å¤±è´¥"
    }
```

#### æœç´¢ç­–ç•¥ä¼˜åŒ–

**æŸ¥è¯¢ä¼˜åŒ–æœºåˆ¶**
```python
def _build_search_query(state: AgentState) -> str:
    """æ„å»ºä¼˜åŒ–çš„æœç´¢æŸ¥è¯¢"""
    user_query = state.get("user_query", "")
    query_type = state.get("query_type", "ANALYTICAL")
    key_entities = state.get("key_entities", [])
    
    # åŸºç¡€æŸ¥è¯¢ä¼˜åŒ–
    optimized_query = user_query
    
    # æ ¹æ®æŸ¥è¯¢ç±»å‹æ·»åŠ ä¿®é¥°è¯
    if query_type == "FACTUAL":
        optimized_query = f"ä»€ä¹ˆæ˜¯ {optimized_query} å®šä¹‰ æ¦‚å¿µ"
    elif query_type == "RELATIONAL": 
        optimized_query = f"{optimized_query} å…³ç³» å½±å“ è”ç³»"
    elif query_type == "ANALYTICAL":
        optimized_query = f"{optimized_query} åˆ†æ è¶‹åŠ¿ è¯„ä¼°"
    
    # æ·»åŠ å…³é”®å®ä½“å¢å¼º
    if key_entities:
        entity_string = " ".join(key_entities[:3])  # æœ€å¤š3ä¸ªå®ä½“
        optimized_query = f"{optimized_query} {entity_string}"
    
    return optimized_query
```

**æœç´¢å‚æ•°é…ç½®**
```python
def _get_search_parameters(state: AgentState) -> dict:
    """æ ¹æ®æŸ¥è¯¢ç±»å‹é…ç½®æœç´¢å‚æ•°"""
    query_type = state.get("query_type", "ANALYTICAL")
    
    # åŸºç¡€æœç´¢å‚æ•°
    base_params = {
        "max_results": 5,
        "search_depth": "basic",
        "include_answer": True,
        "include_raw_content": False
    }
    
    # æ ¹æ®æŸ¥è¯¢ç±»å‹è°ƒæ•´å‚æ•°
    if query_type == "FACTUAL":
        base_params.update({
            "max_results": 3,  # äº‹å®æ€§æŸ¥è¯¢éœ€è¦ç²¾ç¡®ç»“æœ
            "search_depth": "basic"
        })
    elif query_type == "RELATIONAL":
        base_params.update({
            "max_results": 5,  # å…³ç³»æ€§æŸ¥è¯¢éœ€è¦å¤šä¸ªæ¥æº
            "search_depth": "advanced"
        })
    elif query_type == "ANALYTICAL":
        base_params.update({
            "max_results": 7,  # åˆ†ææ€§æŸ¥è¯¢éœ€è¦å…¨é¢ä¿¡æ¯
            "search_depth": "advanced"
        })
    
    return base_params
```

#### æœç´¢æ‰§è¡Œæœºåˆ¶

```python
def _execute_web_search(state: AgentState) -> List[Dict[str, Any]]:
    """æ‰§è¡Œç½‘ç»œæœç´¢"""
    
    # æ„å»ºæœç´¢æŸ¥è¯¢å’Œå‚æ•°
    search_query = _build_search_query(state)
    search_params = _get_search_parameters(state)
    
    logger.info(f"æœç´¢æŸ¥è¯¢: {search_query}")
    logger.info(f"æœç´¢å‚æ•°: {search_params}")
    
    try:
        # åˆå§‹åŒ–Tavilyæœç´¢å®¢æˆ·ç«¯
        tavily = TavilySearchAPIWrapper(api_key=config.TAVILY_API_KEY)
        
        # æ‰§è¡Œæœç´¢
        search_results = tavily.search(
            query=search_query,
            **search_params
        )
        
        # å¤„ç†æœç´¢ç»“æœ
        if search_results and isinstance(search_results, list):
            return search_results
        else:
            logger.warning(f"æœç´¢è¿”å›æ ¼å¼å¼‚å¸¸: {type(search_results)}")
            return []
            
    except Exception as e:
        logger.error(f"Tavilyæœç´¢æ‰§è¡Œå¤±è´¥: {e}")
        return []
```

#### ç»“æœå¤„ç†å’Œè¿‡æ»¤

```python
def _process_search_results(search_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """å¤„ç†å’Œè¿‡æ»¤æœç´¢ç»“æœ"""
    
    processed_results = []
    
    for result in search_results:
        try:
            # æå–æ ‡å‡†åŒ–å­—æ®µ
            processed_result = {
                "title": result.get("title", ""),
                "content": result.get("content", ""),
                "url": result.get("url", ""),
                "score": result.get("score", 0.0),
                "source_type": "web_search",
                "published_date": result.get("published_date", ""),
                "raw_content": result.get("raw_content", "")
            }
            
            # å†…å®¹è´¨é‡è¿‡æ»¤
            if len(processed_result["content"]) < 50:
                continue  # è·³è¿‡å†…å®¹è¿‡çŸ­çš„ç»“æœ
            
            if not processed_result["title"]:
                continue  # è·³è¿‡æ²¡æœ‰æ ‡é¢˜çš„ç»“æœ
            
            processed_results.append(processed_result)
            
        except Exception as e:
            logger.warning(f"å¤„ç†æœç´¢ç»“æœæ—¶å‡ºé”™: {e}")
            continue
    
    # æŒ‰åˆ†æ•°æ’åº
    processed_results.sort(key=lambda x: x.get("score", 0), reverse=True)
    
    # é™åˆ¶ç»“æœæ•°é‡
    return processed_results[:5]
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from src.agents.web_search import web_search_node

# è¾“å…¥çŠ¶æ€ï¼ˆæ¥è‡ªè´¨é‡è¯„ä¼°èŠ‚ç‚¹ï¼‰
state_needing_search = {
    "user_query": "2024å¹´AIæœ€æ–°å‘å±•è¶‹åŠ¿",
    "query_type": "ANALYTICAL",
    "need_web_search": True,
    "key_entities": ["AI", "äººå·¥æ™ºèƒ½", "2024"],
    "confidence_score": 0.4  # ä½äºé˜ˆå€¼ï¼Œéœ€è¦æœç´¢
}

# æ‰§è¡Œç½‘ç»œæœç´¢
search_result = web_search_node(state_needing_search)

print(f"æœç´¢ç»“æœæ•°é‡: {len(search_result['web_results'])}")
print(f"æœç´¢æ‘˜è¦: {search_result['web_search_summary']}")

# æŸ¥çœ‹æœç´¢ç»“æœ
for i, result in enumerate(search_result['web_results']):
    print(f"\nç»“æœ {i+1}:")
    print(f"  æ ‡é¢˜: {result['title']}")
    print(f"  åˆ†æ•°: {result['score']:.2f}")
    print(f"  URL: {result['url']}")
    print(f"  å†…å®¹: {result['content'][:100]}...")
```

---

### 5. ç­”æ¡ˆç”ŸæˆèŠ‚ç‚¹ (answer_generation.py)

**ä¸»è¦åŠŸèƒ½**: æ•´åˆæ‰€æœ‰ä¿¡æ¯æºï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼Œæä¾›æ¥æºæ ‡æ³¨ã€‚

#### æ ¸å¿ƒå‡½æ•°: answer_generation_node

```python
def answer_generation_node(state: AgentState) -> Dict[str, Any]:
    """
    ç­”æ¡ˆç”ŸæˆèŠ‚ç‚¹
    
    åŠŸèƒ½:
    1. å¤šæºä¿¡æ¯æ•´åˆ
    2. æ™ºèƒ½ç­”æ¡ˆç”Ÿæˆ
    3. æ¥æºæ ‡æ³¨å’Œè¿½è¸ª
    4. ç½®ä¿¡åº¦è®¡ç®—
    
    ä¿¡æ¯æºä¼˜å…ˆçº§:
    1. LightRAGæœ¬åœ°çŸ¥è¯† (ä¼˜å…ˆ)
    2. ç½‘ç»œæœç´¢ç»“æœ (è¡¥å……)
    3. å›¾è°±å…³ç³»ä¿¡æ¯ (å¢å¼º)
    """
```

#### ä¿¡æ¯æºæ•´åˆæœºåˆ¶

**ä¸Šä¸‹æ–‡ä¿¡æ¯æ”¶é›†**
```python
def _collect_context_information(state: AgentState) -> Dict[str, Any]:
    """æ”¶é›†æ‰€æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    
    context_info = {
        "context_parts": [],
        "source_types": [],
        "primary_source": None,
        "supplementary_sources": []
    }
    
    # 1. æ”¶é›†LightRAGæ£€ç´¢ç»“æœ
    lightrag_results = state.get("lightrag_results", {})
    if lightrag_results.get("content"):
        context_info["context_parts"].append({
            "content": lightrag_results["content"],
            "source": "lightrag_knowledge",
            "mode": lightrag_results.get("mode", "unknown"),
            "priority": 1  # æœ€é«˜ä¼˜å…ˆçº§
        })
        context_info["primary_source"] = "lightrag_knowledge"
        context_info["source_types"].append("æœ¬åœ°çŸ¥è¯†åº“")
    
    # 2. æ”¶é›†ç½‘ç»œæœç´¢ç»“æœ
    web_results = state.get("web_results", [])
    for web_result in web_results[:3]:  # æœ€å¤šä½¿ç”¨å‰3ä¸ªæœç´¢ç»“æœ
        context_info["context_parts"].append({
            "content": web_result.get("content", ""),
            "title": web_result.get("title", ""),
            "url": web_result.get("url", ""),
            "source": "web_search", 
            "priority": 2  # æ¬¡è¦ä¼˜å…ˆçº§
        })
        if "ç½‘ç»œæœç´¢" not in context_info["source_types"]:
            context_info["source_types"].append("ç½‘ç»œæœç´¢")
        context_info["supplementary_sources"].append("web_search")
    
    # 3. ç»Ÿè®¡ä¿¡æ¯æº
    context_info["total_sources"] = len(context_info["context_parts"])
    context_info["has_local_knowledge"] = any(
        part["source"] == "lightrag_knowledge" 
        for part in context_info["context_parts"]
    )
    context_info["has_web_supplement"] = any(
        part["source"] == "web_search" 
        for part in context_info["context_parts"]
    )
    
    return context_info
```

#### ç­”æ¡ˆç”Ÿæˆæç¤ºè¯æ„å»º

```python
def _build_answer_prompt(state: AgentState, context_info: Dict[str, Any]) -> str:
    """æ„å»ºç­”æ¡ˆç”Ÿæˆæç¤ºè¯"""
    
    user_query = state.get("user_query", "")
    query_type = state.get("query_type", "ANALYTICAL")
    lightrag_mode = state.get("lightrag_mode", "hybrid")
    
    # æ„å»ºä¸Šä¸‹æ–‡å†…å®¹
    context_sections = []
    
    for i, context_part in enumerate(context_info["context_parts"]):
        source_type = context_part["source"]
        content = context_part["content"]
        
        if source_type == "lightrag_knowledge":
            context_sections.append(f"ã€æœ¬åœ°çŸ¥è¯†åº“ - {context_part.get('mode', 'unknown')}æ¨¡å¼ã€‘\n{content}")
        elif source_type == "web_search":
            title = context_part.get("title", "ç½‘ç»œèµ„æ–™")
            context_sections.append(f"ã€ç½‘ç»œæœç´¢ç»“æœ - {title}ã€‘\n{content}")
    
    # æ„å»ºå®Œæ•´æç¤ºè¯
    prompt = f"""
è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œè¦æ±‚å‡†ç¡®ã€å…¨é¢ã€æœ‰æ¡ç†ã€‚

ç”¨æˆ·é—®é¢˜: {user_query}
æŸ¥è¯¢ç±»å‹: {query_type}
æ£€ç´¢æ¨¡å¼: {lightrag_mode}

å‚è€ƒä¿¡æ¯:
{chr(10).join(context_sections)}

å›ç­”è¦æ±‚:
1. ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œé¿å…é‡å¤é—®é¢˜å†…å®¹
2. ä¼˜å…ˆä½¿ç”¨æœ¬åœ°çŸ¥è¯†åº“ä¿¡æ¯ï¼Œç”¨ç½‘ç»œä¿¡æ¯è¡¥å……
3. ä¿æŒå›ç­”çš„é€»è¾‘æ¸…æ™°å’Œç»“æ„å®Œæ•´
4. å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯šå®è¯´æ˜å±€é™æ€§
5. æ ¹æ®æŸ¥è¯¢ç±»å‹è°ƒæ•´å›ç­”é£æ ¼ï¼š
   - FACTUAL: æä¾›å‡†ç¡®å®šä¹‰å’Œäº‹å®
   - RELATIONAL: é‡ç‚¹é˜è¿°å…³ç³»å’Œå½±å“
   - ANALYTICAL: è¿›è¡Œæ·±å…¥åˆ†æå’Œæ€»ç»“

è¯·ç”Ÿæˆå›ç­”ï¼š
"""
    
    return prompt
```

#### LLMç­”æ¡ˆç”Ÿæˆ

```python
def _generate_answer_with_llm(answer_prompt: str) -> str:
    """ä½¿ç”¨LLMç”Ÿæˆç­”æ¡ˆ"""
    
    try:
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        llm = ChatOpenAI(
            model=config.LLM_MODEL,
            temperature=config.LLM_TEMPERATURE,
            max_tokens=config.LLM_MAX_TOKENS,
            api_key=config.LLM_API_KEY,
            base_url=config.LLM_BASE_URL
        )
        
        # ç”Ÿæˆç­”æ¡ˆ
        response = llm.invoke(answer_prompt)
        final_answer = response.content.strip()
        
        # ç­”æ¡ˆè´¨é‡æ£€æŸ¥
        if len(final_answer) < 50:
            return "æŠ±æ­‰ï¼Œç”Ÿæˆçš„ç­”æ¡ˆè¿‡çŸ­ï¼Œè¯·é‡æ–°æé—®æˆ–æä¾›æ›´å¤šä¸Šä¸‹æ–‡ã€‚"
        
        return final_answer
        
    except Exception as e:
        logger.error(f"LLMç­”æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
        return f"æŠ±æ­‰ï¼Œç­”æ¡ˆç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
```

#### ç­”æ¡ˆç½®ä¿¡åº¦è®¡ç®—

```python
def _calculate_answer_confidence(state: AgentState, context_info: Dict[str, Any]) -> float:
    """è®¡ç®—ç­”æ¡ˆç½®ä¿¡åº¦"""
    
    confidence_factors = []
    
    # 1. ä¿¡æ¯æºè´¨é‡å› å­ (40%)
    source_quality = 0.0
    if context_info.get("has_local_knowledge"):
        source_quality += 0.7  # æœ¬åœ°çŸ¥è¯†åº“è´¡çŒ®
    if context_info.get("has_web_supplement"):
        source_quality += 0.3  # ç½‘ç»œæœç´¢è´¡çŒ®
    confidence_factors.append(("source_quality", source_quality, 0.4))
    
    # 2. ä¿¡æ¯æºæ•°é‡å› å­ (20%)
    source_count = context_info.get("total_sources", 0)
    source_count_score = min(source_count / 3.0, 1.0)  # 3ä¸ªæ¥æºä¸ºæ»¡åˆ†
    confidence_factors.append(("source_count", source_count_score, 0.2))
    
    # 3. æ£€ç´¢æˆåŠŸç‡å› å­ (25%)
    retrieval_success = state.get("retrieval_success", False)
    retrieval_score = state.get("retrieval_score", 0.0) if retrieval_success else 0.0
    confidence_factors.append(("retrieval_quality", retrieval_score, 0.25))
    
    # 4. è´¨é‡è¯„ä¼°å› å­ (15%)
    confidence_score = state.get("confidence_score", 0.0)
    confidence_factors.append(("confidence_assessment", confidence_score, 0.15))
    
    # åŠ æƒè®¡ç®—æ€»ç½®ä¿¡åº¦
    total_confidence = sum(
        score * weight 
        for _, score, weight in confidence_factors
    )
    
    return min(total_confidence, 1.0)
```

#### ä¿¡æ¯æ¥æºæ•´ç†

```python
def _organize_sources(context_info: Dict[str, Any]) -> List[Dict[str, Any]]:
    """æ•´ç†ä¿¡æ¯æ¥æºåˆ—è¡¨"""
    
    sources = []
    
    for context_part in context_info["context_parts"]:
        source_info = {
            "type": context_part["source"],
            "confidence": 0.0
        }
        
        if context_part["source"] == "lightrag_knowledge":
            source_info.update({
                "content": context_part["content"][:200] + "...",  # æˆªå–é¢„è§ˆ
                "mode": context_part.get("mode", "unknown"),
                "confidence": 0.8
            })
        elif context_part["source"] == "web_search":
            source_info.update({
                "title": context_part.get("title", "ç½‘ç»œèµ„æ–™"),
                "url": context_part.get("url", ""),
                "content": context_part["content"][:200] + "...",
                "confidence": 0.6
            })
        
        sources.append(source_info)
    
    # æŒ‰ç½®ä¿¡åº¦æ’åº
    sources.sort(key=lambda x: x.get("confidence", 0), reverse=True)
    
    return sources
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
from src.agents.answer_generation import answer_generation_node

# è¾“å…¥çŠ¶æ€ï¼ˆåŒ…å«æ‰€æœ‰å‰åºèŠ‚ç‚¹ç»“æœï¼‰
complete_state = {
    "user_query": "æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
    "query_type": "ANALYTICAL",
    "lightrag_mode": "hybrid",
    "lightrag_results": {
        "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸ...(è¯¦ç»†å†…å®¹)",
        "mode": "hybrid"
    },
    "retrieval_success": True,
    "retrieval_score": 0.85,
    "confidence_score": 0.75,
    "need_web_search": True,
    "web_results": [
        {
            "title": "æ·±åº¦å­¦ä¹ vsæœºå™¨å­¦ä¹ ï¼šå®Œæ•´å¯¹æ¯”æŒ‡å—",
            "content": "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ...(ç½‘ç»œå†…å®¹)",
            "url": "https://example.com/article",
            "score": 0.9
        }
    ]
}

# æ‰§è¡Œç­”æ¡ˆç”Ÿæˆ
final_result = answer_generation_node(complete_state)

print(f"æœ€ç»ˆç­”æ¡ˆ:\n{final_result['final_answer']}")
print(f"\nç­”æ¡ˆç½®ä¿¡åº¦: {final_result['answer_confidence']:.2f}")
print(f"ä½¿ç”¨çš„ä¿¡æ¯æºæ•°é‡: {final_result['context_used']}")
print(f"æ£€ç´¢æ¨¡å¼: {final_result['lightrag_mode_used']}")

# æŸ¥çœ‹ä¿¡æ¯æ¥æº
print(f"\nä¿¡æ¯æ¥æº:")
for i, source in enumerate(final_result['sources']):
    print(f"  {i+1}. {source['type']} (ç½®ä¿¡åº¦: {source.get('confidence', 0):.2f})")
    if source.get('title'):
        print(f"     æ ‡é¢˜: {source['title']}")
    if source.get('url'):
        print(f"     é“¾æ¥: {source['url']}")
```

---

## èŠ‚ç‚¹åä½œæœºåˆ¶

### çŠ¶æ€ä¼ é€’æµç¨‹

1. **æŸ¥è¯¢åˆ†æ** â†’ è¯†åˆ«æŸ¥è¯¢ç±»å‹ï¼Œé€‰æ‹©æ£€ç´¢æ¨¡å¼
2. **LightRAGæ£€ç´¢** â†’ æ‰§è¡Œæœ¬åœ°çŸ¥è¯†æ£€ç´¢ï¼Œè¯„ä¼°è´¨é‡
3. **è´¨é‡è¯„ä¼°** â†’ å¤šç»´åº¦è¯„ä¼°ï¼Œå†³å®šæ˜¯å¦éœ€è¦è¡¥å……æœç´¢
4. **ç½‘ç»œæœç´¢** (æ¡ä»¶æ€§) â†’ è¡¥å……æœ€æ–°ä¿¡æ¯
5. **ç­”æ¡ˆç”Ÿæˆ** â†’ æ•´åˆæ‰€æœ‰ä¿¡æ¯ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

### é”™è¯¯å¤„ç†ç­–ç•¥

**èŠ‚ç‚¹çº§é”™è¯¯å¤„ç†**
- æ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰ç‹¬ç«‹çš„å¼‚å¸¸æ•è·
- å¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
- è¯¦ç»†çš„é”™è¯¯æ—¥å¿—è®°å½•

**å·¥ä½œæµçº§å®¹é”™æœºåˆ¶**
- æŸä¸ªèŠ‚ç‚¹å¤±è´¥ä¸å½±å“åç»­èŠ‚ç‚¹æ‰§è¡Œ
- æ™ºèƒ½é™çº§å¤„ç† (å¦‚æ£€ç´¢å¤±è´¥æ—¶ç›´æ¥è¿›è¡Œç½‘ç»œæœç´¢)
- å¤šé‡å¤‡é€‰æ–¹æ¡ˆ

### æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

**å¹¶è¡Œå¤„ç†å¯èƒ½**
- æŸ¥è¯¢åˆ†æå’ŒæŸäº›é¢„å¤„ç†å¯ä»¥å¹¶è¡Œ
- ç½‘ç»œæœç´¢å¯ä»¥å¼‚æ­¥æ‰§è¡Œ
- ç¼“å­˜æœºåˆ¶å‡å°‘é‡å¤è®¡ç®—

**èµ„æºç®¡ç†**
- åˆç†çš„LLMè°ƒç”¨æ¬¡æ•°æ§åˆ¶
- ç½‘ç»œæœç´¢ç»“æœæ•°é‡é™åˆ¶
- å†…å­˜ä½¿ç”¨ä¼˜åŒ–

---

## æ‰©å±•å¼€å‘æŒ‡å—

### æ·»åŠ æ–°èŠ‚ç‚¹

1. **åˆ›å»ºèŠ‚ç‚¹æ–‡ä»¶**
```python
# src/agents/new_node.py
def new_node_function(state: AgentState) -> Dict[str, Any]:
    """æ–°èŠ‚ç‚¹åŠŸèƒ½æè¿°"""
    
    # è·å–æ‰€éœ€çš„çŠ¶æ€ä¿¡æ¯
    input_data = state.get("input_field", "")
    
    # æ‰§è¡ŒèŠ‚ç‚¹é€»è¾‘
    try:
        result = process_data(input_data)
        
        return {
            "new_field": result,
            "success": True
        }
        
    except Exception as e:
        logger.error(f"æ–°èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {e}")
        return {
            "new_field": "",
            "success": False
        }
```

2. **æ›´æ–°çŠ¶æ€å®šä¹‰**
```python
# åœ¨ src/core/state.py ä¸­æ·»åŠ æ–°å­—æ®µ
class AgentState(TypedDict):
    # ç°æœ‰å­—æ®µ...
    new_field: str
    success: bool
```

3. **åœ¨å·¥ä½œæµä¸­æ³¨å†Œ**
```python
# åœ¨ workflow.py æˆ– enhanced_workflow.py ä¸­
def _add_nodes(self):
    # ç°æœ‰èŠ‚ç‚¹...
    self.graph.add_node("new_node", new_node_function)

def _add_edges(self):
    # æ·»åŠ è¿æ¥
    self.graph.add_edge("previous_node", "new_node")
    self.graph.add_edge("new_node", "next_node")
```

### èŠ‚ç‚¹åŠŸèƒ½æ‰©å±•

**å¢å¼ºæŸ¥è¯¢åˆ†æ**
- æ·»åŠ æ›´å¤æ‚çš„æŸ¥è¯¢åˆ†ç±»é€»è¾‘
- æ”¯æŒå¤šè¯­è¨€æŸ¥è¯¢åˆ†æ
- é›†æˆæ„å›¾è¯†åˆ«æ¨¡å‹

**ä¼˜åŒ–æ£€ç´¢ç­–ç•¥**
- å®ç°adaptiveæ£€ç´¢æ¨¡å¼
- æ·»åŠ æ£€ç´¢ç»“æœæ’åºç®—æ³•
- æ”¯æŒå¤šè½®æ£€ç´¢

**å¢å¼ºè´¨é‡è¯„ä¼°**
- æ·»åŠ æ›´å¤šè¯„ä¼°ç»´åº¦
- å®ç°æœºå™¨å­¦ä¹ è¯„ä¼°æ¨¡å‹
- æ”¯æŒç”¨æˆ·åé¦ˆå­¦ä¹ 

**æ‰©å±•æœç´¢åŠŸèƒ½**
- æ”¯æŒå¤šä¸ªæœç´¢å¼•æ“
- æ·»åŠ æœç´¢ç»“æœå»é‡
- å®ç°æ™ºèƒ½æœç´¢ç­–ç•¥

**ä¼˜åŒ–ç­”æ¡ˆç”Ÿæˆ**
- æ”¯æŒä¸åŒç­”æ¡ˆé£æ ¼
- æ·»åŠ å¤šè½®å¯¹è¯èƒ½åŠ›
- å®ç°ç­”æ¡ˆä¸ªæ€§åŒ–

---

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜è¯Šæ–­

**æŸ¥è¯¢åˆ†æå¤±è´¥**
```python
# æ£€æŸ¥LLMé…ç½®
from src.core.config import config

def test_query_analysis():
    if not config.LLM_API_KEY:
        print("âŒ LLM APIå¯†é’¥æœªé…ç½®")
        return False
    
    # æµ‹è¯•ç®€å•æŸ¥è¯¢åˆ†æ
    from src.agents.query_analysis import query_analysis_node
    
    test_state = {"user_query": "ä»€ä¹ˆæ˜¯AIï¼Ÿ", "session_id": "test"}
    try:
        result = query_analysis_node(test_state)
        print("âœ… æŸ¥è¯¢åˆ†ææ­£å¸¸")
        return True
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢åˆ†æå¤±è´¥: {e}")
        return False
```

**æ£€ç´¢èŠ‚ç‚¹é—®é¢˜**
```python
def test_lightrag_retrieval():
    # æ£€æŸ¥LightRAGå®¢æˆ·ç«¯
    from src.utils.lightrag_client import query_lightrag_sync
    
    try:
        result = query_lightrag_sync("æµ‹è¯•æŸ¥è¯¢", "local")
        if result.get("success"):
            print("âœ… LightRAGæ£€ç´¢æ­£å¸¸")
        else:
            print(f"âŒ LightRAGæ£€ç´¢å¤±è´¥: {result.get('error')}")
    except Exception as e:
        print(f"âŒ LightRAGæ£€ç´¢å¼‚å¸¸: {e}")
```

**ç½‘ç»œæœç´¢é—®é¢˜**
```python
def test_web_search():
    from src.core.config import config
    
    if not config.TAVILY_API_KEY:
        print("âŒ Tavily APIå¯†é’¥æœªé…ç½®")
        return False
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    try:
        from tavily import TavilySearchAPIWrapper
        tavily = TavilySearchAPIWrapper(api_key=config.TAVILY_API_KEY)
        results = tavily.search("AIå‘å±•", max_results=1)
        print("âœ… ç½‘ç»œæœç´¢æ­£å¸¸")
        return True
    except Exception as e:
        print(f"âŒ ç½‘ç»œæœç´¢å¤±è´¥: {e}")
        return False
```

### æ€§èƒ½è°ƒä¼˜å»ºè®®

**èŠ‚ç‚¹æ‰§è¡Œæ—¶é—´ä¼˜åŒ–**
- ç›‘æ§æ¯ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œæ—¶é—´
- ä¼˜åŒ–LLMè°ƒç”¨å‚æ•°
- å®ç°ç»“æœç¼“å­˜æœºåˆ¶

**å†…å­˜ä½¿ç”¨ä¼˜åŒ–**
- åŠæ—¶æ¸…ç†å¤§å‹æ•°æ®ç»“æ„
- æ§åˆ¶ä¸Šä¸‹æ–‡ä¿¡æ¯å¤§å°
- ä¼˜åŒ–çŠ¶æ€æ•°æ®ä¼ é€’

**å¹¶å‘æ€§èƒ½æå‡**
- ä½¿ç”¨å¼‚æ­¥å¤„ç†
- å®ç°èŠ‚ç‚¹é—´å¹¶è¡Œæ‰§è¡Œ
- ä¼˜åŒ–I/Oæ“ä½œ

---

**ğŸ“ è¯´æ˜**: æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†æ‰€æœ‰å·¥ä½œæµèŠ‚ç‚¹çš„å®ç°ç»†èŠ‚ã€‚å¦‚éœ€äº†è§£å…¶ä»–æ¨¡å—ï¼Œè¯·æŸ¥çœ‹å¯¹åº”çš„æŠ€æœ¯æ–‡æ¡£ã€‚