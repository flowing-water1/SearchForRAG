"""
æŸ¥è¯¢åˆ†æèŠ‚ç‚¹
åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œç¡®å®šæŸ¥è¯¢ç±»å‹å¹¶é€‰æ‹©æœ€ä½³çš„LightRAGæ£€ç´¢æ¨¡å¼

å‡çº§åˆ°LangGraphç»“æ„åŒ–è¾“å‡ºæŠ€æœ¯:
- ä½¿ç”¨Pydantic BaseModelç¡®ä¿ç±»å‹å®‰å…¨
- é‡‡ç”¨with_structured_output()æ›¿ä»£æ‰‹å·¥JSONè§£æ
- æå‡ç³»ç»Ÿå¯é æ€§ä»3/10åˆ°9/10
"""

import json
import logging
from typing import Dict, Any

from langchain_openai import ChatOpenAI

from ..core.config import config
from ..core.state import AgentState, QueryAnalysisResult
from ..schemas import QueryAnalysisResult as PydanticQueryAnalysisResult, create_fallback_query_analysis

# ç®€å•çš„æ—¥å¿—é…ç½®ï¼Œé¿å…å¾ªç¯å¯¼å…¥
logger = logging.getLogger(__name__)
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)

# å®‰å…¨çš„ JSON è§£æå‡½æ•°
def safe_json_parse(text: str) -> Dict[str, Any]:
    """å®‰å…¨çš„ JSON è§£æï¼Œé¿å…å¾ªç¯å¯¼å…¥"""
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        return {}

def query_analysis_node(state: AgentState) -> Dict[str, Any]:
    """
    æŸ¥è¯¢åˆ†æèŠ‚ç‚¹
    
    åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œç¡®å®šæŸ¥è¯¢ç±»å‹å¹¶é€‰æ‹©æœ€ä½³çš„LightRAGæ£€ç´¢æ¨¡å¼ï¼š
    - FACTUAL (äº‹å®æ€§) â†’ localæ¨¡å¼: å¯»æ‰¾å…·ä½“äº‹å®ã€å®šä¹‰ã€æ¦‚å¿µ
    - RELATIONAL (å…³ç³»æ€§) â†’ globalæ¨¡å¼: æ¢ç´¢å®ä½“é—´å…³ç³»ã€å½±å“ã€è”ç³»
    - ANALYTICAL (åˆ†ææ€§) â†’ hybridæ¨¡å¼: éœ€è¦ç»¼åˆåˆ†æã€æ¨ç†ã€å¤šç»´ä¿¡æ¯
    
    Args:
        state: å½“å‰å·¥ä½œæµçŠ¶æ€
        
    Returns:
        æ›´æ–°åçš„çŠ¶æ€å­—å…¸
    """
    logger.info(f"å¼€å§‹æŸ¥è¯¢åˆ†æ: {state['user_query'][:50]}...")
    
    try:
        # åˆå§‹åŒ–LLM  
        llm = ChatOpenAI(
            model=config.LLM_MODEL,
            temperature=0,
            api_key=config.LLM_API_KEY,
            base_url=config.LLM_BASE_URL
        )
        
        # ğŸš€ å‡çº§ï¼šä½¿ç”¨LangGraphç»“æ„åŒ–è¾“å‡ºæŠ€æœ¯
        # æ›¿æ¢æ‰‹å·¥JSONè§£æä¸ºè‡ªåŠ¨ç»“æ„åŒ–è¾“å‡ºï¼Œå¤§å¹…æå‡å¯é æ€§
        structured_llm = llm.with_structured_output(PydanticQueryAnalysisResult)
        
        # æ„å»ºåˆ†ææç¤ºè¯
        analysis_prompt = _build_analysis_prompt(state["user_query"])
        
        # ğŸ¯ æ‰§è¡Œç»“æ„åŒ–åˆ†æ - è‡ªåŠ¨éªŒè¯å’Œç±»å‹æ£€æŸ¥
        analysis_result: PydanticQueryAnalysisResult = structured_llm.invoke(analysis_prompt)
        
        # ç¡®ä¿ç±»å‹å’Œæ¨¡å¼çš„ä¸€è‡´æ€§
        analysis_result = analysis_result.ensure_type_mode_consistency()
        
        # è®°å½•åˆ†æç»“æœ
        logger.info(f"âœ… ç»“æ„åŒ–æŸ¥è¯¢åˆ†æå®Œæˆ:")
        logger.info(f"  - æŸ¥è¯¢ç±»å‹: {analysis_result.query_type}")
        logger.info(f"  - LightRAGæ¨¡å¼: {analysis_result.lightrag_mode}")
        logger.info(f"  - å…³é”®å®ä½“: {analysis_result.key_entities}")
        
        # ğŸ”„ ä¿æŒå…¼å®¹æ€§ï¼šè½¬æ¢ä¸ºå­—å…¸æ ¼å¼è¿”å›
        return analysis_result.to_dict()
        
    except Exception as e:
        logger.error(f"âŒ ç»“æ„åŒ–æŸ¥è¯¢åˆ†æå¤±è´¥: {e}")
        
        # ğŸ›¡ï¸ ä½¿ç”¨æ”¹è¿›çš„fallbackæœºåˆ¶
        fallback_result = create_fallback_query_analysis(
            state["user_query"], 
            str(e)
        )
        
        logger.info(f"ğŸ”„ ä½¿ç”¨fallbackæŸ¥è¯¢åˆ†æ: {fallback_result.lightrag_mode}æ¨¡å¼")
        
        # ä¿æŒå…¼å®¹æ€§ï¼šè¿”å›å­—å…¸æ ¼å¼
        return fallback_result.to_dict()

def _build_analysis_prompt(user_query: str) -> str:
    """
    æ„å»ºæŸ¥è¯¢åˆ†ææç¤ºè¯
    
    Args:
        user_query: ç”¨æˆ·æŸ¥è¯¢
        
    Returns:
        åˆ†ææç¤ºè¯
    """
    return f"""
è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢ï¼Œç¡®å®šæœ€é€‚åˆçš„LightRAGæ£€ç´¢æ¨¡å¼ã€‚

ç”¨æˆ·æŸ¥è¯¢ï¼š{user_query}

è¯·æ ¹æ®æŸ¥è¯¢çš„æ€§è´¨ï¼Œåˆ¤æ–­æŸ¥è¯¢ç±»å‹å¹¶é€‰æ‹©æœ€ä½³çš„æ£€ç´¢æ¨¡å¼ï¼š

1. **FACTUAL (äº‹å®æ€§æŸ¥è¯¢)** â†’ localæ¨¡å¼
   - å¯»æ‰¾å…·ä½“äº‹å®ã€å®šä¹‰ã€æ¦‚å¿µ
   - éœ€è¦ç²¾ç¡®çš„ä¿¡æ¯åŒ¹é…
   - ä¾‹å­ï¼š"ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"ã€"Pythonçš„åŸºæœ¬è¯­æ³•"

2. **RELATIONAL (å…³ç³»æ€§æŸ¥è¯¢)** â†’ globalæ¨¡å¼
   - æ¢ç´¢å®ä½“é—´å…³ç³»ã€å½±å“ã€è”ç³»
   - éœ€è¦å›¾è°±éå†å’Œå…³ç³»æ¨ç†
   - ä¾‹å­ï¼š"è°å‘æ˜äº†æœºå™¨å­¦ä¹ ï¼Ÿ"ã€"Aå’ŒBä¹‹é—´çš„å…³ç³»"

3. **ANALYTICAL (åˆ†ææ€§æŸ¥è¯¢)** â†’ hybridæ¨¡å¼
   - éœ€è¦ç»¼åˆåˆ†æã€æ¨ç†ã€å¤šç»´ä¿¡æ¯
   - ç»“åˆäº‹å®å’Œå…³ç³»è¿›è¡Œå¤æ‚åˆ†æ
   - ä¾‹å­ï¼š"æœºå™¨å­¦ä¹ çš„å‘å±•è¶‹åŠ¿"ã€"æ¯”è¾ƒAå’ŒBçš„ä¼˜ç¼ºç‚¹"

è¯·æå–æŸ¥è¯¢ä¸­çš„å…³é”®å®ä½“ï¼Œå¹¶å¯¹æŸ¥è¯¢è¿›è¡Œä¼˜åŒ–å¤„ç†ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{{
    "query_type": "FACTUAL/RELATIONAL/ANALYTICAL",
    "lightrag_mode": "local/global/hybrid",
    "key_entities": ["å®ä½“1", "å®ä½“2", ...],
    "processed_query": "ç»è¿‡ä¼˜åŒ–çš„æŸ¥è¯¢æ–‡æœ¬",
    "reasoning": "é€‰æ‹©è¯¥æ¨¡å¼çš„è¯¦ç»†åŸå› "
}}

æ³¨æ„ï¼š
- åªè¿”å›JSONæ ¼å¼çš„ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡æœ¬
- ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½å­˜åœ¨
- key_entitiesæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œå¯ä»¥ä¸ºç©º
- processed_queryåº”è¯¥æ˜¯ç»è¿‡ä¼˜åŒ–çš„æŸ¥è¯¢æ–‡æœ¬
"""

def _validate_analysis_result(analysis: Dict[str, Any]) -> Dict[str, Any]:
    """
    éªŒè¯å’Œæ ‡å‡†åŒ–åˆ†æç»“æœ
    
    Args:
        analysis: åŸå§‹åˆ†æç»“æœ
        
    Returns:
        éªŒè¯åçš„åˆ†æç»“æœ
    """
    # é»˜è®¤å€¼
    defaults = {
        "query_type": "ANALYTICAL",
        "lightrag_mode": "hybrid", 
        "key_entities": [],
        "processed_query": "",
        "reasoning": "ä½¿ç”¨é»˜è®¤é…ç½®"
    }
    
    # éªŒè¯query_type
    valid_types = ["FACTUAL", "RELATIONAL", "ANALYTICAL"]
    if analysis.get("query_type") not in valid_types:
        analysis["query_type"] = defaults["query_type"]
    
    # éªŒè¯lightrag_mode
    valid_modes = ["local", "global", "hybrid"]
    if analysis.get("lightrag_mode") not in valid_modes:
        analysis["lightrag_mode"] = defaults["lightrag_mode"]
    
    # éªŒè¯key_entities
    if not isinstance(analysis.get("key_entities"), list):
        analysis["key_entities"] = defaults["key_entities"]
    
    # éªŒè¯processed_query
    if not isinstance(analysis.get("processed_query"), str):
        analysis["processed_query"] = defaults["processed_query"]
    
    # éªŒè¯reasoning
    if not isinstance(analysis.get("reasoning"), str):
        analysis["reasoning"] = defaults["reasoning"]
    
    # ç¡®ä¿æŸ¥è¯¢ç±»å‹å’Œæ¨¡å¼åŒ¹é…
    type_mode_mapping = {
        "FACTUAL": "local",
        "RELATIONAL": "global",
        "ANALYTICAL": "hybrid"
    }
    
    expected_mode = type_mode_mapping.get(analysis["query_type"])
    if expected_mode and analysis["lightrag_mode"] != expected_mode:
        logger.warning(f"æŸ¥è¯¢ç±»å‹ {analysis['query_type']} ä¸æ¨¡å¼ {analysis['lightrag_mode']} ä¸åŒ¹é…ï¼Œè‡ªåŠ¨ä¿®æ­£ä¸º {expected_mode}")
        analysis["lightrag_mode"] = expected_mode
    
    return analysis

def get_query_analysis_examples() -> Dict[str, QueryAnalysisResult]:
    """
    è·å–æŸ¥è¯¢åˆ†æç¤ºä¾‹
    
    Returns:
        æŸ¥è¯¢åˆ†æç¤ºä¾‹å­—å…¸
    """
    examples = {
        "factual": QueryAnalysisResult(
            query_type="FACTUAL",
            lightrag_mode="local", 
            key_entities=["æœºå™¨å­¦ä¹ "],
            processed_query="ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿè¯·æä¾›å®šä¹‰å’ŒåŸºæœ¬æ¦‚å¿µã€‚",
            reasoning="ç”¨æˆ·è¯¢é—®å…·ä½“æ¦‚å¿µçš„å®šä¹‰ï¼Œå±äºäº‹å®æ€§æŸ¥è¯¢ï¼Œé€‚åˆä½¿ç”¨localæ¨¡å¼è¿›è¡Œå‘é‡æ£€ç´¢"
        ),
        "relational": QueryAnalysisResult(
            query_type="RELATIONAL",
            lightrag_mode="global",
            key_entities=["æœºå™¨å­¦ä¹ ", "äººå·¥æ™ºèƒ½"],
            processed_query="æœºå™¨å­¦ä¹ ä¸äººå·¥æ™ºèƒ½çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ",
            reasoning="ç”¨æˆ·è¯¢é—®å®ä½“é—´å…³ç³»ï¼Œéœ€è¦å›¾è°±éå†ï¼Œé€‚åˆä½¿ç”¨globalæ¨¡å¼"
        ),
        "analytical": QueryAnalysisResult(
            query_type="ANALYTICAL", 
            lightrag_mode="hybrid",
            key_entities=["æœºå™¨å­¦ä¹ ", "æœªæ¥", "å‘å±•è¶‹åŠ¿"],
            processed_query="åˆ†ææœºå™¨å­¦ä¹ çš„å‘å±•è¶‹åŠ¿åŠå…¶å¯¹æœªæ¥çš„å½±å“",
            reasoning="ç”¨æˆ·éœ€è¦ç»¼åˆåˆ†æå’Œé¢„æµ‹ï¼Œéœ€è¦ç»“åˆäº‹å®å’Œå…³ç³»ä¿¡æ¯ï¼Œé€‚åˆä½¿ç”¨hybridæ¨¡å¼"
        )
    }
    
    return examples