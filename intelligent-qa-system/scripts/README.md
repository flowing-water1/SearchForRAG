# è„šæœ¬å·¥å…·æŠ€æœ¯æ–‡æ¡£

> è¿”å› [é¡¹ç›®æ¦‚è§ˆæ–‡æ¡£](../../TECHNICAL_REFERENCE.md)

## ğŸ“ ç›¸å…³æ–‡æ¡£å¯¼èˆª
- **[æ ¸å¿ƒæ¨¡å—æ–‡æ¡£](../src/core/README.md)** - æŸ¥çœ‹è„šæœ¬ä½¿ç”¨çš„é…ç½®å’Œå·¥ä½œæµ
- **[å·¥å…·æ¨¡å—æ–‡æ¡£](../src/utils/README.md)** - æŸ¥çœ‹è„šæœ¬ä¾èµ–çš„å®¢æˆ·ç«¯å’Œå·¥å…·
- **[æµ‹è¯•æ¨¡å—æ–‡æ¡£](../tests/README.md)** - æŸ¥çœ‹è„šæœ¬çš„æµ‹è¯•å’ŒéªŒè¯
- **[é¡¹ç›®æ ¹ç›®å½•](../../TECHNICAL_REFERENCE.md)** - è¿”å›é¡¹ç›®å®Œæ•´æ¦‚è§ˆ

## ğŸ”— è„šæœ¬ä¸ç³»ç»Ÿé›†æˆ
- [é…ç½®ç®¡ç†](../src/core/README.md#1-é…ç½®ç®¡ç†ç³»ç»Ÿ-configpy) - è„šæœ¬ä½¿ç”¨çš„é…ç½®ç³»ç»Ÿ
- [LightRAGå®¢æˆ·ç«¯](../src/utils/README.md#5-lightragå®¢æˆ·ç«¯-lightrag_clientpy) - æ–‡æ¡£æ‘„å–çš„æ ¸å¿ƒä¾èµ–
- [ç³»ç»Ÿç›‘æ§](../src/utils/README.md#4-ç³»ç»Ÿç›‘æ§-system_monitoringpy) - ç¯å¢ƒæ£€æŸ¥å’Œå¥åº·éªŒè¯
- [é”™è¯¯å¤„ç†](../src/utils/README.md#3-é”™è¯¯å¤„ç†æ¡†æ¶-error_handlingpy) - è„šæœ¬çš„å¼‚å¸¸å¤„ç†æœºåˆ¶

---

## æ¨¡å—æ¦‚è¿°

è„šæœ¬å·¥å…·æ¨¡å— (scripts/) æä¾›äº†æ™ºèƒ½é—®ç­”ç³»ç»Ÿçš„éƒ¨ç½²ã€ç®¡ç†å’Œç»´æŠ¤è„šæœ¬ã€‚è¿™äº›è„šæœ¬è‡ªåŠ¨åŒ–äº†ç¯å¢ƒè®¾ç½®ã€æ•°æ®æ‘„å–ã€è¿æ¥æµ‹è¯•ç­‰å…³é”®æ“ä½œï¼Œç®€åŒ–äº†ç³»ç»Ÿçš„éƒ¨ç½²å’Œè¿ç»´æµç¨‹ã€‚

### æ¨¡å—ç»“æ„
```
scripts/
â”œâ”€â”€ setup_environment.py     # ç¯å¢ƒåˆå§‹åŒ–è„šæœ¬
â”œâ”€â”€ ingest_documents.py      # æ–‡æ¡£æ‘„å–è„šæœ¬
â””â”€â”€ test_connections.py      # è¿æ¥æµ‹è¯•è„šæœ¬
```

### è„šæœ¬åˆ†ç±»
- **ç¯å¢ƒç®¡ç†**: åˆå§‹åŒ–å’Œé…ç½®ç³»ç»Ÿç¯å¢ƒ
- **æ•°æ®ç®¡ç†**: æ–‡æ¡£æ‘„å–å’ŒçŸ¥è¯†åº“æ„å»º
- **è¿ç»´å·¥å…·**: è¿æ¥æµ‹è¯•å’Œå¥åº·æ£€æŸ¥

---

## è„šæœ¬è¯¦è§£

### 1. ç¯å¢ƒåˆå§‹åŒ–è„šæœ¬ (setup_environment.py)

**ä¸»è¦åŠŸèƒ½**: è®¾ç½®æ•°æ®åº“ã€åˆ›å»ºå¿…è¦çš„è¡¨å’Œç´¢å¼•ï¼Œåˆå§‹åŒ–ç³»ç»Ÿè¿è¡Œç¯å¢ƒã€‚

#### è„šæœ¬ç»“æ„

```python
"""
ç¯å¢ƒåˆå§‹åŒ–è„šæœ¬
è®¾ç½®æ•°æ®åº“ã€åˆ›å»ºå¿…è¦çš„è¡¨å’Œç´¢å¼•
"""

import sys
import os
import asyncio
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from core.config import config
from utils.helpers import setup_logger, ensure_directory
from utils.lightrag_client import initialize_lightrag
from utils.document_processor import ingest_documents

logger = setup_logger(__name__)
```

#### ç›®å½•åˆ›å»ºåŠŸèƒ½

```python
async def setup_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•
    
    åˆ›å»ºç›®å½•:
    - RAGå­˜å‚¨ç›®å½•
    - å‘é‡å­˜å‚¨ç›®å½•
    - å›¾å­˜å‚¨ç›®å½•
    - æ–‡æ¡£ç›®å½•
    """
    logger.info("åˆ›å»ºé¡¹ç›®ç›®å½•...")
    
    directories = [
        config.RAG_STORAGE_DIR,
        config.RAG_STORAGE_DIR / "kv_storage",
        config.RAG_STORAGE_DIR / "vector_storage", 
        config.RAG_STORAGE_DIR / "graph_storage",
        config.DOCS_DIR
    ]
    
    for directory in directories:
        ensure_directory(directory)
        logger.info(f"âœ… ç›®å½•å·²åˆ›å»º: {directory}")
```

#### PostgreSQLè®¾ç½®

```python
async def setup_postgresql():
    """è®¾ç½®PostgreSQLæ•°æ®åº“
    
    åŠŸèƒ½:
    - æ£€æŸ¥æ•°æ®åº“è¿æ¥
    - å®‰è£…pgvectoræ‰©å±•
    - åˆ›å»ºå¿…è¦çš„è¡¨å’Œç´¢å¼•
    - é…ç½®å‘é‡å­˜å‚¨
    """
    logger.info("è®¾ç½®PostgreSQLæ•°æ®åº“...")
    
    try:
        import psycopg2
        
        # è¿æ¥æ•°æ®åº“
        conn = psycopg2.connect(config.postgres_url)
        conn.autocommit = True
        cursor = conn.cursor()
        
        # å°è¯•åˆ›å»ºpgvectoræ‰©å±•
        try:
            cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
            logger.info("âœ… pgvectoræ‰©å±•å·²å®‰è£…")
        except psycopg2.Error as e:
            logger.warning(f"âš ï¸  pgvectoræ‰©å±•å®‰è£…å¤±è´¥: {e}")
            logger.info("è¯·æ‰‹åŠ¨å®‰è£…pgvectoræ‰©å±•")
        
        # åˆ›å»ºå‘é‡è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS document_vectors (
                id SERIAL PRIMARY KEY,
                document_id VARCHAR(255) NOT NULL,
                content TEXT NOT NULL,
                embedding VECTOR(1536),
                metadata JSONB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
        """)
        
        # åˆ›å»ºç´¢å¼•
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_document_vectors_embedding 
            ON document_vectors USING ivfflat (embedding vector_cosine_ops);
        """)
        
        # åˆ›å»ºæ–‡æ¡£å…ƒæ•°æ®è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS documents (
                id VARCHAR(255) PRIMARY KEY,
                title VARCHAR(255),
                content TEXT,
                source VARCHAR(255),
                metadata JSONB,
                processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
        """)
        
        cursor.close()
        conn.close()
        
        logger.info("âœ… PostgreSQLæ•°æ®åº“è®¾ç½®å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ PostgreSQLè®¾ç½®å¤±è´¥: {e}")
        return False
```

#### Neo4jè®¾ç½®

```python
async def setup_neo4j():
    """è®¾ç½®Neo4jå›¾æ•°æ®åº“
    
    åŠŸèƒ½:
    - æ£€æŸ¥Neo4jè¿æ¥
    - åˆ›å»ºçº¦æŸå’Œç´¢å¼•
    - é…ç½®å›¾å­˜å‚¨å‚æ•°
    """
    logger.info("è®¾ç½®Neo4jæ•°æ®åº“...")
    
    try:
        from neo4j import GraphDatabase
        
        # è¿æ¥Neo4j
        driver = GraphDatabase.driver(
            config.NEO4J_URI,
            auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD)
        )
        
        with driver.session() as session:
            # åˆ›å»ºå”¯ä¸€çº¦æŸ
            constraints = [
                "CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:Entity) REQUIRE e.id IS UNIQUE",
                "CREATE CONSTRAINT document_id IF NOT EXISTS FOR (d:Document) REQUIRE d.id IS UNIQUE"
            ]
            
            for constraint in constraints:
                try:
                    session.run(constraint)
                    logger.info(f"âœ… çº¦æŸå·²åˆ›å»º: {constraint.split()[2]}")
                except Exception as e:
                    logger.warning(f"çº¦æŸåˆ›å»ºå¯èƒ½å·²å­˜åœ¨: {e}")
            
            # åˆ›å»ºç´¢å¼•
            indexes = [
                "CREATE INDEX entity_name IF NOT EXISTS FOR (e:Entity) ON (e.name)",
                "CREATE INDEX document_title IF NOT EXISTS FOR (d:Document) ON (d.title)"
            ]
            
            for index in indexes:
                try:
                    session.run(index)
                    logger.info(f"âœ… ç´¢å¼•å·²åˆ›å»º: {index.split()[2]}")
                except Exception as e:
                    logger.warning(f"ç´¢å¼•åˆ›å»ºå¯èƒ½å·²å­˜åœ¨: {e}")
        
        driver.close()
        logger.info("âœ… Neo4jæ•°æ®åº“è®¾ç½®å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Neo4jè®¾ç½®å¤±è´¥: {e}")
        logger.info("è¯·æ£€æŸ¥Neo4jæœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ")
        return False
```

#### LightRAGåˆå§‹åŒ–

```python
async def setup_lightrag():
    """åˆå§‹åŒ–LightRAGç³»ç»Ÿ
    
    åŠŸèƒ½:
    - åˆå§‹åŒ–LightRAGå®¢æˆ·ç«¯
    - é…ç½®å­˜å‚¨åç«¯
    - éªŒè¯ç³»ç»ŸåŠŸèƒ½
    """
    logger.info("åˆå§‹åŒ–LightRAGç³»ç»Ÿ...")
    
    try:
        from utils.lightrag_client import lightrag_client
        
        # åˆå§‹åŒ–LightRAGå®¢æˆ·ç«¯
        success = await lightrag_client.initialize()
        
        if success:
            logger.info("âœ… LightRAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            
            # è·å–ç³»ç»ŸçŠ¶æ€
            status = await lightrag_client.get_health_status()
            logger.info(f"LightRAGçŠ¶æ€: {status}")
            
            return True
        else:
            logger.error("âŒ LightRAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"âŒ LightRAGåˆå§‹åŒ–å¼‚å¸¸: {e}")
        return False
```

#### å®Œæ•´ç¯å¢ƒè®¾ç½®

```python
async def setup_complete_environment():
    """è®¾ç½®å®Œæ•´ç¯å¢ƒ
    
    æ‰§è¡Œæ­¥éª¤:
    1. åˆ›å»ºå¿…è¦ç›®å½•
    2. è®¾ç½®PostgreSQL
    3. è®¾ç½®Neo4j
    4. åˆå§‹åŒ–LightRAG
    5. éªŒè¯ç¯å¢ƒé…ç½®
    """
    logger.info("ğŸš€ å¼€å§‹ç¯å¢ƒåˆå§‹åŒ–...")
    
    success_count = 0
    total_steps = 4
    
    # 1. åˆ›å»ºç›®å½•
    try:
        await setup_directories()
        success_count += 1
        logger.info("âœ… æ­¥éª¤ 1/4: ç›®å½•åˆ›å»ºå®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ æ­¥éª¤ 1/4: ç›®å½•åˆ›å»ºå¤±è´¥ - {e}")
    
    # 2. è®¾ç½®PostgreSQL
    try:
        postgres_success = await setup_postgresql()
        if postgres_success:
            success_count += 1
            logger.info("âœ… æ­¥éª¤ 2/4: PostgreSQLè®¾ç½®å®Œæˆ")
        else:
            logger.error("âŒ æ­¥éª¤ 2/4: PostgreSQLè®¾ç½®å¤±è´¥")
    except Exception as e:
        logger.error(f"âŒ æ­¥éª¤ 2/4: PostgreSQLè®¾ç½®å¼‚å¸¸ - {e}")
    
    # 3. è®¾ç½®Neo4j
    try:
        neo4j_success = await setup_neo4j()
        if neo4j_success:
            success_count += 1
            logger.info("âœ… æ­¥éª¤ 3/4: Neo4jè®¾ç½®å®Œæˆ")
        else:
            logger.error("âŒ æ­¥éª¤ 3/4: Neo4jè®¾ç½®å¤±è´¥")
    except Exception as e:
        logger.error(f"âŒ æ­¥éª¤ 3/4: Neo4jè®¾ç½®å¼‚å¸¸ - {e}")
    
    # 4. åˆå§‹åŒ–LightRAG
    try:
        lightrag_success = await setup_lightrag()
        if lightrag_success:
            success_count += 1
            logger.info("âœ… æ­¥éª¤ 4/4: LightRAGåˆå§‹åŒ–å®Œæˆ")
        else:
            logger.error("âŒ æ­¥éª¤ 4/4: LightRAGåˆå§‹åŒ–å¤±è´¥")
    except Exception as e:
        logger.error(f"âŒ æ­¥éª¤ 4/4: LightRAGåˆå§‹åŒ–å¼‚å¸¸ - {e}")
    
    # æ€»ç»“
    logger.info(f"\nğŸ¯ ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ: {success_count}/{total_steps} æ­¥éª¤æˆåŠŸ")
    
    if success_count == total_steps:
        logger.info("ğŸ‰ æ‰€æœ‰ç»„ä»¶è®¾ç½®æˆåŠŸï¼ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªã€‚")
        return True
    else:
        logger.warning("âš ï¸  éƒ¨åˆ†ç»„ä»¶è®¾ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶æ‰‹åŠ¨ä¿®å¤ã€‚")
        return False

# ä¸»æ‰§è¡Œå‡½æ•°
async def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    try:
        success = await setup_complete_environment()
        
        if success:
            print("\n" + "="*50)
            print("ğŸ‰ ç¯å¢ƒåˆå§‹åŒ–æˆåŠŸå®Œæˆï¼")
            print("ä½ ç°åœ¨å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨ç³»ç»Ÿ:")
            print("  streamlit run main_app.py")
            print("  streamlit run streamlit_app.py")
            print("="*50)
            sys.exit(0)
        else:
            print("\n" + "="*50)
            print("âš ï¸  ç¯å¢ƒåˆå§‹åŒ–éƒ¨åˆ†å¤±è´¥")
            print("è¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—å¹¶æ‰‹åŠ¨ä¿®å¤é—®é¢˜")
            print("="*50)
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ç¯å¢ƒåˆå§‹åŒ–å¼‚å¸¸: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
```

### 2. æ–‡æ¡£æ‘„å–è„šæœ¬ (ingest_documents.py)

**ä¸»è¦åŠŸèƒ½**: æ‰¹é‡å¤„ç†å’Œæ‘„å–æ–‡æ¡£åˆ°çŸ¥è¯†åº“ï¼Œæ„å»ºå‘é‡ç´¢å¼•å’ŒçŸ¥è¯†å›¾è°±ã€‚

#### è„šæœ¬æ¶æ„

```python
"""
æ–‡æ¡£æ‘„å–è„šæœ¬
æ‰¹é‡å¤„ç†æ–‡æ¡£å¹¶æ‘„å–åˆ°LightRAGçŸ¥è¯†åº“
"""

import asyncio
import sys
from pathlib import Path
import argparse
from typing import List, Dict, Any
import json

# æ·»åŠ srcè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from core.config import config
from utils.lightrag_client import lightrag_client
from utils.document_processor import DocumentProcessor
from utils.helpers import setup_logger, validate_file_type
from utils.advanced_logging import get_performance_logger

logger = setup_logger(__name__)
perf_logger = get_performance_logger(__name__)
```

#### æ–‡æ¡£å¤„ç†å™¨

```python
class DocumentIngestor:
    """æ–‡æ¡£æ‘„å–å™¨
    
    åŠŸèƒ½:
    - æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼
    - æ‰¹é‡å¤„ç†å’Œè¿›åº¦è·Ÿè¸ª
    - é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
    - æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–
    """
    
    def __init__(self, batch_size: int = 10):
        self.batch_size = batch_size
        self.processor = DocumentProcessor()
        self.processed_count = 0
        self.failed_count = 0
        self.total_count = 0
    
    async def ingest_directory(self, directory: Path, recursive: bool = True) -> Dict[str, Any]:
        """æ‘„å–ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡æ¡£
        
        Args:
            directory: æ–‡æ¡£ç›®å½•è·¯å¾„
            recursive: æ˜¯å¦é€’å½’å¤„ç†å­ç›®å½•
            
        Returns:
            æ‘„å–ç»“æœç»Ÿè®¡
        """
        logger.info(f"å¼€å§‹æ‘„å–ç›®å½•: {directory}")
        perf_logger.start_operation("directory_ingestion", directory=str(directory))
        
        try:
            # è·å–æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶
            files = self._get_document_files(directory, recursive)
            self.total_count = len(files)
            
            logger.info(f"å‘ç° {self.total_count} ä¸ªæ–‡æ¡£æ–‡ä»¶")
            
            if self.total_count == 0:
                logger.warning("æœªå‘ç°å¯å¤„ç†çš„æ–‡æ¡£æ–‡ä»¶")
                return self._get_summary()
            
            # åˆ†æ‰¹å¤„ç†æ–‡æ¡£
            for i in range(0, len(files), self.batch_size):
                batch_files = files[i:i + self.batch_size]
                batch_number = i // self.batch_size + 1
                total_batches = (len(files) + self.batch_size - 1) // self.batch_size
                
                logger.info(f"å¤„ç†æ‰¹æ¬¡ {batch_number}/{total_batches} ({len(batch_files)} æ–‡ä»¶)")
                
                await self._process_batch(batch_files)
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (i + len(batch_files)) / len(files) * 100
                logger.info(f"è¿›åº¦: {progress:.1f}% ({self.processed_count}/{self.total_count})")
            
            # å®Œæˆæ‘„å–
            perf_logger.end_operation(
                success=True,
                processed_files=self.processed_count,
                failed_files=self.failed_count
            )
            
            summary = self._get_summary()
            logger.info("æ‘„å–å®Œæˆ:")
            logger.info(f"  æˆåŠŸ: {summary['processed_count']} æ–‡ä»¶")
            logger.info(f"  å¤±è´¥: {summary['failed_count']} æ–‡ä»¶")
            logger.info(f"  æ€»è®¡: {summary['total_count']} æ–‡ä»¶")
            
            return summary
            
        except Exception as e:
            perf_logger.end_operation(success=False, error=str(e))
            logger.error(f"ç›®å½•æ‘„å–å¤±è´¥: {e}")
            raise
    
    def _get_document_files(self, directory: Path, recursive: bool) -> List[Path]:
        """è·å–ç›®å½•ä¸­çš„æ–‡æ¡£æ–‡ä»¶"""
        supported_extensions = {'.txt', '.md', '.pdf', '.docx', '.html', '.json'}
        files = []
        
        if recursive:
            pattern = "**/*"
        else:
            pattern = "*"
        
        for file_path in directory.glob(pattern):
            if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
                files.append(file_path)
        
        return sorted(files)
    
    async def _process_batch(self, files: List[Path]):
        """å¤„ç†æ–‡ä»¶æ‰¹æ¬¡"""
        tasks = [self._process_single_file(file_path) for file_path in files]
        
        # å¹¶å‘å¤„ç†æ–‡ä»¶
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for file_path, result in zip(files, results):
            if isinstance(result, Exception):
                logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {result}")
                self.failed_count += 1
            elif result:
                logger.info(f"âœ… æˆåŠŸå¤„ç†: {file_path.name}")
                self.processed_count += 1
            else:
                logger.warning(f"âš ï¸  è·³è¿‡æ–‡ä»¶: {file_path.name}")
                self.failed_count += 1
    
    async def _process_single_file(self, file_path: Path) -> bool:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            # è¯»å–æ–‡æ¡£å†…å®¹
            content = await self.processor.read_document(file_path)
            
            if not content or len(content.strip()) < 100:
                logger.warning(f"æ–‡æ¡£å†…å®¹è¿‡çŸ­ï¼Œè·³è¿‡: {file_path}")
                return False
            
            # å‡†å¤‡æ–‡æ¡£å…ƒæ•°æ®
            metadata = {
                "source": str(file_path),
                "filename": file_path.name,
                "extension": file_path.suffix,
                "size": file_path.stat().st_size,
                "processed_at": datetime.now().isoformat()
            }
            
            # æ‘„å–åˆ°LightRAG
            success = await lightrag_client.insert_document(content, metadata)
            
            return success
            
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å¼‚å¸¸ {file_path}: {e}")
            return False
    
    def _get_summary(self) -> Dict[str, Any]:
        """è·å–æ‘„å–ç»“æœæ‘˜è¦"""
        return {
            "total_count": self.total_count,
            "processed_count": self.processed_count,
            "failed_count": self.failed_count,
            "success_rate": self.processed_count / self.total_count if self.total_count > 0 else 0
        }
```

#### å‘½ä»¤è¡Œæ¥å£

```python
def create_argument_parser() -> argparse.ArgumentParser:
    """åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(
        description="æ™ºèƒ½é—®ç­”ç³»ç»Ÿæ–‡æ¡£æ‘„å–å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python ingest_documents.py docs/                    # æ‘„å–docsç›®å½•
  python ingest_documents.py docs/ --recursive        # é€’å½’æ‘„å–å­ç›®å½•
  python ingest_documents.py docs/ --batch-size 20    # è®¾ç½®æ‰¹æ¬¡å¤§å°
  python ingest_documents.py single_file.pdf          # æ‘„å–å•ä¸ªæ–‡ä»¶
        """
    )
    
    parser.add_argument(
        "path",
        type=str,
        help="è¦æ‘„å–çš„æ–‡æ¡£è·¯å¾„(æ–‡ä»¶æˆ–ç›®å½•)"
    )
    
    parser.add_argument(
        "--recursive", "-r",
        action="store_true",
        help="é€’å½’å¤„ç†å­ç›®å½•"
    )
    
    parser.add_argument(
        "--batch-size", "-b",
        type=int,
        default=10,
        help="æ‰¹æ¬¡å¤„ç†å¤§å° (é»˜è®¤: 10)"
    )
    
    parser.add_argument(
        "--force", "-f",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°å¤„ç†å·²å­˜åœ¨çš„æ–‡æ¡£"
    )
    
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸å®é™…æ‘„å–æ–‡æ¡£"
    )
    
    return parser

async def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    parser = create_argument_parser()
    args = parser.parse_args()
    
    # éªŒè¯è·¯å¾„
    input_path = Path(args.path)
    if not input_path.exists():
        logger.error(f"è·¯å¾„ä¸å­˜åœ¨: {input_path}")
        sys.exit(1)
    
    try:
        # åˆå§‹åŒ–LightRAGå®¢æˆ·ç«¯
        logger.info("åˆå§‹åŒ–LightRAGå®¢æˆ·ç«¯...")
        await lightrag_client.initialize()
        
        # åˆ›å»ºæ–‡æ¡£æ‘„å–å™¨
        ingestor = DocumentIngestor(batch_size=args.batch_size)
        
        # æ‰§è¡Œæ‘„å–
        if input_path.is_file():
            # å•æ–‡ä»¶æ‘„å–
            logger.info(f"æ‘„å–å•ä¸ªæ–‡ä»¶: {input_path}")
            success = await ingestor._process_single_file(input_path)
            
            if success:
                logger.info("âœ… æ–‡ä»¶æ‘„å–æˆåŠŸ")
            else:
                logger.error("âŒ æ–‡ä»¶æ‘„å–å¤±è´¥")
                sys.exit(1)
        
        elif input_path.is_dir():
            # ç›®å½•æ‘„å–
            if args.dry_run:
                logger.info("ğŸ” è¯•è¿è¡Œæ¨¡å¼ - ä»…æ‰«ææ–‡ä»¶ï¼Œä¸æ‰§è¡Œæ‘„å–")
                files = ingestor._get_document_files(input_path, args.recursive)
                logger.info(f"å‘ç° {len(files)} ä¸ªå¯å¤„ç†æ–‡ä»¶:")
                for file_path in files:
                    logger.info(f"  - {file_path}")
            else:
                summary = await ingestor.ingest_directory(input_path, args.recursive)
                
                if summary["success_rate"] > 0.8:
                    logger.info("ğŸ‰ æ–‡æ¡£æ‘„å–æˆåŠŸå®Œæˆ")
                elif summary["success_rate"] > 0.5:
                    logger.warning("âš ï¸  æ–‡æ¡£æ‘„å–éƒ¨åˆ†æˆåŠŸ")
                else:
                    logger.error("âŒ æ–‡æ¡£æ‘„å–å¤§éƒ¨åˆ†å¤±è´¥")
                    sys.exit(1)
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        logger.error(f"æ–‡æ¡£æ‘„å–å¼‚å¸¸: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
```

### 3. è¿æ¥æµ‹è¯•è„šæœ¬ (test_connections.py)

**ä¸»è¦åŠŸèƒ½**: æµ‹è¯•ç³»ç»Ÿå„ç»„ä»¶çš„è¿æ¥çŠ¶æ€å’Œå¥åº·çŠ¶å†µã€‚

#### æµ‹è¯•æ¶æ„

```python
"""
è¿æ¥æµ‹è¯•è„šæœ¬
æµ‹è¯•ç³»ç»Ÿå„ç»„ä»¶çš„è¿æ¥çŠ¶æ€å’Œé…ç½®
"""

import asyncio
import sys
from pathlib import Path
import json
from typing import Dict, Any, List
import time

# æ·»åŠ srcè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from core.config import config
from utils.lightrag_client import lightrag_client
from utils.system_monitoring import ApplicationHealthChecker
from utils.helpers import setup_logger

logger = setup_logger(__name__)
```

#### è¿æ¥æµ‹è¯•å™¨

```python
class ConnectionTester:
    """è¿æ¥æµ‹è¯•å™¨
    
    åŠŸèƒ½:
    - æµ‹è¯•æ‰€æœ‰å¤–éƒ¨ä¾èµ–è¿æ¥
    - ç”Ÿæˆè¯¦ç»†çš„å¥åº·æŠ¥å‘Š
    - æä¾›ä¿®å¤å»ºè®®
    """
    
    def __init__(self):
        self.health_checker = ApplicationHealthChecker()
        self.test_results = {}
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰è¿æ¥æµ‹è¯•"""
        logger.info("ğŸ” å¼€å§‹ç³»ç»Ÿè¿æ¥æµ‹è¯•...")
        
        tests = [
            ("é…ç½®éªŒè¯", self._test_configuration),
            ("PostgreSQLè¿æ¥", self._test_postgresql),
            ("Neo4jè¿æ¥", self._test_neo4j),
            ("OpenAI API", self._test_openai_api),
            ("Tavily API", self._test_tavily_api),
            ("LightRAGç³»ç»Ÿ", self._test_lightrag_system),
            ("æ–‡ä»¶ç³»ç»Ÿè®¿é—®", self._test_file_system)
        ]
        
        total_tests = len(tests)
        passed_tests = 0
        
        for i, (test_name, test_func) in enumerate(tests, 1):
            logger.info(f"[{i}/{total_tests}] æµ‹è¯• {test_name}...")
            
            try:
                result = await test_func()
                self.test_results[test_name] = result
                
                if result["status"] == "success":
                    logger.info(f"âœ… {test_name}: {result['message']}")
                    passed_tests += 1
                elif result["status"] == "warning":
                    logger.warning(f"âš ï¸  {test_name}: {result['message']}")
                    passed_tests += 0.5
                else:
                    logger.error(f"âŒ {test_name}: {result['message']}")
                
            except Exception as e:
                error_result = {
                    "status": "error",
                    "message": f"æµ‹è¯•å¼‚å¸¸: {str(e)}",
                    "details": {"exception": str(e)}
                }
                self.test_results[test_name] = error_result
                logger.error(f"âŒ {test_name}: æµ‹è¯•å¼‚å¸¸ - {e}")
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        success_rate = passed_tests / total_tests
        overall_status = self._determine_overall_status(success_rate)
        
        summary = {
            "overall_status": overall_status,
            "success_rate": success_rate,
            "total_tests": total_tests,
            "passed_tests": int(passed_tests),
            "test_results": self.test_results,
            "recommendations": self._generate_recommendations()
        }
        
        logger.info(f"\nğŸ“Š æµ‹è¯•å®Œæˆ: {int(passed_tests)}/{total_tests} é€šè¿‡ ({success_rate:.1%})")
        return summary
    
    async def _test_configuration(self) -> Dict[str, Any]:
        """æµ‹è¯•é…ç½®æœ‰æ•ˆæ€§"""
        issues = []
        warnings = []
        
        # æ£€æŸ¥å¿…éœ€é…ç½®
        required_configs = [
            ("LLM_API_KEY", "LLM APIå¯†é’¥"),
            ("LLM_MODEL", "LLMæ¨¡å‹"),
            ("EMBEDDING_MODEL", "åµŒå…¥æ¨¡å‹")
        ]
        
        for config_key, description in required_configs:
            value = getattr(config, config_key, None)
            if not value:
                issues.append(f"ç¼ºå°‘é…ç½®: {description} ({config_key})")
        
        # æ£€æŸ¥å¯é€‰é…ç½®
        optional_configs = [
            ("TAVILY_API_KEY", "Tavilyæœç´¢APIå¯†é’¥"),
            ("NEO4J_URI", "Neo4jæ•°æ®åº“URI"),
            ("POSTGRES_HOST", "PostgreSQLä¸»æœº")
        ]
        
        for config_key, description in optional_configs:
            value = getattr(config, config_key, None)
            if not value:
                warnings.append(f"å¯é€‰é…ç½®æœªè®¾ç½®: {description} ({config_key})")
        
        # éªŒè¯APIå¯†é’¥æ ¼å¼
        if hasattr(config, 'LLM_API_KEY') and config.LLM_API_KEY:
            if not config.LLM_API_KEY.startswith(('sk-', 'gsk_')):
                warnings.append("LLM APIå¯†é’¥æ ¼å¼å¯èƒ½ä¸æ­£ç¡®")
        
        if issues:
            return {
                "status": "error",
                "message": f"é…ç½®éªŒè¯å¤±è´¥: {len(issues)} ä¸ªå¿…éœ€é…ç½®ç¼ºå¤±",
                "details": {"issues": issues, "warnings": warnings}
            }
        elif warnings:
            return {
                "status": "warning", 
                "message": f"é…ç½®åŸºæœ¬æ­£ç¡®ï¼Œä½†æœ‰ {len(warnings)} ä¸ªè­¦å‘Š",
                "details": {"warnings": warnings}
            }
        else:
            return {
                "status": "success",
                "message": "æ‰€æœ‰é…ç½®éªŒè¯é€šè¿‡",
                "details": {}
            }
    
    async def _test_postgresql(self) -> Dict[str, Any]:
        """æµ‹è¯•PostgreSQLè¿æ¥"""
        try:
            health_check = self.health_checker.check_database_connection()
            
            if health_check.status.value == "healthy":
                return {
                    "status": "success",
                    "message": "PostgreSQLè¿æ¥æ­£å¸¸",
                    "details": health_check.details
                }
            else:
                return {
                    "status": "error",
                    "message": health_check.message,
                    "details": health_check.details
                }
                
        except Exception as e:
            return {
                "status": "error",
                "message": f"PostgreSQLè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}",
                "details": {"exception": str(e)}
            }
    
    async def _test_neo4j(self) -> Dict[str, Any]:
        """æµ‹è¯•Neo4jè¿æ¥"""
        try:
            if not hasattr(config, 'NEO4J_URI') or not config.NEO4J_URI:
                return {
                    "status": "warning",
                    "message": "Neo4jé…ç½®æœªè®¾ç½®ï¼Œå°†ä½¿ç”¨æ–‡ä»¶å­˜å‚¨",
                    "details": {}
                }
            
            from neo4j import GraphDatabase
            
            driver = GraphDatabase.driver(
                config.NEO4J_URI,
                auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD)
            )
            
            with driver.session() as session:
                result = session.run("RETURN 1 as test")
                test_value = result.single()["test"]
            
            driver.close()
            
            if test_value == 1:
                return {
                    "status": "success",
                    "message": "Neo4jè¿æ¥æ­£å¸¸",
                    "details": {"uri": config.NEO4J_URI}
                }
            else:
                return {
                    "status": "error",
                    "message": "Neo4jæµ‹è¯•æŸ¥è¯¢è¿”å›å¼‚å¸¸å€¼",
                    "details": {"expected": 1, "actual": test_value}
                }
                
        except Exception as e:
            return {
                "status": "error",
                "message": f"Neo4jè¿æ¥å¤±è´¥: {str(e)}",
                "details": {"exception": str(e)}
            }
    
    async def _test_openai_api(self) -> Dict[str, Any]:
        """æµ‹è¯•OpenAI APIè¿æ¥"""
        try:
            from openai import OpenAI
            
            client = OpenAI(
                api_key=config.LLM_API_KEY,
                base_url=config.LLM_BASE_URL
            )
            
            # æµ‹è¯•æ¨¡å‹åˆ—è¡¨
            models = client.models.list()
            
            if models:
                model_count = len(models.data) if hasattr(models, 'data') else 0
                return {
                    "status": "success",
                    "message": f"OpenAI APIè¿æ¥æ­£å¸¸ï¼Œå¯ç”¨æ¨¡å‹: {model_count}",
                    "details": {
                        "base_url": config.LLM_BASE_URL,
                        "model_count": model_count
                    }
                }
            else:
                return {
                    "status": "error",
                    "message": "OpenAI APIè¿æ¥æˆåŠŸä½†æ— å¯ç”¨æ¨¡å‹",
                    "details": {}
                }
                
        except Exception as e:
            return {
                "status": "error",
                "message": f"OpenAI APIè¿æ¥å¤±è´¥: {str(e)}",
                "details": {"exception": str(e)}
            }
    
    async def _test_tavily_api(self) -> Dict[str, Any]:
        """æµ‹è¯•Tavily APIè¿æ¥"""
        try:
            if not hasattr(config, 'TAVILY_API_KEY') or not config.TAVILY_API_KEY:
                return {
                    "status": "warning",
                    "message": "Tavily APIå¯†é’¥æœªé…ç½®ï¼Œç½‘ç»œæœç´¢åŠŸèƒ½ä¸å¯ç”¨",
                    "details": {}
                }
            
            from tavily import TavilySearchAPIWrapper
            
            tavily = TavilySearchAPIWrapper(api_key=config.TAVILY_API_KEY)
            
            # æ‰§è¡Œæµ‹è¯•æœç´¢
            results = tavily.search("test query", max_results=1)
            
            if results:
                return {
                    "status": "success",
                    "message": "Tavily APIè¿æ¥æ­£å¸¸",
                    "details": {"test_results": len(results)}
                }
            else:
                return {
                    "status": "warning",
                    "message": "Tavily APIè¿æ¥æˆåŠŸä½†æµ‹è¯•æœç´¢æ— ç»“æœ",
                    "details": {}
                }
                
        except Exception as e:
            return {
                "status": "error",
                "message": f"Tavily APIè¿æ¥å¤±è´¥: {str(e)}",
                "details": {"exception": str(e)}
            }
    
    async def _test_lightrag_system(self) -> Dict[str, Any]:
        """æµ‹è¯•LightRAGç³»ç»Ÿ"""
        try:
            # åˆå§‹åŒ–LightRAGå®¢æˆ·ç«¯
            await lightrag_client.initialize()
            
            # è·å–å¥åº·çŠ¶æ€
            health_status = await lightrag_client.get_health_status()
            
            if health_status.get("initialized", False):
                return {
                    "status": "success",
                    "message": "LightRAGç³»ç»Ÿæ­£å¸¸",
                    "details": health_status
                }
            else:
                return {
                    "status": "error",
                    "message": "LightRAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥",
                    "details": health_status
                }
                
        except Exception as e:
            return {
                "status": "error",
                "message": f"LightRAGç³»ç»Ÿæµ‹è¯•å¤±è´¥: {str(e)}",
                "details": {"exception": str(e)}
            }
    
    async def _test_file_system(self) -> Dict[str, Any]:
        """æµ‹è¯•æ–‡ä»¶ç³»ç»Ÿè®¿é—®"""
        try:
            issues = []
            
            # æ£€æŸ¥å¿…è¦ç›®å½•
            directories = [
                config.RAG_STORAGE_DIR,
                config.DOCS_DIR
            ]
            
            for directory in directories:
                if not directory.exists():
                    issues.append(f"ç›®å½•ä¸å­˜åœ¨: {directory}")
                elif not os.access(directory, os.R_OK | os.W_OK):
                    issues.append(f"ç›®å½•æ— è¯»å†™æƒé™: {directory}")
            
            # æ£€æŸ¥æ—¥å¿—ç›®å½•
            log_dir = Path("logs")
            if not log_dir.exists():
                try:
                    log_dir.mkdir(exist_ok=True)
                except Exception as e:
                    issues.append(f"æ— æ³•åˆ›å»ºæ—¥å¿—ç›®å½•: {e}")
            
            if issues:
                return {
                    "status": "error",
                    "message": f"æ–‡ä»¶ç³»ç»Ÿè®¿é—®æœ‰ {len(issues)} ä¸ªé—®é¢˜",
                    "details": {"issues": issues}
                }
            else:
                return {
                    "status": "success",
                    "message": "æ–‡ä»¶ç³»ç»Ÿè®¿é—®æ­£å¸¸",
                    "details": {}
                }
                
        except Exception as e:
            return {
                "status": "error",
                "message": f"æ–‡ä»¶ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {str(e)}",
                "details": {"exception": str(e)}
            }
    
    def _determine_overall_status(self, success_rate: float) -> str:
        """ç¡®å®šæ•´ä½“çŠ¶æ€"""
        if success_rate >= 0.9:
            return "healthy"
        elif success_rate >= 0.7:
            return "warning"
        else:
            return "error"
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        recommendations = []
        
        for test_name, result in self.test_results.items():
            if result["status"] == "error":
                if "é…ç½®" in test_name:
                    recommendations.append("æ£€æŸ¥.envæ–‡ä»¶ï¼Œç¡®ä¿æ‰€æœ‰å¿…éœ€é…ç½®å·²è®¾ç½®")
                elif "PostgreSQL" in test_name:
                    recommendations.append("å¯åŠ¨PostgreSQLæœåŠ¡å¹¶å®‰è£…pgvectoræ‰©å±•")
                elif "Neo4j" in test_name:
                    recommendations.append("å¯åŠ¨Neo4jæœåŠ¡æˆ–æ›´æ–°è¿æ¥é…ç½®")
                elif "OpenAI" in test_name:
                    recommendations.append("éªŒè¯OpenAI APIå¯†é’¥å’Œç½‘ç»œè¿æ¥")
                elif "Tavily" in test_name:
                    recommendations.append("é…ç½®Tavily APIå¯†é’¥(å¯é€‰)")
                elif "LightRAG" in test_name:
                    recommendations.append("æ£€æŸ¥LightRAGä¾èµ–å’Œå­˜å‚¨é…ç½®")
                elif "æ–‡ä»¶ç³»ç»Ÿ" in test_name:
                    recommendations.append("æ£€æŸ¥ç›®å½•æƒé™å’Œç£ç›˜ç©ºé—´")
        
        return recommendations
```

#### ä¸»æ‰§è¡Œå‡½æ•°

```python
async def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    try:
        tester = ConnectionTester()
        summary = await tester.run_all_tests()
        
        # æ‰“å°è¯¦ç»†æŠ¥å‘Š
        print("\n" + "="*60)
        print("ğŸ” ç³»ç»Ÿè¿æ¥æµ‹è¯•æŠ¥å‘Š")
        print("="*60)
        
        overall_status = summary["overall_status"]
        if overall_status == "healthy":
            print("ğŸŸ¢ æ•´ä½“çŠ¶æ€: å¥åº·")
        elif overall_status == "warning":
            print("ğŸŸ¡ æ•´ä½“çŠ¶æ€: è­¦å‘Š")
        else:
            print("ğŸ”´ æ•´ä½“çŠ¶æ€: é”™è¯¯")
        
        print(f"ğŸ“Š æˆåŠŸç‡: {summary['success_rate']:.1%}")
        print(f"ğŸ“ˆ é€šè¿‡æµ‹è¯•: {summary['passed_tests']}/{summary['total_tests']}")
        
        # æ‰“å°å¤±è´¥çš„æµ‹è¯•
        failed_tests = [
            name for name, result in summary["test_results"].items()
            if result["status"] == "error"
        ]
        
        if failed_tests:
            print(f"\nâŒ å¤±è´¥çš„æµ‹è¯• ({len(failed_tests)}):")
            for test_name in failed_tests:
                result = summary["test_results"][test_name]
                print(f"  - {test_name}: {result['message']}")
        
        # æ‰“å°å»ºè®®
        if summary["recommendations"]:
            print(f"\nğŸ’¡ ä¿®å¤å»ºè®®:")
            for i, rec in enumerate(summary["recommendations"], 1):
                print(f"  {i}. {rec}")
        
        print("="*60)
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = Path("connection_test_report.json")
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        # æ ¹æ®ç»“æœè®¾ç½®é€€å‡ºç 
        if overall_status == "healthy":
            sys.exit(0)
        elif overall_status == "warning":
            sys.exit(1)
        else:
            sys.exit(2)
            
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        logger.error(f"è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
```

---

## è„šæœ¬ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¼€å§‹

```bash
# 1. åˆå§‹åŒ–ç¯å¢ƒ
python scripts/setup_environment.py

# 2. æµ‹è¯•ç³»ç»Ÿè¿æ¥
python scripts/test_connections.py

# 3. æ‘„å–æ–‡æ¡£
python scripts/ingest_documents.py docs/
```

### è¯¦ç»†ä½¿ç”¨æ–¹æ³•

**ç¯å¢ƒåˆå§‹åŒ–**
```bash
# å®Œæ•´ç¯å¢ƒè®¾ç½®
python scripts/setup_environment.py

# æŸ¥çœ‹è®¾ç½®æ—¥å¿—
tail -f logs/setup.log
```

**æ–‡æ¡£æ‘„å–**
```bash
# æ‘„å–å•ä¸ªç›®å½•
python scripts/ingest_documents.py documents/

# é€’å½’æ‘„å–æ‰€æœ‰å­ç›®å½•
python scripts/ingest_documents.py documents/ --recursive

# è®¾ç½®æ‰¹æ¬¡å¤§å°
python scripts/ingest_documents.py documents/ --batch-size 20

# è¯•è¿è¡Œï¼ˆä¸å®é™…æ‘„å–ï¼‰
python scripts/ingest_documents.py documents/ --dry-run

# æ‘„å–å•ä¸ªæ–‡ä»¶
python scripts/ingest_documents.py path/to/document.pdf
```

**è¿æ¥æµ‹è¯•**
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python scripts/test_connections.py

# æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š
cat connection_test_report.json
```

---

## è‡ªåŠ¨åŒ–å’Œé›†æˆ

### éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# deploy.sh - è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬

set -e

echo "ğŸš€ å¼€å§‹ç³»ç»Ÿéƒ¨ç½²..."

# 1. ç¯å¢ƒåˆå§‹åŒ–
echo "ğŸ“‹ æ­¥éª¤ 1: ç¯å¢ƒåˆå§‹åŒ–"
python scripts/setup_environment.py

# 2. è¿æ¥æµ‹è¯•
echo "ğŸ” æ­¥éª¤ 2: è¿æ¥æµ‹è¯•"
python scripts/test_connections.py

# 3. æ‘„å–ç¤ºä¾‹æ–‡æ¡£
echo "ğŸ“š æ­¥éª¤ 3: æ‘„å–ç¤ºä¾‹æ–‡æ¡£"
if [ -d "docs/" ]; then
    python scripts/ingest_documents.py docs/ --recursive
fi

echo "âœ… éƒ¨ç½²å®Œæˆï¼"
echo "ç°åœ¨å¯ä»¥è¿è¡Œ: streamlit run main_app.py"
```

### å®šæ—¶ä»»åŠ¡

```bash
# crontab -e
# æ¯æ—¥å¥åº·æ£€æŸ¥
0 9 * * * cd /path/to/project && python scripts/test_connections.py >> logs/daily_health.log 2>&1

# æ¯å‘¨æ–‡æ¡£æ‘„å–
0 2 * * 0 cd /path/to/project && python scripts/ingest_documents.py new_docs/ --recursive >> logs/weekly_ingest.log 2>&1
```

### Dockeré›†æˆ

```dockerfile
# Dockerfileä¸­çš„è„šæœ¬ä½¿ç”¨
FROM python:3.10

COPY scripts/ /app/scripts/
COPY src/ /app/src/

WORKDIR /app

# å®‰è£…ä¾èµ–
RUN pip install -r requirements.txt

# åˆå§‹åŒ–ç¯å¢ƒ
RUN python scripts/setup_environment.py

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python scripts/test_connections.py || exit 1

CMD ["streamlit", "run", "main_app.py"]
```

---

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥**
```bash
# æ£€æŸ¥ä¾èµ–
pip list | grep -E "(psycopg2|neo4j|lightrag)"

# æ£€æŸ¥æ•°æ®åº“æœåŠ¡
systemctl status postgresql
systemctl status neo4j

# æ‰‹åŠ¨æµ‹è¯•è¿æ¥
python -c "import psycopg2; print('PostgreSQLå¯ç”¨')"
python -c "from neo4j import GraphDatabase; print('Neo4jå¯ç”¨')"
```

**æ–‡æ¡£æ‘„å–å¤±è´¥**
```bash
# æ£€æŸ¥æ–‡ä»¶æƒé™
ls -la docs/

# æµ‹è¯•å•ä¸ªæ–‡ä»¶
python scripts/ingest_documents.py single_file.txt --dry-run

# æŸ¥çœ‹è¯¦ç»†é”™è¯¯
python scripts/ingest_documents.py docs/ --batch-size 1
```

**è¿æ¥æµ‹è¯•å¼‚å¸¸**
```bash
# é€æ­¥æµ‹è¯•
python -c "from src.core.config import config; print(config.LLM_API_KEY[:10])"
curl -H "Authorization: Bearer $LLM_API_KEY" https://api.openai.com/v1/models
```

### è°ƒè¯•æŠ€å·§

**è¯¦ç»†æ—¥å¿—**
```python
# åœ¨è„šæœ¬ä¸­å¯ç”¨è°ƒè¯•æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)
```

**æ€§èƒ½ç›‘æ§**
```python
# æ·»åŠ æ€§èƒ½ç›‘æ§
from utils.advanced_logging import get_performance_logger
perf_logger = get_performance_logger(__name__)

perf_logger.start_operation("script_execution")
# è„šæœ¬é€»è¾‘
perf_logger.end_operation(success=True)
```

---

**ğŸ“ è¯´æ˜**: æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†æ™ºèƒ½é—®ç­”ç³»ç»Ÿçš„æ‰€æœ‰è„šæœ¬å·¥å…·ã€‚è¿™äº›è„šæœ¬è‡ªåŠ¨åŒ–äº†ç¯å¢ƒè®¾ç½®ã€æ–‡æ¡£æ‘„å–å’Œç³»ç»Ÿç›‘æ§ç­‰å…³é”®æ“ä½œï¼Œæ˜¯ç³»ç»Ÿéƒ¨ç½²å’Œç»´æŠ¤çš„é‡è¦å·¥å…·ã€‚